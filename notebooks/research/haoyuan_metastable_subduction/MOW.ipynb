{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, I tried to reproduce the results of the following papers\n",
    "\n",
    "Kubo et al., 2009 (Seismological and experimental constraints on metastable phase transformations\n",
    "and rheology of the Mariana slab)\n",
    "\n",
    "Note:\n",
    "- some of the equations still don't show correctly. Also they seem to mess up the title when they are presented in the \"OUTLINE\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "root_path = os.path.join(Path().resolve().parent.parent.parent)\n",
    "\n",
    "if str(os.path.abspath(root_path)) not in sys.path:\n",
    "    sys.path.insert(0, str(os.path.abspath(root_path)))\n",
    "\n",
    "# Include this pakage\n",
    "import hamageolib.utils.plot_helper as plot_helper\n",
    "import hamageolib.research.haoyuan_2d_subduction.metastable as Meta\n",
    "\n",
    "from hamageolib.utils.exception_handler import my_assert\n",
    "from hamageolib.utils.handy_shortcuts_haoyuan import Mute\n",
    "\n",
    "# Directory path of this notebook\n",
    "base_dir = Path().resolve()\n",
    "\n",
    "# For dumping results\n",
    "results_dir = os.path.join(root_path, \"dtemp\")\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.mkdir(results_dir)\n",
    "\n",
    "# For scripts (e.g. bash, paraview)\n",
    "SCRIPT_DIR = os.path.join(root_path, \"scripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vtk.util.numpy_support import vtk_to_numpy\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.spatial import cKDTree\n",
    "    \n",
    "year = 365.0 * 24.0 * 3600.0  # Seconds in one year\n",
    "\n",
    "# define a function for round values\n",
    "round_values = lambda values: [round(x) for x in values]\n",
    "\n",
    "def idw_interpolation(points, values, query_points, k=5, power=1):\n",
    "    \"\"\"\n",
    "    Perform inverse distance weighting (IDW) interpolation.\n",
    "\n",
    "    Args:\n",
    "        points (np.ndarray): Coordinates of known data points (N x D).\n",
    "        values (np.ndarray): Values at the known data points (N,).\n",
    "        query_points (np.ndarray): Coordinates of query points (M x D).\n",
    "        k (int): Number of nearest neighbors to consider for interpolation.\n",
    "        power (int): Power parameter for the inverse distance weighting.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Interpolated values at the query points (M,).\n",
    "    \"\"\"\n",
    "    # Ensure values are a NumPy array\n",
    "    values = np.asarray(values)\n",
    "    \n",
    "    # Build a KDTree for fast nearest-neighbor lookup\n",
    "    tree = cKDTree(points)\n",
    "\n",
    "    # Find the k nearest neighbors for each query point\n",
    "    distances, indices = tree.query(query_points, k=k)\n",
    "\n",
    "    # Handle zero distances (avoid division by zero)\n",
    "    distances = np.maximum(distances, 1e-12)\n",
    "\n",
    "    # Compute weights as the inverse distance raised to the power\n",
    "    weights = 1 / distances**power\n",
    "\n",
    "    # Normalize weights\n",
    "    weights /= weights.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Interpolate the values\n",
    "    print(\"indices: \", indices) # debug\n",
    "    interpolated_values = np.sum(weights * values[indices], axis=1)\n",
    "\n",
    "    return interpolated_values\n",
    "\n",
    "\n",
    "def extract_contour_coordinates(xv, yv, t_sub_grid, levels, spacing=None):\n",
    "    \"\"\"\n",
    "    Extracts the x and y coordinates of contours from a meshed grid and field data.\n",
    "\n",
    "    Args:\n",
    "        xv (numpy.ndarray): 2D array of x-coordinates.\n",
    "        yv (numpy.ndarray): 2D array of y-coordinates.\n",
    "        t_sub_grid (numpy.ndarray): 2D array of field data on the grid.\n",
    "        levels (list or array): Contour levels (values) to extract.\n",
    "        spacing (float, optional): Desired spacing between contour points. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with levels as keys and (x, y) coordinate arrays as values.\n",
    "    \"\"\"\n",
    "    # Create the contour object\n",
    "    contours = plt.contour(xv, yv, t_sub_grid, levels=levels)\n",
    "\n",
    "    my_assert(len(contours.collections) == len(levels), ValueError,\\\n",
    "              \"Values of collections (%d) do not equal the provided levels(%d)\"\\\n",
    "                  % (len(contours.collections), len(levels)))\n",
    "\n",
    "    contour_coordinates = {}\n",
    "    for i, level in enumerate(levels):\n",
    "        x_coords = []\n",
    "        y_coords = []\n",
    "\n",
    "        # Extract paths for the given level\n",
    "        for path in contours.collections[i].get_paths():\n",
    "            vertices = path.vertices  # Extract contour points\n",
    "            xs, ys = vertices[:, 0], vertices[:, 1]\n",
    "\n",
    "            if spacing is not None and len(xs) > 1:\n",
    "                # Calculate cumulative distances along the contour\n",
    "                distances = np.sqrt(np.diff(xs)**2 + np.diff(ys)**2)\n",
    "                cumulative_distances = np.concatenate([[0], np.cumsum(distances)])\n",
    "\n",
    "                # Create interpolation functions for x and y\n",
    "                interp_x = interp1d(cumulative_distances, xs, kind='cubic', bounds_error=False, fill_value=\"extrapolate\")\n",
    "                interp_y = interp1d(cumulative_distances, ys, kind='cubic', bounds_error=False, fill_value=\"extrapolate\")\n",
    "\n",
    "                # Generate new cumulative distances with the desired spacing\n",
    "                cumulative_distances_with_spacing = np.arange(0, cumulative_distances[-1], spacing)\n",
    "\n",
    "                # Interpolate x and y for evenly spaced points\n",
    "                xs = interp_x(cumulative_distances_with_spacing)\n",
    "                ys = interp_y(cumulative_distances_with_spacing)\n",
    "\n",
    "            x_coords.extend(xs)\n",
    "            y_coords.extend(ys)\n",
    "\n",
    "        contour_coordinates[level] = (np.array(x_coords), np.array(y_coords))\n",
    "    \n",
    "    plt.close()  # Close the plot to avoid displaying it\n",
    "    return contour_coordinates\n",
    "\n",
    "def offset_curve(X, Y, d):\n",
    "    # Compute tangents as finite differences\n",
    "    dX = np.gradient(X)\n",
    "    dY = np.gradient(Y)\n",
    "    \n",
    "    # Compute normals by rotating tangents 90 degrees\n",
    "    normals = np.array([dY, -dX]).T  # Rotate tangent vectors\n",
    "    norm_length = np.linalg.norm(normals, axis=1, keepdims=True)\n",
    "    normals = normals / norm_length  # Normalize to unit vectors\n",
    "    \n",
    "    # Offset points by the normal vectors scaled by the distance d\n",
    "    X_offset = X + d * normals[:, 0]\n",
    "    Y_offset = Y + d * normals[:, 1]\n",
    "    \n",
    "    return X_offset, Y_offset\n",
    "\n",
    "def process_segments(slab_segments, n_spacing=10):\n",
    "    \"\"\"\n",
    "    Processes segments to generate a continuous curve based on lengths and dip angles.\n",
    "\n",
    "    Args:\n",
    "        slab_segments (list): List of segment dictionaries with 'length' and 'angle' keys.\n",
    "        n_spacing (int): Number of points per segment for interpolation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - lengths (numpy.ndarray): Accumulated lengths at each point.\n",
    "            - depths (numpy.ndarray): Accumulated depths at each point.\n",
    "            - dip_angles (numpy.ndarray): Corresponding dip angles at each point.\n",
    "            - Xs (numpy.ndarray): X coordinates of each point.\n",
    "    \"\"\"\n",
    "    # Calculate the total number of points in advance\n",
    "    total_points = sum(n_spacing for _ in slab_segments)\n",
    "\n",
    "    # Preallocate arrays\n",
    "    lengths = np.zeros(total_points)\n",
    "    depths = np.zeros(total_points)\n",
    "    dip_angles = np.zeros(total_points)\n",
    "    Xs = np.zeros(total_points)\n",
    "\n",
    "    accumulated_length = 0\n",
    "    accumulated_depth = 0\n",
    "    accumulated_x = 0\n",
    "    current_index = 0\n",
    "\n",
    "    for segment in slab_segments:\n",
    "        # Extract length and angle pair\n",
    "        length = segment['length']\n",
    "        angle_pair = segment['angle']\n",
    "\n",
    "        # Generate n_spacing points for angles and step lengths\n",
    "        segment_angles = np.linspace(angle_pair[0], angle_pair[1], n_spacing)\n",
    "        step_length = length / (n_spacing - 1)  # Incremental length per step\n",
    "\n",
    "        # Calculate incremental depths and X increments for each step\n",
    "        segment_depth_increments = step_length * (\n",
    "            np.sin(np.radians(segment_angles[:-1])) + np.sin(np.radians(segment_angles[1:]))\n",
    "        ) / 2.0  # Midpoint rule for depth integration\n",
    "\n",
    "        segment_x_increments = step_length * (\n",
    "            np.cos(np.radians(segment_angles[:-1])) + np.cos(np.radians(segment_angles[1:]))\n",
    "        ) / 2.0  # Midpoint rule for X integration\n",
    "\n",
    "        # Accumulated lengths and depths\n",
    "        segment_accumulated_lengths = accumulated_length + np.arange(n_spacing) * step_length\n",
    "        segment_depths = accumulated_depth + np.concatenate([np.array([0]), np.cumsum(segment_depth_increments)])\n",
    "        segment_xs = accumulated_x + np.concatenate([np.array([0]), np.cumsum(segment_x_increments)])\n",
    "\n",
    "        # Write to preallocated arrays\n",
    "        lengths[current_index:current_index + n_spacing] = segment_accumulated_lengths\n",
    "        depths[current_index:current_index + n_spacing] = segment_depths\n",
    "        dip_angles[current_index:current_index + n_spacing] = np.radians(segment_angles)\n",
    "        Xs[current_index:current_index + n_spacing] = segment_xs\n",
    "\n",
    "        # Update accumulations for the next segment\n",
    "        accumulated_length = segment_accumulated_lengths[-1]\n",
    "        accumulated_depth = segment_depths[-1]\n",
    "        accumulated_x = segment_xs[-1]\n",
    "        current_index += n_spacing\n",
    "\n",
    "    return lengths, depths, dip_angles, Xs\n",
    "\n",
    "\n",
    "def distances_to_curve(Xs, Ys, x, y):\n",
    "    \"\"\"\n",
    "    Computes the signed distance from each point in (x, y) to a curve defined by (Xs, Ys).\n",
    "\n",
    "    Positive distance: below the curve (smaller y).\n",
    "    Negative distance: above the curve (larger y).\n",
    "\n",
    "    Args:\n",
    "        Xs (numpy.ndarray): X-coordinates of the curve points (1D array).\n",
    "        Ys (numpy.ndarray): Y-coordinates of the curve points (1D array).\n",
    "        x (numpy.ndarray): X-coordinates of the points (1D array).\n",
    "        y (numpy.ndarray): Y-coordinates of the points (1D array).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The signed distance from each point in (x, y) to the curve (1D array).\n",
    "    \"\"\"\n",
    "    # Ensure x and y are numpy arrays\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    # Reshape (x, y) to allow broadcasting against (Xs, Ys)\n",
    "    x = x[:, np.newaxis]  # Shape (n_points, 1)\n",
    "    y = y[:, np.newaxis]  # Shape (n_points, 1)\n",
    "\n",
    "    # Compute squared distances for all combinations\n",
    "    distances_squared = (Xs - x) ** 2 + (Ys - y) ** 2  # Shape (n_points, len(Xs))\n",
    "\n",
    "    # Find the index of the closest point on the curve for each query point\n",
    "    min_indices = np.argmin(distances_squared, axis=1)\n",
    "\n",
    "    # Use min_indices to directly extract the minimum distances\n",
    "    min_distances = np.sqrt(distances_squared[np.arange(len(x)), min_indices])\n",
    "\n",
    "    # Determine if the point is above or below the curve\n",
    "    closest_Ys = Ys[min_indices]\n",
    "    signs = np.where(y.flatten() < closest_Ys, 1.0, -1.0)\n",
    "\n",
    "    # Apply the sign to the distances\n",
    "    signed_distances = signs * min_distances\n",
    "    return signed_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equilibrium phase transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equilibrium phase transition for 410 km\n",
    "# dV - change in volume fraction\n",
    "# See whether these are still needed\n",
    "# dV_ol_wd - m^3 / mol, difference in volume between phases\n",
    "# V_initial - m^3 / mol, for olivine, estimation at 410 km\n",
    "# PT410 = {\"P\": 13.5e9, \"T\": 1740.0, \"cl\": 2e6, \"dV\": 0.052, \"dV_ol_wd\": 2.4e-6, \"V_initial\": 35.17e-6}\n",
    "PT410 = {\"P\": 13.5e9, \"T\": 1740.0, \"cl\": 2e6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosoya 2005 (The Kinematics)\n",
    "\n",
    "### Summary: Growth Rate and Timescale Calculations Based on Hosoya 2006\n",
    "\n",
    "This notebook contains Python code for calculating the growth rate and critical timescales of phase transformations based on the kinetic models described in *Hosoya et al., 2006*. The calculations rely on the Arrhenius law and consider the effects of pressure, temperature, and water content.\n",
    "\n",
    "### Constants and Assumptions\n",
    "\n",
    "- Universal gas constant: \\( R = 8.31446 \\, \\text{J/mol·K} \\)\n",
    "- Activation enthalpy: \\( \\Delta H = 274 \\, \\text{kJ/mol} \\)\n",
    "- Activation volume: \\( V^* = 3.3 \\times 10^{-6} \\, \\text{m}^3/\\text{mol} \\)\n",
    "- Volume difference: \\( \\Delta V = 2.4 \\times 10^{-6} \\, \\text{m}^3/\\text{mol} \\)\n",
    "- Water concentration scaling exponent: \\( n = 3.2 \\)\n",
    "\n",
    "### Functions Overview\n",
    "\n",
    "1. **`growth_rate_hosoya_06_eq2_P1(P, T, Coh)`**:\n",
    "   - Calculates the growth rate using Equation 2 from Hosoya (2006) for given pressure (`P`), temperature (`T`), and water concentration (`Coh`).\n",
    "   - **Parameters**:\n",
    "     - `P`: Pressure (Pa)\n",
    "     - `T`: Temperature (K)\n",
    "     - `Coh`: Water concentration (wt.ppm H2O)\n",
    "   - **Returns**: Growth rate in meters per second.\n",
    "\n",
    "2. **`growth_rate_hosoya_06_eq2(P, P_eq, T, Coh)`**:\n",
    "   - Extends the growth rate calculation to handle cases where the pressure is an array and determines whether the pressure exceeds the equilibrium pressure (`P_eq`).\n",
    "   - **Parameters**:\n",
    "     - `P`: Pressure (float or ndarray)\n",
    "     - `P_eq`: Equilibrium pressure (Pa)\n",
    "     - `T`: Temperature (K)\n",
    "     - `Coh`: Water concentration (wt.ppm H2O)\n",
    "   - **Returns**: Growth rate as a float or array.\n",
    "\n",
    "3. **`timescale_hosoya_06(P, P_eq, growth_rate, Coh)`**:\n",
    "   - Computes the critical timescale for phase transitions using growth rate and equilibrium properties.\n",
    "   - **Parameters**:\n",
    "     - `P`: Pressure (Pa)\n",
    "     - `P_eq`: Equilibrium pressure (Pa)\n",
    "     - `growth_rate`: Growth rate (m/s)\n",
    "     - `Coh`: Water concentration (wt.ppm H2O)\n",
    "   - **Returns**: Critical timescale (seconds).\n",
    "\n",
    "### Visualization\n",
    "\n",
    "The notebook includes plots to visualize the growth rate variations:\n",
    "- **Pressure vs. Growth Rate**: Explores the dependence of growth rate on pressure.\n",
    "- **Temperature vs. Growth Rate**: Shows how growth rate changes with temperature.\n",
    "- **OH Content vs. Growth Rate**: Investigates the effect of water concentration on growth rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "from scipy.integrate import cumtrapz\n",
    "\n",
    "def growth_rate_P1(P, T, Coh):\n",
    "    \"\"\"\n",
    "    Calculate the growth rate following Equation 2 in Hosoya 2006.\n",
    "\n",
    "    Parameters:\n",
    "    - P (float): Pressure in Pascals.\n",
    "    - T (float): Temperature in Kelvin.\n",
    "    - Coh (float): Concentration of water in weight parts per million (wt.ppm H2O).\n",
    "\n",
    "    Returns:\n",
    "    - float: The growth rate calculated using the given parameters.\n",
    "    \"\"\"\n",
    "    R = 8.31446  # J / mol*K, universal gas constant\n",
    "\n",
    "    # Constants based on Hosoya 2006\n",
    "    A = np.exp(-18.0)  # m s-1 wt.ppmH2O^(-3.2)\n",
    "    n = 3.2\n",
    "    dHa = 274.0e3  # J / mol, activation enthalpy\n",
    "    Vstar = 3.3e-6  # m^3 / mol, activation volume\n",
    "\n",
    "    growth_rate_part = A * Coh**n * np.exp(-(dHa + P * Vstar) / (R * T))\n",
    "\n",
    "    return growth_rate_part\n",
    "\n",
    "\n",
    "def growth_rate_metastable(P, P_eq, T, Coh):\n",
    "    \"\"\"\n",
    "    Calculate growth rate using Equation 2 from Hosoya 2006 for metastable conditions.\n",
    "\n",
    "    Parameters:\n",
    "    - P (float or ndarray): Actual pressure (Pa).\n",
    "    - P_eq (float or ndarray): Equilibrium pressure (Pa).\n",
    "    - T (float or ndarray): Temperature (K).\n",
    "    - Coh (float): Water concentration (wt.ppm H2O).\n",
    "\n",
    "    Returns:\n",
    "    - float or ndarray: Growth rate for the given conditions.\n",
    "    \"\"\"\n",
    "    if type(T) in [float, np.float64]:\n",
    "        if Ps > P_eq:\n",
    "            growth_rate = growth_rate(P, P_eq, T, Coh)\n",
    "        else:\n",
    "            growth_rate = 0.0\n",
    "    elif type(T) == np.ndarray:\n",
    "        assert P.shape == T.shape\n",
    "        assert P_eq.shape == T.shape\n",
    "        growth_rate = np.zeros(T.shape)\n",
    "        mask = (P > P_eq)  # Check metastable condition\n",
    "        growth_rate[mask] = growth_rate(P[mask], P_eq[mask], T[mask], Coh)\n",
    "    else:\n",
    "        raise TypeError(\"T must be float or ndarray\")\n",
    "    return growth_rate\n",
    "\n",
    "\n",
    "def growth_rate(P, P_eq, T, Coh):\n",
    "    \"\"\"\n",
    "    Calculate the growth rate following Equation 2 in Hosoya 2006, considering \n",
    "    pressure and temperature variations.\n",
    "\n",
    "    Parameters:\n",
    "    - P (float or np.ndarray): Pressure in Pascals.\n",
    "    - P_eq (float or np.ndarray): Equilibrium pressure in Pascals.\n",
    "    - T (float or np.ndarray): Temperature in Kelvin.\n",
    "    - Coh (float): Concentration of water in weight parts per million (wt.ppm H2O).\n",
    "\n",
    "    Returns:\n",
    "    - float or np.ndarray: The growth rate for each pressure point.\n",
    "    \"\"\"\n",
    "    R = 8.31446  # J / mol*K, universal gas constant\n",
    "\n",
    "    # Determine growth rate based on pressure type (float or array)\n",
    "    if type(P) in [float, np.float64]:\n",
    "        if P > P_eq:\n",
    "            dGr = PT410[\"dV_ol_wd\"] * (P - P_eq)\n",
    "            growth_rate = growth_rate_P1(P, T, Coh) * T * (1 - np.exp(-dGr / (R * T)))\n",
    "        else:\n",
    "            growth_rate = 0.0\n",
    "    elif type(P) == np.ndarray:\n",
    "        growth_rate = np.zeros(P.shape)\n",
    "        mask = P > P_eq\n",
    "        Pm = P[mask]\n",
    "        Tm = T[mask]\n",
    "        dGr = PT410[\"dV_ol_wd\"] * (Pm - P_eq[mask])\n",
    "        growth_rate[mask] = growth_rate_P1(Pm, Tm, Coh) * Tm * (1 - np.exp(-dGr / (R * Tm)))\n",
    "    else:\n",
    "        raise TypeError(\"P must be float or ndarray\")\n",
    "\n",
    "    return growth_rate\n",
    "\n",
    "\n",
    "def timescale_hosoya_06(P, P_eq, growth_rate, Coh):\n",
    "    \"\"\"\n",
    "    Calculate the critical time scale for phase transition kinetics.\n",
    "\n",
    "    Parameters:\n",
    "    - P (float): Pressure in Pascals.\n",
    "    - P_eq (float): Equilibrium pressure in Pascals.\n",
    "    - growth_rate (float): Growth rate in m/s.\n",
    "    - Coh (float): Concentration of water in weight parts per million (wt.ppm H2O).\n",
    "\n",
    "    Returns:\n",
    "    - float: The critical timescale in seconds.\n",
    "    \"\"\"\n",
    "    R = 8.31446  # J / mol*K, universal gas constant\n",
    "\n",
    "    # Constants for calculation\n",
    "    A = np.exp(-18.0)  # m s-1 wt.ppmH2O^(-3.2)\n",
    "    A_dot = A * PT410[\"dV_ol_wd\"] / R\n",
    "    n = 3.2\n",
    "    dHa = 274.0e3  # J / mol, activation enthalpy\n",
    "    Vstar = 3.3e-6  # m^3 / mol, activation volume\n",
    "\n",
    "    Tcr = (dHa + P * Vstar) / R / (np.log(A_dot * Coh**n * (P - P_eq) / growth_rate))\n",
    "\n",
    "    return Tcr\n",
    "\n",
    "def MO_Vfraction_classic(growth_rates, ts, da0):\n",
    "\n",
    "    # Compute cumulative integral of growth rates over time\n",
    "    integral = np.zeros(growth_rates.shape)  # Initialize integral\n",
    "    integral[1:] = cumtrapz(growth_rates, ts)  # Cumulative integral\n",
    "\n",
    "    # Calculate transformed volume fraction\n",
    "    S = 3.35 / da0  # Surface area per unit volume (1/m)\n",
    "    V = 1 - np.exp(-2.0 * S * integral)  # Transformed volume fraction\n",
    "\n",
    "    return V\n",
    "\n",
    "\n",
    "plot_hosoya_06 = False\n",
    "\n",
    "if plot_hosoya_06:\n",
    "\n",
    "    # Visualization of growth rate variations\n",
    "    fig = plt.figure(tight_layout=True, figsize=(15, 5))\n",
    "    gs = gridspec.GridSpec(1, 3)\n",
    "\n",
    "    # Plot growth rate vs Pressure\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    T = 900 + 273.15  # Temperature in Kelvin\n",
    "    Ps = np.arange(13e9, 16e9, 0.1e9)  # Pressure range in Pascals\n",
    "    Coh = 1000.0  # Concentration of water in wt.ppm H2O\n",
    "    growth_rate_part = growth_rate_P1(Ps, T, Coh)\n",
    "    ax.plot(Ps / 1e9, np.log(growth_rate_part))  # Pressure in GPa\n",
    "    ax.grid()\n",
    "    ax.set_xlim([13.0, 16.0])\n",
    "    ax.set_ylim([-34.0, -22.0])\n",
    "    ax.set_xlabel(\"Pressure (GPa)\")\n",
    "    ax.set_ylabel(\"ln(growth_rate/T[1-exp(-dGr/RT)])\")\n",
    "\n",
    "    # Plot growth rate vs Temperature\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "    T_invert = np.arange(0.7, 1.1, 0.01)  # 1000/T range\n",
    "    Ts = 1000.0 / T_invert  # Temperature in Kelvin\n",
    "    P = 15e9  # Pressure in Pascals\n",
    "    Coh = 1000.0  # Concentration of water in wt.ppm H2O\n",
    "    growth_rate_part = growth_rate_P1(P, Ts, Coh)\n",
    "    ax.plot(T_invert, np.log(growth_rate_part))\n",
    "    ax.grid()\n",
    "    ax.set_xlim([0.7, 1.1])\n",
    "    ax.set_ylim([-34.0, -22.0])\n",
    "    ax.set_xlabel(\"1000/T (K)\")\n",
    "\n",
    "    # Plot growth rate vs OH content\n",
    "    ax = fig.add_subplot(gs[0, 2])\n",
    "    T = 900 + 273.15  # Temperature in Kelvin\n",
    "    P = 15e9  # Pressure in Pascals\n",
    "    log10_Cohs = np.arange(2, 4, 0.05)  # Logarithmic OH content range\n",
    "    Cohs = 10**log10_Cohs  # OH content in wt.ppm H2O\n",
    "    growth_rate_part = growth_rate_P1(P, T, Cohs)\n",
    "    ax.semilogx(Cohs, np.log(growth_rate_part))\n",
    "    ax.grid()\n",
    "    ax.set_xlim([10**2, 10**4])\n",
    "    ax.set_ylim([-34.0, -22.0])\n",
    "    ax.set_xlabel(\"OH content (wt. ppm H2O)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also plot the values of grow rate for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_hosoya_06:\n",
    "\n",
    "\n",
    "    # Visualization of growth rate variations\n",
    "    fig = plt.figure(tight_layout=True, figsize=(15, 5))\n",
    "    gs = gridspec.GridSpec(1, 3)\n",
    "\n",
    "    # Plot growth rate vs Pressure\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    T = 900 + 273.15  # Temperature in Kelvin\n",
    "    Ps = np.arange(13e9, 16e9, 0.1e9)  # Pressure range in Pascals\n",
    "    Ts = np.full(Ps.shape, T)\n",
    "    Ps_eq = np.full(Ps.shape, PT410[\"P\"])\n",
    "    Coh = 1000.0  # Concentration of water in wt.ppm H2O\n",
    "    growth_rate = growth_rate(Ps, Ps_eq, Ts, Coh)\n",
    "    # growth_rate_part = growth_rate_P1(Ps, T, Coh)\n",
    "\n",
    "    ax.plot(Ps/1e9, np.log(growth_rate))\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"Pressure (GPa)\")\n",
    "    ax.set_ylabel(\"Growth Rate (m/s)\")\n",
    "    ax.set_xlim([13.0, 16.0])\n",
    "\n",
    "\n",
    "    # Plot growth rate vs Temperature\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "    T_invert = np.arange(0.7, 1.1, 0.01)  # 1000/T range\n",
    "    Ts = 1000.0 / T_invert  # Temperature in Kelvin\n",
    "    P = 15e9  # Pressure in Pascals\n",
    "    Ps = np.full(Ts.shape, P)\n",
    "    Ps_eq = np.full(Ps.shape, PT410[\"P\"])\n",
    "    Coh = 1000.0  # Concentration of water in wt.ppm H2O\n",
    "    growth_rate = growth_rate(Ps, Ps_eq, Ts, Coh)\n",
    "    ax.plot(T_invert, np.log(growth_rate))\n",
    "    ax.grid()\n",
    "    ax.set_xlim([0.7, 1.1])\n",
    "    # ax.set_ylim([-34.0, -22.0])\n",
    "    ax.set_xlabel(\"1000/T (K)\")\n",
    "    # ax.set_ylabel(\"Growth Rate (m/s)\")\n",
    "\n",
    "\n",
    "    # Plot growth rate vs OH content\n",
    "    ax = fig.add_subplot(gs[0, 2])\n",
    "    T = 900 + 273.15  # Temperature in Kelvin\n",
    "    P = 15e9  # Pressure in Pascals\n",
    "    log10_Cohs = np.arange(2, 4, 0.05)  # Logarithmic OH content range\n",
    "    Cohs = 10**log10_Cohs  # OH content in wt.ppm H2O\n",
    "    Ts = np.full(Cohs.shape, T)\n",
    "    Ps = np.full(Cohs.shape, P)\n",
    "    Ps_eq = np.full(Cohs.shape, PT410[\"P\"])\n",
    "    growth_rate = growth_rate(Ps, Ps_eq, Ts, Cohs)\n",
    "    # growth_rate_part = growth_rate_P1(P, T, Cohs)\n",
    "    ax.semilogx(Cohs, growth_rate)\n",
    "    ax.grid()\n",
    "    ax.set_xlim([10**2, 10**4])\n",
    "#     ax.set_ylim([-34.0, -22.0])\n",
    "    ax.set_xlabel(\"OH content (wt. ppm H2O)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kubo et al., 2009\n",
    "\n",
    "### Interpolation and Visualization of Temperature Profile\n",
    "\n",
    "This section of the notebook focuses on loading, interpolating, and visualizing a temperature profile (their Fig. 2) based on depth from a CSV file.\n",
    "They already include the latent heat release from the exthorthemic transition in the thermal model (Fig. 2).\n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Data Loading**:\n",
    "   - Reads the temperature profile from a CSV file (`kubo_2009_T_center.csv`).\n",
    "   - The file is located in the `data_set` directory within the specified `base_dir`.\n",
    "\n",
    "2. **Data Extraction**:\n",
    "   - Extracts depth (in kilometers) and temperature (in degrees Celsius) columns from the loaded dataset.\n",
    "\n",
    "3. **Interpolation**:\n",
    "   - Uses `scipy.interpolate.interp1d` to create an interpolation function for the temperature profile.\n",
    "   - Generates interpolated values for depths at 1 km intervals.\n",
    "\n",
    "4. **Visualization**:\n",
    "   - Plots the interpolated temperature profile, with depth on the x-axis and temperature on the y-axis.\n",
    "   - Includes axis labels and a grid for improved clarity.\n",
    "\n",
    "### Assumptions and Requirements\n",
    "\n",
    "- The CSV file must exist at the specified path, and its structure should include two columns: depth and temperature.\n",
    "- The depth values should be sorted in ascending order for proper interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "reproduce_Kubo_2009 = False\n",
    "\n",
    "if reproduce_Kubo_2009:\n",
    "\n",
    "    # Load and plot the temperature profile from a CSV file.\n",
    "    # Load temperature profile data from the file\n",
    "    file_T_path = os.path.join(base_dir, \"data_set\", \"kubo_2009_T_center.csv\")\n",
    "    assert(os.path.isfile(file_T_path))  # Ensure the file exists\n",
    "    data_T = pd.read_csv(file_T_path)  # Read data using pandas\n",
    "\n",
    "    # Extract depth and temperature columns\n",
    "    depths = data_T.iloc[:, 0]  # Depth in kilometers\n",
    "    Ts = data_T.iloc[:, 1]  # Temperature in degrees Celsius\n",
    "\n",
    "    # Interpolate temperature profile\n",
    "    T_interp = interp1d(depths, Ts)  # Create an interpolating function\n",
    "\n",
    "    # Generate interpolated values\n",
    "    depths1 = np.arange(depths.iloc[0], depths.iloc[-1], 1.0)  # Interpolated depths (km)\n",
    "    Ts1 = T_interp(depths1)  # Interpolated temperatures (C)\n",
    "\n",
    "    # Plot the interpolated temperature profile\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(depths1, Ts1)  # Depth vs. temperature plot\n",
    "\n",
    "    # Add plot labels and grid\n",
    "    ax.set_xlabel(\"Depth (km)\")  # Label for x-axis\n",
    "    ax.set_ylabel(\"Temperature (C)\")  # Label for y-axis\n",
    "    ax.grid()  # Add grid for better visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section calculates and visualizes two types of temperature dependencies in their Fig. 4\n",
    "\n",
    "1. Non-equilibrium temperature (\\( T_{NE} \\)) as a function of overpressure.\n",
    "2. Grain size-dependent temperature (\\( T_{GN} \\)) as a function of grain size.\n",
    "\n",
    "#### Equation for V\n",
    "\n",
    "$V = 1 - exp\\left[-2S \\int_{0}^t \\dot{x}\\left(\\tau\\right)d\\tau\\right]$\n",
    "\n",
    "#### Key Steps\n",
    "\n",
    "1. **Non-equilibrium Temperature ($T_{NE}$)**:\n",
    "   - Computes $T_{NE}$ for 1000 ppm and 100 ppm water concentrations.\n",
    "   - Uses an overpressure range ($\\Delta P$) from $0.01 \\, \\text{GPa}$ to $1.0 \\, \\text{GPa}$.\n",
    "   - Subduction velocity ($v_{sub}$) and timescale ($t_{sub}$) are used to estimate the growth rate.\n",
    "   - Visualized as $T_{NE}$ versus overpressure in a log-log plot.\n",
    "\n",
    "2. **Grain Size-dependent Temperature ($T_{GN}$)**:\n",
    "   - Computes $T_{GN}$ for 1000 ppm and 100 ppm water concentrations.\n",
    "   - Uses a grain size range ($d$) from $10^{-6} \\, \\text{m}$ to $10^{-1} \\, \\text{m}$.\n",
    "   - Grain size-dependent growth rate ($v_{GN}$) is calculated using a fixed subduction timescale ($t_{sub}$).\n",
    "   - Visualized as $T_{GN}$ versus grain size in a log-log plot.\n",
    "\n",
    "#### Constants and Assumptions\n",
    "\n",
    "- **Year Conversion**: $1 \\, \\text{year} = 365 \\times 24 \\times 3600 \\, \\text{s}$\n",
    "- **Equilibrium Conditions**:\n",
    "  - Equilibrium temperature: $T_{eq,410} = 1760 \\, \\text{K}$\n",
    "  - Clapeyron slope: $c_{l,410} = 4 \\times 10^6 \\, \\text{Pa/K}$\n",
    "  - Equilibrium pressure: $P_{410} = 14 \\, \\text{GPa}$\n",
    "- **Subduction Properties**:\n",
    "  - Grain size: $d = 5 \\times 10^{-3} \\, \\text{m}$\n",
    "  - Subduction velocity: $v_{sub} = 0.1 / \\text{year}$\n",
    "  - Subduction timescale: $t_{sub} = 10^5 \\, \\text{years}$\n",
    "\n",
    "#### Additional notes\n",
    "* Note their ol-wd curves references the Hosoya 2005 paper, while the post-spinel curve references the Kubo et al., 2002a, 2008 paper.\n",
    "* S is the area of grain-boundary of parent phase (=3.35/d), d is the grain size of the parental olivine, assuming equidimensional grains (tetrakaidecahedra) [Cahn, 1956]. Note this seems the only place the parental grain size is needed.\n",
    "* d is assumed to 5 mm in their figure 3.\n",
    "* tsub, the subduction timescale, is based on $v_{sub}t_{sub} = 10 km$, thus a velocity of 10 cm yields a timescale of ${10}^5$ years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reproduce_Kubo_2009:\n",
    "\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig = plt.figure(tight_layout=True, figsize=(5, 10))\n",
    "    gs = gridspec.GridSpec(2, 1)\n",
    "\n",
    "    # ---- Figure 4a: T_NE (non-equilibrium temperature) vs. overpressure ----\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    P_eq = PT410[\"P\"]  # Equilibrium pressure (Pa)\n",
    "    lndP = np.arange(-2.0, 0.0, 0.05)  # Logarithmic overpressure range (log10 GPa)\n",
    "    dP = 10**lndP * 1e9  # Overpressure range (Pa)\n",
    "    P = P_eq + dP  # Actual pressure range (Pa)\n",
    "    d = 5e-3  # Grain size (m)\n",
    "    v_sub = 0.1 / year  # Subduction velocity (m/s)\n",
    "    t_sub = 1e5 * year  # Subduction timescale (s)\n",
    "    growth_rate_NE = v_sub  # Growth rate for non-equilibrium\n",
    "\n",
    "    # Calculate non-equilibrium temperature timescale (T_NE) for 1000 ppm water\n",
    "    ts_NE = timescale_hosoya_06(P, P_eq, growth_rate_NE, 1000.0)\n",
    "    ax.semilogx(dP / 1e9, ts_NE - 273.15, label=\"ol-wd, 1000 ppm\")  # Plot curve for 1000 ppm\n",
    "\n",
    "    # Calculate T_NE for 100 ppm water\n",
    "    ts_NE_coh100 = timescale_hosoya_06(P, P_eq, growth_rate_NE, 100.0)\n",
    "    ax.semilogx(dP / 1e9, ts_NE_coh100 - 273.15, label=\"ol-wd, 100 ppm\")  # Plot curve for 100 ppm\n",
    "\n",
    "    # Configure subplot\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.set_xlim([1e-2, 1.0])  # Overpressure range (GPa)\n",
    "    ax.set_ylim([800, 2100.0])  # Temperature range (°C)\n",
    "    ax.set_xlabel(\"Overpressure (GPa)\")\n",
    "    ax.set_ylabel(\"T_NE (C)\")\n",
    "\n",
    "    # ---- Figure 4b: T_GN (grain size-dependent temperature) vs. grain size ----\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "    logds = np.arange(-6, -1, 0.1)  # Logarithmic grain size range\n",
    "    ds = 10**logds  # Grain size range (m)\n",
    "    growth_rate_GN = ds / t_sub  # Grain size-dependent growth rate (m/s)\n",
    "    dP = 0.5e9  # Overpressure (Pa)\n",
    "    P = P_eq + dP  # Pressure for grain size calculations (Pa)\n",
    "\n",
    "    # Calculate grain size-dependent temperature timescale (T_GN) for 1000 ppm water\n",
    "    ts_GN = timescale_hosoya_06(P, P_eq, growth_rate_GN, 1000.0)\n",
    "    ax.semilogx(ds, ts_GN - 273.15, label=\"ol-wd, 1000 ppm\")  # Plot curve for 1000 ppm\n",
    "\n",
    "    # Calculate T_GN for 100 ppm water\n",
    "    ts_GN_coh100 = timescale_hosoya_06(P, P_eq, growth_rate_GN, 100.0)\n",
    "    ax.semilogx(ds, ts_GN_coh100 - 273.15, label=\"ol-wd, 100 ppm\")  # Plot curve for 100 ppm\n",
    "\n",
    "    # Configure subplot\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.set_xlim([1e-6, 1e-1])  # Grain size range (m)\n",
    "    ax.set_ylim([400, 1700.0])  # Temperature range (°C)\n",
    "    ax.set_xlabel(\"Parental grain size (m)\")\n",
    "    ax.set_ylabel(\"T_GN (C)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIgure 5: Nucleation and Growth Visualization\n",
    "\n",
    "#### Key Steps\n",
    "\n",
    "1. **Parameters**:\n",
    "   - Temperature (\\(T\\)) and pressure (\\(P\\)) profiles are calculated for depths from 400 km to 700 km.\n",
    "   - Grain sizes (\\(d\\)) are set to \\(5 \\times 10^{-3} \\, \\text{m}\\) for grain-boundary nucleation and \\(5 \\times 10^{-5} \\, \\text{m}\\) for intracrystalline nucleation.\n",
    "\n",
    "2. **Growth Rates**:\n",
    "   - Growth rates are computed using metastable conditions for varying water concentrations (\\(C_{OH}\\)).\n",
    "\n",
    "3. **Transformed Volume Fractions**:\n",
    "   - The cumulative transformed volume (\\(V\\)) is calculated as:\n",
    "     \\[\n",
    "     V = 1 - \\exp(-2.0 \\cdot S \\cdot \\text{integral})\n",
    "     \\]\n",
    "   - \\(S\\) is the surface area per unit volume.\n",
    "\n",
    "4. **Plots**:\n",
    "   - **Grain-boundary nucleation**: \\(V\\) is plotted against depth for water concentrations of 250, 500, and 750 wt.ppm.\n",
    "   - **Intracrystalline nucleation**: \\(V\\) is plotted against depth for water concentrations of 50, 150, and 250 wt.ppm.\n",
    "\n",
    "#### Additional Notes\n",
    "* They seem to not include the positive feedback from the latentheat, as they note \"Previous studies have revealed that the G-type olivine–ringwoodite transformation quickly completes when it proceeds to the critical volume fraction of 5–10 vol.% due to the positive feedback of the latent heat release (e.g., Rubie and Ross, 1994; Kirby et al., 1996; Mosenfelder et al., 2001).\"\n",
    "* The transformed volume by intracrystallion nucleation should always be bigger, since it assumes a smaller parental grain size, thus a larger nucleation area S.\n",
    "* Note the slight differences of our curves to theirs (e.g. the 250 wt.ppm H2O curve in figure 5 a, at 700 depth, theirs is around 0.85, while ours is around 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 5: Grain-boundary and intracrystalline nucleation plots\n",
    "\n",
    "if reproduce_Kubo_2009:\n",
    "\n",
    "    from scipy.integrate import cumtrapz\n",
    "    from matplotlib import gridspec\n",
    "\n",
    "    # Retrieve the default color cycle for consistent plot coloring\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Reference parameters from Hosoya 2005\n",
    "    T660 = 873.0  # Temperature at 660 km depth (K)\n",
    "    Tgrad = 0.6 / 1e3  # Temperature gradient (K/m)\n",
    "    dPdh = 30e6 / 1e3  # Pressure gradient (Pa/m)\n",
    "    v_sub = 0.095 / year  # Subduction velocity (m/s)\n",
    "    depth0 = 400e3  # Initial depth for calculations (m)\n",
    "\n",
    "    # Define depth, temperature, and pressure profiles\n",
    "    depths = np.arange(depth0, 700e3, 1e3)  # Depths from 400 to 700 km (m)\n",
    "    ts = (depths - depth0) / v_sub  # Time required for subduction to each depth (s)\n",
    "    Ts = T_interp(depths / 1e3) + 273.15  # Temperature interpolated and converted to K\n",
    "    Ps = (depths - 410e3) * dPdh + PT410[\"P\"]  # Pressure profile (Pa)\n",
    "\n",
    "    # Equilibrium pressure and corresponding depths\n",
    "    Ps_eq = (Ts - PT410[\"T\"]) * PT410[\"cl\"] + PT410[\"P\"]  # Equilibrium pressure (Pa)\n",
    "    depths_eq = 410e3 + (Ts - PT410[\"T\"]) * PT410[\"cl\"] / dPdh  # Equilibrium depth (m)\n",
    "\n",
    "\n",
    "    # Create a figure for nucleation plots\n",
    "    fig = plt.figure(tight_layout=True, figsize=(5, 10))\n",
    "    gs = gridspec.GridSpec(2, 1)\n",
    "\n",
    "    # ---- Plot 1: Grain-boundary nucleation ----\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    d_ol = 5e-3  # Grain size for olivine (m)\n",
    "    S = 3.35 / d_ol  # Surface area per unit volume (1/m)\n",
    "\n",
    "    # Calculate and plot for different water concentrations\n",
    "    for Coh, color, label in [(250.0, default_colors[2], \"250 wt.ppm H2O\"),\n",
    "                            (500.0, default_colors[1], \"500 wt.ppm H2O\"),\n",
    "                            (750.0, default_colors[0], \"750 wt.ppm H2O\")]:\n",
    "        growth_rates = growth_rate_metastable(Ps, Ps_eq, Ts, Coh)\n",
    "        integral = np.zeros(depths.shape)  # Initialize integral\n",
    "        integral[1:] = cumtrapz(growth_rates, ts)  # Cumulative integral\n",
    "        V = 1 - np.exp(-2.0 * S * integral)  # Transformed volume fraction\n",
    "        ax.plot(depths / 1e3, V, label=label, color=color)\n",
    "\n",
    "    # Configure plot\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Depth (km)\")\n",
    "    ax.set_ylabel(\"Transformed Volume Fraction\")\n",
    "    ax.set_title(\"Grain-boundary nucleation\")\n",
    "\n",
    "    # ---- Plot 2: Intracrystalline nucleation ----\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "    d_ol = 5e-5  # Grain size for olivine (m)\n",
    "    S = 3.35 / d_ol  # Surface area per unit volume (1/m)\n",
    "\n",
    "    # Calculate and plot for different water concentrations\n",
    "    for Coh, color, label in [(50.0, default_colors[4], \"50 wt.ppm H2O\"),\n",
    "                            (150.0, default_colors[3], \"150 wt.ppm H2O\"),\n",
    "                            (250.0, default_colors[2], \"250 wt.ppm H2O\")]:\n",
    "        growth_rates = growth_rate_metastable(Ps, Ps_eq, Ts, Coh)\n",
    "        integral = np.zeros(depths.shape)  # Initialize integral\n",
    "        integral[1:] = cumtrapz(growth_rates, ts)  # Cumulative integral\n",
    "        V = 1 - np.exp(-2.0 * S * integral)  # Transformed volume fraction\n",
    "        ax.plot(depths / 1e3, V, label=label, color=color)\n",
    "\n",
    "    # Configure plot\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Depth (km)\")\n",
    "    ax.set_ylabel(\"Transformed Volume Fraction\")\n",
    "    ax.set_title(\"Intracrystalline nucleation\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 7: Grain size evolution and viscosity calculation\n",
    "\n",
    "#### Key Steps\n",
    "\n",
    "1. **Viscosity Calculation**:\n",
    "   - The flow law from *Kubo et al., 2008* is used to compute viscosity:\n",
    "     $$\n",
    "     \\eta = \\eta_0 \\exp\\left(\\frac{T_0 - T}{a} + \\frac{z}{b} - \\left(\\frac{z}{c}\\right)^2\\right)\n",
    "     $$\n",
    "     - Parameters:\n",
    "       - $T$: Temperature (K).\n",
    "       - $z$: Depth (m).\n",
    "       - $\\eta_0$, reference viscosity.\n",
    "       - $T_0 = 1873.15 \\, \\text{K}$, reference temperature.\n",
    "       - $a = 131.3 \\, \\text{K}$, $b = 150 \\, \\text{km}$, $c = 1086 \\, \\text{km}$.\n",
    "\n",
    "2. **Grain Size Profiles**:\n",
    "   - Initial grain sizes:\n",
    "     - Olivine: $d_{a0} = 5 \\, \\text{mm}$.\n",
    "     - Wadleyite: $d_{b0} = 0.1 \\, \\text{mm}$.\n",
    "   - Grain size evolution is based on the transformed volume fraction $V$:\n",
    "     $$\n",
    "     V = 1 - \\exp(-2.0 \\cdot S \\cdot \\text{integral})\n",
    "     $$\n",
    "     - $S = \\frac{3.35}{d_{a0}}$: Surface area per unit volume (1/m).\n",
    "     - The integral accumulates growth rates over time.\n",
    "\n",
    "3. **Switching Conditions**:\n",
    "   - Grain size switches from olivine to wadleyite when $V > 0.5$.\n",
    "\n",
    "#### Constants and Assumptions\n",
    "\n",
    "- **Depth Range**: 400 km to 700 km.\n",
    "- **Water Concentration**: $C_{OH} = 500 \\, \\text{wt.ppm}$.\n",
    "- **Subduction Velocity**: $v_{\\text{sub}} = 0.095 \\, \\text{m/s}$.\n",
    "\n",
    "#### Additional Notes\n",
    "\n",
    "* Current state: I failed to reproduce the grain size evolution. I assumed the grain size to be the integration of growth rate, this might cause the problem. It might also be the case there is something wrong in the grain growth mechanism.\n",
    "* For the viscosity, they used the Peierls creep in Karato et al., 2001 and Diffusion creep in Frost and Ashby, I didn't go further into these references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 7\n",
    "def flow_law_Kubo_2008(T, z):\n",
    "    \"\"\"\n",
    "    Compute viscosity using the flow law from Kubo et al. 2008.\n",
    "\n",
    "    Parameters:\n",
    "    - T (float): Temperature (K).\n",
    "    - z (float): Depth (m).\n",
    "\n",
    "    Returns:\n",
    "    - float: Viscosity (Pa·s).\n",
    "    \"\"\"\n",
    "    # Constants for the flow law\n",
    "    a = 131.3  # Temperature scaling factor (K)\n",
    "    b = 150.0e3  # Depth linear term (m)\n",
    "    c = 1086e3  # Depth quadratic term (m)\n",
    "    T0 = 1600 + 273.15  # Reference temperature (K)\n",
    "    eta0 = 1e-19  # Reference viscosity (Pa·s)\n",
    "\n",
    "    # Calculate viscosity\n",
    "    eta = eta0 * np.exp((T0 - T) / a + z / b - (z / c)**2.0)\n",
    "\n",
    "    return eta\n",
    "\n",
    "if reproduce_Kubo_2009:\n",
    "\n",
    "    # Initial parameters\n",
    "    da0 = 5e-3  # Initial grain size for olivine (m)\n",
    "    db0 = 1e-7  # Initial grain size for wadleyite (m)\n",
    "    Coh = 500  # Water concentration (wt.ppm H2O)\n",
    "\n",
    "    # Define depth, temperature, and pressure profiles\n",
    "    depths = np.arange(depth0, 700e3, 1e3)  # Depths from 400 to 700 km (m)\n",
    "    ts = (depths - depth0) / v_sub  # Subduction time to each depth (s)\n",
    "    Ts = T_interp(depths / 1e3) + 273.15  # Temperature interpolated and converted to K\n",
    "    Ps = (depths - 410e3) * dPdh + PT410[\"P\"]  # Pressure profile (Pa)\n",
    "\n",
    "    # Equilibrium pressure and corresponding depths\n",
    "    Ps_eq = (Ts - PT410[\"T\"]) * PT410[\"cl\"] + PT410[\"P\"]  # Equilibrium pressure (Pa)\n",
    "\n",
    "    # Initial grain size profile\n",
    "    ds = np.full(depths.size, da0)  # Start with constant grain size (m)\n",
    "\n",
    "    # Calculate growth rates under metastable conditions\n",
    "    growth_rates = growth_rate_metastable(Ps, Ps_eq, Ts, Coh)\n",
    "\n",
    "    # Compute cumulative integral of growth rates over time\n",
    "    integral = np.zeros(depths.shape)  # Initialize integral\n",
    "    integral[1:] = cumtrapz(growth_rates, ts)  # Cumulative integral\n",
    "\n",
    "    # Calculate transformed volume fraction\n",
    "    S = 3.35 / da0  # Surface area per unit volume (1/m)\n",
    "    V = 1 - np.exp(-2.0 * S * integral)  # Transformed volume fraction\n",
    "\n",
    "    # Update grain size profile\n",
    "    db = db0 + integral  # Wadleyite grain size evolution (m)\n",
    "\n",
    "    # Switch grain size based on transformed volume fraction\n",
    "    mask = (V > 0.5)  # Condition where transformed fraction exceeds 50%\n",
    "    ds[mask] = db[mask]  # Update grain size for transformed regions\n",
    "\n",
    "    # Create a figure for grain size plots\n",
    "    fig = plt.figure(tight_layout=True, figsize=(5, 10))\n",
    "    gs = gridspec.GridSpec(2, 1)\n",
    "\n",
    "    # ---- Plot 1: Grain Size vs Depth ----\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    ax.semilogy(depths / 1e3, ds / 1e-6, label=\"grain size (olivine)\")  # Grain size (micron)\n",
    "    ax.semilogy(depths / 1e3, db / 1e-6, label=\"grain size (wadleyite)\")  # Wadleyite grain size (micron)\n",
    "\n",
    "    # Configure plot\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Depth (km)\")\n",
    "    ax.set_ylabel(\"Grain size (micron)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tetzlaff & Schmeling 09\n",
    "\n",
    "### Import their temperature profile in figure 1\n",
    "\n",
    "Here I only plot their curves with no latent heat effects\n",
    "\n",
    "### Check the value of their growth rate\n",
    "\n",
    "Note using their documented values results in a growth rate too low (compared to the same plot in the Hosoya paper). This would in turn result in a 0 fraction of wb contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "def Tprofile_TS09_fig1_warm(depths):\n",
    "\n",
    "    depth0 = 370.28496710020283e3; T0 = 684.1150723737485 + 273.15 # m, K\n",
    "    depth1 = 698.9440717961519e3; T1 = 912.82119751198 + 273.15 # m, K\n",
    "\n",
    "    Ts = (depths - depth0) / (depth1 - depth0) * T1 + (depths - depth1) / (depth0 - depth1) * T0\n",
    "\n",
    "    return Ts\n",
    "\n",
    "def Tprofile_TS09_fig1_cold(depths):\n",
    "\n",
    "    depth0 = 352.5238657769547e3; T0 = 472.0332858291416 + 273.15 # m, K\n",
    "    depth1 = 694.6273339699476e3; T1 = 711.0368878272202 + 273.15 # m, K\n",
    "\n",
    "    Ts = (depths - depth0) / (depth1 - depth0) * T1 + (depths - depth1) / (depth0 - depth1) * T0\n",
    "\n",
    "    return Ts\n",
    "\n",
    "def growth_rate_tetzlaff_schmeling_09(Ts, Ps, depths, depth_eq):\n",
    "\n",
    "    R = 8.31446  # J / mol*K, universal gas constant\n",
    "    k0 = 2005.0\n",
    "    # k0 = 20**5.0\n",
    "    dHa = 350e3 # j / mol\n",
    "    Va = 1.3e-5 # m^3 / mol\n",
    "    Lz = 0.5393\n",
    "    dGr = Lz * (depths - depth_eq) # consistent with their enthalpy calculation\n",
    "    growth_rate = k0 * Ts * np.exp(-(dHa + Ps * Va) / R / Ts) * (1 - np.exp(-dGr / R / Ts))\n",
    "\n",
    "    return growth_rate\n",
    "\n",
    "\n",
    "    \n",
    "def TS09_check():\n",
    "    \n",
    "    R = 8.31446  # J / mol*K, universal gas constant\n",
    "    dPdh = 30e6/1e3 # Pa/m\n",
    "\n",
    "    # Visualization of growth rate variations\n",
    "    fig = plt.figure(tight_layout=True, figsize=(15, 5))\n",
    "    gs = gridspec.GridSpec(1, 3)\n",
    "\n",
    "    # Plot growth rate vs Pressure\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    T = 900 + 273.15  # Temperature in Kelvin\n",
    "    Ps = np.arange(13e9, 16e9, 0.1e9)  # Pressure range in Pascals\n",
    "    depths = (Ps - PT410[\"P\"]) / dPdh + 410e3\n",
    "    depths_eq = 410e3 + (T - PT410[\"T\"]) * PT410[\"cl\"] / dPdh\n",
    "    \n",
    "    Lz = 0.5393\n",
    "    dGr = Lz * (depths - depths_eq) # consistent with their enthalpy calculation\n",
    "    growth_rate = growth_rate_tetzlaff_schmeling_09(T, Ps, depths, depths_eq)\n",
    "    # Coh = 1000.0  # Concentration of water in wt.ppm H2O\n",
    "    ax.plot(Ps / 1e9, np.log(growth_rate/(T*(1-np.exp(-dGr/R/T)))))  # Pressure in GPa\n",
    "    ax.grid()\n",
    "    ax.set_xlim([13.0, 16.0])\n",
    "    # ax.set_ylim([-34.0, -22.0])\n",
    "    ax.set_xlabel(\"Pressure (GPa)\")\n",
    "    ax.set_ylabel(\"ln(growth_rate/T[1-exp(-dGr/RT)])\")\n",
    "\n",
    "    # # Plot growth rate vs Temperature\n",
    "    # ax = fig.add_subplot(gs[0, 1])\n",
    "    # T_invert = np.arange(0.7, 1.1, 0.01)  # 1000/T range\n",
    "    # Ts = 1000.0 / T_invert  # Temperature in Kelvin\n",
    "    # P = 15e9  # Pressure in Pascals\n",
    "    # Coh = 1000.0  # Concentration of water in wt.ppm H2O\n",
    "    # growth_rate_part = growth_rate_P1(P, Ts, Coh)\n",
    "    # ax.plot(T_invert, np.log(growth_rate_part))\n",
    "    # ax.grid()\n",
    "    # ax.set_xlim([0.7, 1.1])\n",
    "    # ax.set_ylim([-34.0, -22.0])\n",
    "    # ax.set_xlabel(\"1000/T (K)\")\n",
    "\n",
    "    # # Plot growth rate vs OH content\n",
    "    # ax = fig.add_subplot(gs[0, 2])\n",
    "    # T = 900 + 273.15  # Temperature in Kelvin\n",
    "    # P = 15e9  # Pressure in Pascals\n",
    "    # log10_Cohs = np.arange(2, 4, 0.05)  # Logarithmic OH content range\n",
    "    # Cohs = 10**log10_Cohs  # OH content in wt.ppm H2O\n",
    "    # growth_rate_part = growth_rate_P1(P, T, Cohs)\n",
    "    # ax.semilogx(Cohs, np.log(growth_rate_part))\n",
    "    # ax.grid()\n",
    "    # ax.set_xlim([10**2, 10**4])\n",
    "    # ax.set_ylim([-34.0, -22.0])\n",
    "    # ax.set_xlabel(\"OH content (wt. ppm H2O)\")\n",
    "\n",
    "\n",
    "TS09_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_depths = np.arange(300e3, 700e3, 1e3)\n",
    "\n",
    "q_Ts_warm = Tprofile_TS09_fig1_warm(q_depths)\n",
    "q_Ts_cold = Tprofile_TS09_fig1_cold(q_depths)\n",
    "\n",
    "fig = plt.figure(tight_layout=True, figsize=(5, 10))\n",
    "gs = gridspec.GridSpec(2, 1)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "ax.plot(q_depths/1e3, q_Ts_cold - 273.15)\n",
    "ax.plot(q_depths/1e3, q_Ts_warm - 273.15)\n",
    "\n",
    "ax.set_xlim([350, 700])\n",
    "ax.set_ylim([450, 1000])\n",
    "\n",
    "ax.set_xlabel(\"Depth (km)\")\n",
    "ax.set_ylabel(\"Temperature (C)\")\n",
    "\n",
    "ax.grid()\n",
    "\n",
    "\n",
    "# calculate MO kinetics\n",
    "# Parameters for equilibrium at the 410 km depth phase boundary\n",
    "dPdh = 30e6/1e3 # Pa/m\n",
    "d_ol = 5e-3 # m\n",
    "    \n",
    "# Equilibrium pressure and corresponding depths\n",
    "v_h = 0.05/year # m / s\n",
    "\n",
    "q_ts = q_depths / v_h\n",
    "q_Ps = (q_depths - 410e3)*dPdh + PT410[\"P\"]\n",
    "q_depths_eq_cold = 410e3 + (q_Ts_cold - PT410[\"T\"]) * PT410[\"cl\"] / dPdh  # Equilibrium depth (m)\n",
    "\n",
    "q_growth_rate_cold = growth_rate_tetzlaff_schmeling_09(q_Ts_cold, q_Ps, q_depths, q_depths_eq_cold)\n",
    "V_cold = MO_Vfraction_classic(q_growth_rate_cold, q_ts, d_ol)\n",
    "\n",
    "# Plot the wd contents\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "ax1.plot(q_depths/1e3, V_cold)\n",
    "ax1.set_xlim([350, 700])\n",
    "ax1.set_ylim([0.0, 1.0])\n",
    "\n",
    "ax1.grid()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kinetics from DaBler etal., 1996 and used in Yoshioka etal., 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nucleation Theory\n",
    "\n",
    "(Supplementary Material: Put the final equation and the formula of $\\Delta G_{c}$ here)\n",
    "\n",
    "The nucleation rate is expressed as:\n",
    "\n",
    "$$\n",
    "I = K_0 T \\exp\\left(-\\frac{\\Delta H_a + P V^*}{RT}\\right) \\exp\\left(-\\frac{\\Delta G^*}{kT} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "K_0 = \\frac{N k}{h} = \\frac{1.75 \\times 10^{28} \\times 1.38 \\times 10^{-23}}{6.626 \\times 10^{-34}} \\approx 3.65 \\times 10^{38}~\\mathrm{K \\cdot s^{-1} \\cdot m^{-3}}\n",
    "$$\n",
    "\n",
    "The critical Gibbs free energy $\\Delta G^*$  varied by assumptions of homogenous nucleation and heterogenous nucleation:$\\Delta G_{c}$ is the change in total Gibbs free energy for homogeneous nucleation:\n",
    "\n",
    "$$\n",
    "\\Delta G_{hom}^* = \\dfrac{16\\pi^2 \\gamma^3V_m^2}{3\\left(\\Delta G_d + \\epsilon\\right)^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta G_{het}^* = f_s \\Delta G_{hom}^*\n",
    "$$\n",
    "\n",
    "where $\\gamma$ is the surface energy from forming the spinel structure from olivine. $V_m$ is the molar volume of spinel, and $f_s$ is a shape factor decreasing the value of the critical free energy change from the homogenous value when heterogenous nucleation effectively wets the grain boundary and lowers the total amount of surface energy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, we import this function from the metastable.py script\n",
    "# Add the origina function here\n",
    "\n",
    "# def nucleation_rate(P, T, P_eq):\n",
    "#     \"\"\"\n",
    "#     Compute the nucleation rate using Equation (10) from Yoshioka et al. (2015).\n",
    "    \n",
    "#     Parameters:\n",
    "#     - T (float): Temperature in Kelvin.\n",
    "#     - P (float): Pressure in Pa\n",
    "#     - delta_G_v (float): Free energy change per volume in J/m^3.\n",
    "\n",
    "#     Constants\n",
    "#     - gamma (float): Surface energy in J/m^2 (default: 0.0506).\n",
    "#     - K0 (float): Pre-exponential factor in s^-1 m^-2 K^-1 (default: 3.54e38).\n",
    "#     - Q_a (float): Activation energy for growth in J/mol (default: 355e3).\n",
    "#     - k (float): Boltzmann constant in J/K (default: 1.38e-23).\n",
    "#     - R (float): Universal gas constant in J/(mol*K) (default: 8.314).\n",
    "#     - dV_ol_wd (float): difference in mole volume between phase.\n",
    "#     - V_initial (float): for olivine, estimation at 410 km, mole volume\n",
    "    \n",
    "#     Returns:\n",
    "#     - I (float): Nucleation rate in s^-1 m^-2.\n",
    "#     \"\"\"\n",
    "#     gamma=0.0506; K0=3.54e38; dH_a=344e3; V_star=4e-6; k=1.38e-23; R=8.314\n",
    "#     dV_ol_wd = 2.4e-6; V_initial = 35.17e-6\n",
    "\n",
    "#     if type(P) in [float, np.float64]:\n",
    "#         assert(P >= P_eq)\n",
    "#     elif type(P) == np.ndarray:\n",
    "#         assert(np.min(P - P_eq) >= 0.0)\n",
    "#     else:\n",
    "#         raise TypeError(\"P must be float or ndarray\")\n",
    "\n",
    "#     delta_G_v = dV_ol_wd / V_initial * (P - P_eq)\n",
    "\n",
    "#     # print(\"P_eq = %.2f GPa, dGr_vs = %.4e\" % (P_eq/1e9, delta_G_v)) # debug\n",
    "\n",
    "#     # Compute the homogeneous nucleation activation energy\n",
    "#     delta_G_hom = (16 * np.pi * gamma**3) / (3 * (delta_G_v)**2)\n",
    "    \n",
    "#     # Compute the nucleation rate\n",
    "#     Q_a = dH_a + P * V_star \n",
    "#     I = K0 * T * np.exp(-delta_G_hom / (k * T)) * np.exp(-Q_a / (R * T))\n",
    "    \n",
    "#     return I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site saturation\n",
    "\n",
    "(Supplementary Material: Put the equation of site saturation and the nondimensionalize number for time here)\n",
    "\n",
    "The time of site saturation is defined as:\n",
    "$$t_s =  \\left(I_s(P, T) Y(P, T)^2 \\right)^{-1/3} = \\left(\\frac{I_v(P, T) Y(P, T)^2}{S_0} \\right)^{-1/3}$$\n",
    "Before site saturation ($t < t_s$), both nucleation and grain growth contribute to the transformation kinetics. After site saturation ($t > t_s$), nucleation becomes ineffective.\n",
    "\n",
    "Additionally, time is nondimensionalized as:\n",
    "$$t = \\frac{L^2}{\\kappa} \\tau$$\n",
    "where $L$ is a characteristic length scale (taken as 100~km) and $\\kappa$ is the thermal diffusivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_sigma_s(I_PT, Y_PT, d_0, **kwargs):\n",
    "#     \"\"\"\n",
    "#     Calculate the dimensionless time (sigma_s) for the phase transformation process.\n",
    "\n",
    "#     Parameters:\n",
    "#     - I_PT (float): Nucleation rate as a function of pressure and temperature (s^-1 m^-3).\n",
    "#     - Y_PT (float): Growth rate as a function of pressure and temperature (m/s).\n",
    "#     - d_0 (float): Grain size of olivine (m).\n",
    "\n",
    "#     Returns:\n",
    "#     - sigma_s (float): Dimensionless time for site saturation.\n",
    "#     \"\"\"\n",
    "#     kappa = kwargs.get(\"kappa\", 1e-6) # Thermal diffusivity (m^2/s).\n",
    "#     D = kwargs.get(\"D\", 100e3) # slab thickness\n",
    "#     # Compute the dimensionless time\n",
    "#     sigma_s = (kappa / D**2) * ((I_PT * Y_PT**2 * d_0) / 6.7)**(-1/3)\n",
    "#     return sigma_s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation (19): Avrami Number Calculation\n",
    "\n",
    "We follow by defining the Avrami number as\n",
    "\n",
    "$$\n",
    "Av = \\left(\\frac{D^2}{\\kappa}\\right)^4 \\cdot I_{max}(P, T) Y_{max}^3(P, T)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_avrami_number(I_max, Y_max, **kwargs):\n",
    "#     \"\"\"\n",
    "#     Calculate the Avrami number (Av) using the corrected Equation (19).\n",
    "    \n",
    "#     Parameters:\n",
    "#     - I_max (float): Maximum nucleation rate in s^-1 m^-2.\n",
    "#     - Y_max (float): Maximum growth rate in m/s.\n",
    "    \n",
    "#     Returns:\n",
    "#     - Av (float): Avrami number (dimensionless).\n",
    "#     \"\"\"\n",
    "#     kappa = kwargs.get(\"kappa\", 1e-6) # Thermal diffusivity (m^2/s).\n",
    "#     D = kwargs.get(\"D\", 100e3) # slab thickness\n",
    "#     # Compute the Avrami number\n",
    "#     Av = (D**2 / kappa)**4 * I_max * Y_max**3\n",
    "#     return Av"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinetic equations\n",
    "\n",
    "(Supplementary Material: put the extended volume fraction and the kinetic equations here; screenshot a non-dimensional equation.)\n",
    "\n",
    "In this system, new grains nucleate at the surface of existing grains and grow kinetically.\n",
    "This leads to an increase in the so-called extended volume fraction $\\tilde{V}$, which assumes no overlap between grains.\n",
    "The true volume fraction $V$ is related to $\\tilde{V}$ through the transformation (Avrami,1941):\n",
    "$$\n",
    "V = 1 - \\exp\\left(-\\tilde{V}\\right)\n",
    "$$\n",
    "$$\n",
    "\\frac{d\\tilde{V}}{dt} = 4 S Y(t), \\qquad t < t_s\n",
    "$$\n",
    "$$\n",
    "\\frac{dS}{dt} = \\pi D Y(t)\n",
    "$$\n",
    "$$\n",
    "\\frac{dD}{dt} = 2 N Y(t)\n",
    "$$\n",
    "$$\n",
    "\\frac{dN}{dt} = I_v\n",
    "$$\n",
    "\n",
    "After site saturation ($t > t_s$), nucleation becomes ineffective, and the extended volume fraction evolves according to:\n",
    "$$\n",
    "\\frac{d\\tilde{V}}{dt} = S_0 Y(P, T)\n",
    "$$\n",
    "\n",
    "where $S$ is the total grain area per unit volume, $D$ is the total grain size per unit volume, and $N$ is the number of new grains per unit volume.\n",
    "\n",
    "![](./figure/nondimensional_1.png)\n",
    "\n",
    "Where:\n",
    "- \\(X_3(s)\\), \\(X_2(s)\\), \\(X_1(s)\\), \\(X_0(s)\\): Represent the total grain volume, total grain area, total grain diameter, and number of grains, respectively.\n",
    "- \\(Av\\): Avrami number, defined as $Av = \\frac{D^2}{j} \\cdot I_{max}(P, T) Y_{max}^3(P, T)$.\n",
    "- \\(Y'(s)\\): Dimensionless growth rate.\n",
    "- \\(I'(s)\\): Dimensionless nucleation rate.\n",
    "\n",
    "Note\n",
    "- I use the name \"X_array\" for the original array of [$\\tilde{V}$, S, D, N], and the name \"X_array_nd\" for the nondimensionalized array \". This usage is consistent managed in all the code blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the summary of nucleation rate, growth rate and saturation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_analysis = False\n",
    "\n",
    "if plot_analysis:\n",
    "\n",
    "    # parameters for kinetics \n",
    "    nucleation_type = 1 # 0 - volumetric; 1 - interface\n",
    "    d0 = 1e-2 # m, grain size\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "    # initiate the kinetics class \n",
    "    _constants, _ = Meta.get_kinetic_constants(nucleation_type)\n",
    "    pTKinetics = Meta.PTKinetics(_constants)\n",
    "\n",
    "    # directory to save results\n",
    "    o_dir = os.path.join(root_path, results_dir, \"plot_analysis\")\n",
    "\n",
    "    if not os.path.isdir(o_dir):\n",
    "        os.mkdir(o_dir)\n",
    "    \n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 2.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (11.0, 16.0)\n",
    "    x_lim3 = (0.4, 1.1)\n",
    "    x_lim5 = (2.0, 4.0)\n",
    "    x_tick_interval = 1.0   # tick interval along x\n",
    "    x_tick_interval3 = 0.1   # tick interval along x\n",
    "    x_tick_interval5 = 0.5\n",
    "    y_lim = (-20.0, 30.0)\n",
    "    y_lim2 = (-15.0, -5.0)\n",
    "    y_lim3 = (-20.0, 30.0)\n",
    "    y_lim4 = (-15.0, -5.0)\n",
    "    y_lim5 = (-20.0, 30.0)\n",
    "    y_lim6 = (-15.0, -5.0)\n",
    "    y_tick_interval = 5.0  # tick interval along y\n",
    "    y_tick_interval2 = 1.0  # tick interval along y\n",
    "    y_tick_interval3 = 5.0\n",
    "    y_tick_interval4 = 1.0\n",
    "    y_tick_interval5 = 5.0\n",
    "    y_tick_interval6 = 1.0\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # Constants:\n",
    "    #   T: constant temperature in rates vs P plot\n",
    "    #   P: constant pressure in rates vs T plot\n",
    "    #   Coh: constant Coh\n",
    "    # T = 9.8426e+02; P = 1.1053e10\n",
    "    T = 1173.2; P = 14.0e9\n",
    "    Coh = 150.0  # Concentration of water in wt.ppm H2O\n",
    "\n",
    "    kappa = 1e-6 # m^2/s\n",
    "    D = 100e3 # m\n",
    "    d0 = 0.01 # m, grain size of olivine, assume this to convert to volumetric rate.\n",
    "\n",
    "    # Visualization of growth rate variations\n",
    "    fig, axes = plt.subplots(1, 3, tight_layout=True, figsize=(3*8*scaling_factor, 6*scaling_factor))\n",
    "\n",
    "    # Plot nondimentional time vs Pressure\n",
    "    ax1 = axes[0]\n",
    "\n",
    "    Ps = np.arange(10e9, 17e9, 0.1e9)  # Pressure range in Pascals\n",
    "    Ts = np.full(Ps.shape, T)\n",
    "    Ps_eq = PT410[\"P\"] + (Ts - PT410[\"T\"])*PT410[\"cl\"]\n",
    "    Ts_eq = PT410[\"T\"] + (Ps - PT410[\"P\"])/PT410[\"cl\"]\n",
    "    # Ps_eq = np.full(Ps.shape, PT410[\"P\"])\n",
    "\n",
    "    nucleation_rate = np.zeros(Ps.shape) # derive nucleation rate\n",
    "    mask = Ps > Ps_eq\n",
    "\n",
    "    if pTKinetics.nucleation_type == 0:\n",
    "        nucleation_rate[mask] = pTKinetics.nucleation_rate(Ps[mask], Ts[mask], Ps_eq[mask], Ts_eq[mask])\n",
    "    elif pTKinetics.nucleation_type == 1:\n",
    "        nucleation_rate[mask] = 6.7/d0 * pTKinetics.nucleation_rate(Ps[mask], Ts[mask], Ps_eq[mask], Ts_eq[mask])\n",
    "    else:\n",
    "        raise NotImplementedError(\"Value of nucleation type needs to be 0 or 1.\")\n",
    "\n",
    "    growth_rate = np.zeros(Ps.shape)\n",
    "    growth_rate[mask] = pTKinetics.growth_rate(Ps[mask], Ts[mask], Ps_eq[mask], Ts_eq[mask], Coh)  # calculate growth rate\n",
    "\n",
    "    sigma_s = Meta.calculate_sigma_s(nucleation_rate, growth_rate, d0)\n",
    "\n",
    "    ax1.plot(Ps / 1e9, np.log10(nucleation_rate), label=\"Nucleation Rate\", color=default_colors[0]) # Plot nucleation rate on ax1\n",
    "    ax1.set_xlabel(\"Pressure (GPa)\")\n",
    "    ax1.set_ylabel(r\"log10($I_v$) ($m^{-3}s^{-1}$)\", color=default_colors[0])\n",
    "    ax1.tick_params(axis='y', labelcolor=default_colors[0])\n",
    "    ax1.set_xlim(x_lim)\n",
    "    ax1.set_ylim(y_lim)\n",
    "\n",
    "    P_eq = PT410[\"P\"] + (T - PT410[\"T\"])*PT410[\"cl\"]\n",
    "    ax1.axvline(x=P_eq / 1e9, color=\"black\", linestyle=\"--\", label=r\"$P_{410}$\") # Add a vertical line at PT410[\"P\"]\n",
    "\n",
    "    ax2 = ax1.twinx() # Create a secondary x-axis for growth rate\n",
    "    ax2.plot(Ps / 1e9, np.log10(growth_rate), label=\"Growth Rate (log)\", color=default_colors[1])\n",
    "    ax2.set_ylabel(\"log10(Y) (m/s)\", color=default_colors[1])\n",
    "    ax2.tick_params(axis='y', labelcolor=default_colors[1])\n",
    "    ax2.set_ylim(y_lim2)\n",
    "\n",
    "    ax1.set_title(\"T = %.1f K, Coh = %.1f ppm\" % (T, Coh))\n",
    "\n",
    "    ax1.grid()\n",
    "    \n",
    "\n",
    "    # Plot rates vs T\n",
    "    ax3 = axes[1]\n",
    "    \n",
    "    T_invert = np.arange(0.4, 1.1, 0.01)  # 1000/T range\n",
    "    Ts_1 = 1000.0 / T_invert  # Temperature in Kelvin\n",
    "    P_array = np.ones(Ts_1.shape) * P # make an array before passing to function\n",
    "    \n",
    "    Ps_eq_1 = PT410[\"P\"] + (Ts_1 - PT410[\"T\"])*PT410[\"cl\"]\n",
    "    Ts_eq_1 = PT410[\"T\"] + (P_array - PT410[\"P\"])/PT410[\"cl\"]\n",
    "\n",
    "    nucleation_rate_1 = np.zeros(Ts_1.shape)\n",
    "\n",
    "    mask = (P_array > Ps_eq_1) # compute mask before passing to function\n",
    "\n",
    "    if pTKinetics.nucleation_type == 0:\n",
    "        nucleation_rate_1[mask] = pTKinetics.nucleation_rate(P_array[mask], Ts_1[mask], Ps_eq_1[mask], Ts_eq_1[mask])\n",
    "    elif pTKinetics.nucleation_type == 1:\n",
    "        nucleation_rate_1[mask] = 6.7/d0 * pTKinetics.nucleation_rate(P_array[mask], Ts_1[mask], Ps_eq_1[mask], Ts_eq_1[mask])\n",
    "    else:\n",
    "        raise NotImplementedError(\"Value of nucleation type needs to be 0 or 1.\")\n",
    "    \n",
    "    ax3.plot(T_invert, np.log10(nucleation_rate_1), color=default_colors[0])\n",
    "    ax3.set_xlim(x_lim3)\n",
    "    ax3.set_ylim(y_lim3)\n",
    "    ax3.set_xlabel(\"1000/T (K)\")\n",
    "    ax3.set_ylabel(r\"log10($I_v$) ($m^{-3}s^{-1}$)\", color=default_colors[0])\n",
    "    ax3.tick_params(axis='y', labelcolor=default_colors[0])\n",
    "\n",
    "    # ax3.set_ylim(y_lim3)\n",
    "\n",
    "    T_eq_1 = PT410[\"T\"] + (P - PT410[\"P\"])/PT410[\"cl\"]\n",
    "    ax3.axvline(x=1000.0 / T_eq_1, color=\"black\", linestyle=\"--\", label=r\"$T_{410}$\") # Add a vertical line at PT410[\"P\"]\n",
    "\n",
    "    ax4 = ax3.twinx() # Plot growth rate vs Temperature\n",
    "    \n",
    "    growth_rate_1 = np.zeros(Ts_1.shape)\n",
    "    growth_rate_1[mask] = pTKinetics.growth_rate(P_array[mask], Ts_1[mask], Ps_eq_1[mask], Ts_eq_1[mask], Coh)\n",
    "    ax4.plot(T_invert, np.log10(growth_rate_1), color=default_colors[1])\n",
    "    ax4.set_ylabel(\"log10(Y) (m/s)\", color=default_colors[1])\n",
    "    ax4.set_ylim(y_lim4)\n",
    "    ax4.tick_params(axis='y', labelcolor=default_colors[1])\n",
    "    \n",
    "    ax3.grid()\n",
    "\n",
    "    ax3.set_title(\"P = %.2f GPa, Coh = %.1f ppm\" % (P/1e9, Coh))\n",
    "\n",
    "    # Plot rates vs Coh\n",
    "    ax5 = axes[2]\n",
    "    \n",
    "    log10_Cohs = np.arange(2, 4, 0.05)  # Logarithmic OH content range\n",
    "    Cohs = 10**log10_Cohs  # OH content in wt.ppm H2O\n",
    "\n",
    "    Ts_2 = np.full(Cohs.shape, T)\n",
    "    Ps_2 = np.full(Cohs.shape, P)\n",
    "    Ps_eq_2 = np.full(Cohs.shape, PT410[\"P\"] + (T - PT410[\"T\"])*PT410[\"cl\"]) \n",
    "    Ts_eq_2 = np.full(Cohs.shape, PT410[\"T\"] + (P - PT410[\"P\"])/PT410[\"cl\"])\n",
    "    \n",
    "    growth_rate_2 = pTKinetics.growth_rate(Ps_2, Ts_2, Ps_eq_2, Ts_eq_2, Cohs)\n",
    "\n",
    "    if pTKinetics.nucleation_type == 0:\n",
    "        nucleation_rate_2 = pTKinetics.nucleation_rate(Ps_2, Ts_2, Ps_eq_2, Ts_eq_2)\n",
    "    elif pTKinetics.nucleation_type == 1:\n",
    "        nucleation_rate_2 = 6.7/d0 * pTKinetics.nucleation_rate(Ps_2, Ts_2, Ps_eq_2, Ts_eq_2)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Value of nucleation type needs to be 0 or 1.\")\n",
    "\n",
    "    # print(\"nucleation_rate_2: \", nucleation_rate_2) # debug\n",
    "    \n",
    "    ax5.plot(np.log10(Cohs), np.log10(nucleation_rate_2), color=default_colors[0])\n",
    "    ax5.set_xlim(x_lim5)\n",
    "    ax5.set_ylim(y_lim5)\n",
    "    ax5.set_xlabel(r\"log10($C_{OH}$) (ppm H / Si)\") \n",
    "    ax5.set_ylabel(r\"log10($I_v$) ($m^{-3}s^{-1}$)\", color=default_colors[0])\n",
    "    ax5.tick_params(axis='y', labelcolor=default_colors[0])\n",
    "    \n",
    "    ax6 = ax5.twinx() # Plot growth rate vs Temperature\n",
    "    ax6.plot(np.log10(Cohs), np.log10(growth_rate_2), color=default_colors[1])\n",
    "    ax6.set_ylabel(r\"log10(Y) (m/s)\", color=default_colors[1])\n",
    "    ax6.tick_params(axis='y', labelcolor=default_colors[1])\n",
    "    ax6.set_ylim(y_lim6)\n",
    "\n",
    "    ax5.set_title(\"T = %.1f K, P = %.2f GPa\" % (T, P/1e9))\n",
    "\n",
    "    ax1.xaxis.set_major_locator(MultipleLocator(x_tick_interval)) # set ticks\n",
    "    ax1.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax1.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax1.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax2.yaxis.set_major_locator(MultipleLocator(y_tick_interval2))\n",
    "    ax2.yaxis.set_minor_locator(MultipleLocator(y_tick_interval2/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax3.xaxis.set_major_locator(MultipleLocator(x_tick_interval3))\n",
    "    ax3.xaxis.set_minor_locator(MultipleLocator(x_tick_interval3/(n_minor_ticks+1)))\n",
    "    ax3.yaxis.set_major_locator(MultipleLocator(y_tick_interval3))\n",
    "    ax3.yaxis.set_minor_locator(MultipleLocator(y_tick_interval3/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax4.yaxis.set_major_locator(MultipleLocator(y_tick_interval4))\n",
    "    ax4.yaxis.set_minor_locator(MultipleLocator(y_tick_interval4/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax5.xaxis.set_major_locator(MultipleLocator(x_tick_interval5)) # set ticks\n",
    "    ax5.xaxis.set_minor_locator(MultipleLocator(x_tick_interval5/(n_minor_ticks+1)))\n",
    "    ax5.yaxis.set_major_locator(MultipleLocator(y_tick_interval5))\n",
    "    ax5.yaxis.set_minor_locator(MultipleLocator(y_tick_interval5/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax6.yaxis.set_major_locator(MultipleLocator(y_tick_interval6))\n",
    "    ax6.yaxis.set_minor_locator(MultipleLocator(y_tick_interval6/(n_minor_ticks+1)))\n",
    "\n",
    "    ax5.grid()\n",
    "\n",
    "    for spine in ax.spines.values(): \n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    \n",
    "    # save outputs\n",
    "    file_out = os.path.join(o_dir, \"Yoshioka_2015_rates_P_%.1fGPa_T_%.1fK_Coh_%.1f_nu_%d.pdf\" % (P/1e9, T, Coh, pTKinetics.nucleation_type))\n",
    "    fig.savefig(file_out)\n",
    "    print(\"Saved figure: %s\" % file_out)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_analysis:\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 2.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    \n",
    "    x_lim = (11.0, 16.0)\n",
    "    x_lim3 = (0.5, 1.1)\n",
    "    x_lim5 = (2.0, 4.0)\n",
    "    y_lim = (-20.0, 20.0)\n",
    "    y_lim1_1 = (-1.0, 1.0)\n",
    "    y_lim3 = (-20.0, 20.0)\n",
    "    y_lim3_1 = (-5.0, 5.0)\n",
    "    y_lim5 = (-16.0, -11.0)\n",
    "    y_lim5_1 = (-5.0, 5.0)\n",
    "    x_tick_interval = 1.0   # tick interval along x\n",
    "    x_tick_interval3 = 0.1   # tick interval along x\n",
    "    y_tick_interval = 10.0\n",
    "    y_tick_interval1_1 = 0.5\n",
    "    y_tick_interval3 = 10.0\n",
    "    y_tick_interval3_1 = 2.5\n",
    "    y_tick_interval5 = 1.0\n",
    "    y_tick_interval5_1 = 2.5\n",
    "    \n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "\n",
    "    # initiate figure\n",
    "    fig, axes = plt.subplots(1, 3, tight_layout=True, figsize=(3*8*scaling_factor, 6*scaling_factor))\n",
    "    \n",
    "\n",
    "    # Plot nondimentional time vs Pressure\n",
    "    ax1 = axes[0] \n",
    "    ax1_1 = ax1.twinx()\n",
    "    sigma_s = Meta.calculate_sigma_s(nucleation_rate, growth_rate, d0, kappa=kappa, D=D)\n",
    "    t_g = d0 / 6.7 / growth_rate\n",
    "\n",
    "    ax1.plot(Ps / 1e9, np.log10(sigma_s*D*2.0/kappa/year), color=default_colors[0])\n",
    "    ax1_1.plot(Ps / 1e9, np.log10(t_g/year), color=default_colors[1])\n",
    "    \n",
    "    ax1.axvline(x=P_eq / 1e9, color=\"black\", linestyle=\"--\", label=r\"$P_{eq}$\") # Add a vertical line at PT410[\"P\"]\n",
    "\n",
    "    ax1.grid()\n",
    "\n",
    "    ax1.set_xlim(x_lim)\n",
    "    ax1.set_ylim(y_lim)\n",
    "    \n",
    "    # ax1_1.set_ylim(y_lim1_1)\n",
    "    \n",
    "    ax1.set_xlabel(\"Pressure (GPa)\")\n",
    "    ax1.set_ylabel(\"log (Saturation Time) (year)\", color=default_colors[0])\n",
    "    ax1_1.set_ylabel(\"log (Growth Time) (year)\", color=default_colors[1])\n",
    "\n",
    "    ax1.tick_params(axis='y', labelcolor=default_colors[0])\n",
    "    ax1_1.tick_params(axis='y', labelcolor=default_colors[1])\n",
    "\n",
    "    ax1.set_title(\"T = %.1f K, Coh = %.1f ppm\" % (T, Coh))\n",
    "    \n",
    "    \n",
    "    # Plot nondimentional time vs Temperature\n",
    "    \n",
    "    ax3 = axes[1] \n",
    "    ax3_1 = ax3.twinx()\n",
    "\n",
    "    sigma_s_1 = Meta.calculate_sigma_s(nucleation_rate_1, growth_rate_1, d0, kappa=kappa, D=D)\n",
    "    t_g_1 = d0 / 6.7 / growth_rate_1\n",
    "    \n",
    "    ax3.plot(T_invert, np.log10(sigma_s_1*D*2.0/kappa/year), color=default_colors[0])\n",
    "    ax3_1.plot(T_invert, np.log10(t_g_1/year), color=default_colors[1])\n",
    "    ax3.axvline(x=1000.0 / T_eq_1, color=\"black\", linestyle=\"--\", label=r\"$T_{eq}$\") # Add a vertical line at PT410[\"P\"]\n",
    "    \n",
    "    ax3.set_xlim(x_lim3)\n",
    "    ax3.set_ylim(y_lim3)\n",
    "    ax3_1.set_ylim(y_lim3_1)\n",
    "\n",
    "    ax3.grid()\n",
    "    \n",
    "    ax3.set_xlabel(\"1000/T (K)\")\n",
    "    ax3.set_ylabel(\"log (Saturation Time) (year)\", color=default_colors[0])\n",
    "    ax3_1.set_ylabel(\"log (Growth Time) (year)\", color=default_colors[1])\n",
    "    \n",
    "    ax3.tick_params(axis='y', labelcolor=default_colors[0])\n",
    "    ax3_1.tick_params(axis='y', labelcolor=default_colors[1])\n",
    "    \n",
    "    ax3.set_title(\"P = %.2f GPa, Coh = %.1f ppm\" % (P/1e9, Coh))\n",
    "\n",
    "    # Plot nondimentional time vs Coh\n",
    "    \n",
    "    ax5 = axes[2] \n",
    "    ax5_1 = ax5.twinx()\n",
    "    \n",
    "    sigma_s_2 = Meta.calculate_sigma_s(nucleation_rate_2, growth_rate_2, d0, kappa=kappa, D=D)\n",
    "    t_g_2 = d0 / 6.7 / growth_rate_2\n",
    "\n",
    "    ax5.plot(np.log10(Cohs), np.log10(sigma_s_2*D*2.0/kappa/year), color=default_colors[0])\n",
    "    ax5_1.plot(np.log10(Cohs), np.log10(t_g_2/year), color=default_colors[1])\n",
    "    \n",
    "    ax5.set_xlabel(\"log10(OH content) (wt. ppm H2O)\") \n",
    "    ax5.set_ylabel(\"log (Saturation Time) (year)\", color=default_colors[0])\n",
    "    ax5_1.set_ylabel(\"log (Growth Time) (year)\", color=default_colors[1])\n",
    "    \n",
    "    ax5.set_title(\"T = %.1f K, P = %.2f GPa\" % (T, P/1e9))\n",
    "    \n",
    "    ax5.set_xlim(x_lim5)\n",
    "    ax5.set_ylim(y_lim5)\n",
    "    ax5_1.set_ylim(y_lim5_1)\n",
    "    \n",
    "    ax5.tick_params(axis='y', labelcolor=default_colors[0])\n",
    "    ax5_1.tick_params(axis='y', labelcolor=default_colors[1])\n",
    "    \n",
    "    ax5.grid()\n",
    "    \n",
    "    # ax3.set_title(\"P = %.1f GPa, T = %.1f K\" % (P / 1e9, T))\n",
    "\n",
    "\n",
    "    # ax3.semilogy(Ps/1e9, sigma_s)\n",
    "    # ax3.set_xlabel(\"Pressure (GPa)\")\n",
    "    # ax3.set_ylabel(\"Nondimentional Saturation Time\")\n",
    "    # ax3.grid()\n",
    "    # ax3.set_xlim([13.0, 16.0])\n",
    "    \n",
    "    # ax3.axvline(x=PT410[\"P\"] / 1e9, color=\"black\", linestyle=\"--\", label=r\"$P_{410}$\") # Add a vertical line at PT410[\"P\"]\n",
    "\n",
    "    ax1.xaxis.set_major_locator(MultipleLocator(x_tick_interval)) # set ticks\n",
    "    ax1.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax1.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax1.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax1_1.yaxis.set_major_locator(MultipleLocator(y_tick_interval1_1))\n",
    "    ax1_1.yaxis.set_minor_locator(MultipleLocator(y_tick_interval1_1/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax3.xaxis.set_major_locator(MultipleLocator(x_tick_interval3)) # set ticks\n",
    "    ax3.xaxis.set_minor_locator(MultipleLocator(x_tick_interval3/(n_minor_ticks+1)))\n",
    "    ax3.yaxis.set_major_locator(MultipleLocator(y_tick_interval3))\n",
    "    ax3.yaxis.set_minor_locator(MultipleLocator(y_tick_interval3/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax3_1.yaxis.set_major_locator(MultipleLocator(y_tick_interval3_1))\n",
    "    ax3_1.yaxis.set_minor_locator(MultipleLocator(y_tick_interval3_1/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax5.xaxis.set_major_locator(MultipleLocator(x_tick_interval5)) # set ticks\n",
    "    ax5.xaxis.set_minor_locator(MultipleLocator(x_tick_interval5/(n_minor_ticks+1)))\n",
    "    ax5.yaxis.set_major_locator(MultipleLocator(y_tick_interval5))\n",
    "    ax5.yaxis.set_minor_locator(MultipleLocator(y_tick_interval5/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax5_1.yaxis.set_major_locator(MultipleLocator(y_tick_interval5_1))\n",
    "    ax5_1.yaxis.set_minor_locator(MultipleLocator(y_tick_interval5_1/(n_minor_ticks+1)))\n",
    "\n",
    "\n",
    "    for spine in ax.spines.values(): \n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    \n",
    "    # save outputs\n",
    "    file_out = os.path.join(o_dir, \"Yoshioka_2015_summary_P_%.1fGPa_T_%.1fK.pdf\" % (P/1e9, T))\n",
    "    fig.savefig(file_out)\n",
    "    print(\"Saved figure: %s\" % file_out)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the kinetics at specific P, T conditions\n",
    "\n",
    "All variables $X_0$, $X_1$, $X_2$, $X_3$ are advected with particles in our numerical simulation using ASPECT. The differential equations are solved with 4-th order Runge-Kutta method at every timestep to update the metastable kinetics.\n",
    "\n",
    "Here we test the solution with prescribed P, T conditions.\n",
    "\n",
    "### Solve the kinetics for a (P, T) condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tips: look at the class definiition in file hamageolib/research/haoyuan_2d_subduction/metastable.py\n",
    "is_solving_point = False\n",
    "\n",
    "if is_solving_point:\n",
    "    \n",
    "    Coh = 150.0 # ppm H2O\n",
    "    d0 = 1e-2 # m, initial grain size\n",
    "    Peq = 13.5e9\n",
    "    Teq = 1740.0\n",
    "    Cl = 2e6\n",
    "    \n",
    "    Ps = [13.5e9 for i in range(3)]\n",
    "    Ts = [873.15, 973.15, 1573.15]\n",
    "\n",
    "    nucleation_type = 1 # 0 - volumetric; 1 - surface\n",
    "\n",
    "    # initiate the kinetics class \n",
    "    _, _constants1 = Meta.get_kinetic_constants(nucleation_type)\n",
    "    Mo_Kinetics = Meta.MO_KINETICS(_constants1, post_process=[\"ts\", \"tg\"])\n",
    "    Mo_Kinetics.set_initial_grain_size(d0)\n",
    "\n",
    "    # set P T condition for solution\n",
    "    Mo_Kinetics.set_PT_eq(Peq, Teq, Cl)\n",
    "    Mo_Kinetics.link_and_set_kinetics_model(Meta.PTKinetics)\n",
    "\n",
    "    print(\"Equilirbium T at %.3f\" % Meta.compute_eq_T(PT410, Ps[0]))\n",
    "    print(\"Compute kinetics at Ts:\", Ts)\n",
    "    \n",
    "    # Parameters for solver\n",
    "    t_max = 10e6 * year # s\n",
    "    n_t = 100\n",
    "    n_span = 10\n",
    "\n",
    "    result_array = []\n",
    "    for i in range(len(Ps)):\n",
    "        P = Ps[i]\n",
    "        T = Ts[i]\n",
    "\n",
    "        Mo_Kinetics.set_kinetics_fixed(P, T, Coh)\n",
    "\n",
    "        # solve the kinetics\n",
    "        with Mute():\n",
    "            results = Mo_Kinetics.solve(P, T, 0.0, t_max, n_t, n_span, debug=True)        \n",
    "\n",
    "        # export result\n",
    "        txt_file_path = os.path.join(results_dir, \"solution_P%.2fGPa_T%.2fK.txt\" % (P/1e9, T))\n",
    "        with open(txt_file_path, 'w') as fout:\n",
    "            np.savetxt(txt_file_path, results)\n",
    "        print(\"Solution saved to %s\" % txt_file_path)\n",
    "\n",
    "        result_array.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For one of the condition, Plot the whole kinetics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For all the different conditions, Plot the volume of tranferred materiala\n",
    "\n",
    "We choose T = 873.15, as the transition is rate-controlled in this condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_solving_point:\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "    # index of condition\n",
    "    idx = 1\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 1.0\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (0.0, 1000) # year\n",
    "    x_tick_interval = 2e3   # tick interval along x\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "\n",
    "    P = Ps[idx]\n",
    "    T = Ts[idx]\n",
    "\n",
    "    # parse result for one P, T condition\n",
    "    results = result_array[idx]\n",
    "    time = results[:, 0]\n",
    "    total_grain_number = results[:, 1]\n",
    "    total_grain_diameter = results[:, 2]\n",
    "    volume = results[:, 5]\n",
    "    extended_volume = results[:, 4]\n",
    "    is_saturated_a = results[:, 6]\n",
    "    time_saturated_a = results[:, 7]\n",
    "\n",
    "    # Derive an average grain size\n",
    "    average_grain_diameter = 2.0 * (volume / total_grain_number / (4.0/3.0 * np.pi))**(1.0/3.0)\n",
    "    \n",
    "    # find condition at saturation\n",
    "    total_grain_number_saturated_value = Mo_Kinetics.X_saturated[0]\n",
    "    total_grain_diameter_saturated_value = Mo_Kinetics.X_saturated[1]\n",
    "    extended_volume_saturated_value = Mo_Kinetics.X_saturated[3]\n",
    "\n",
    "    average_grain_diameter_saturated_value = total_grain_diameter_saturated_value / total_grain_number_saturated_value\n",
    "\n",
    "    # find the critical radius\n",
    "    critical_radius_value = Mo_Kinetics.compute_rc(0)\n",
    "\n",
    "    # find where cite situation \n",
    "    indices = np.where(is_saturated_a == 1.0)[0]\n",
    "    time_saturated_value = time_saturated_a[indices[0]]\n",
    "    extended_volume_critial_saturated_value = 4 * np.pi / 3 * critical_radius_value**3.0 * total_grain_number_saturated_value\n",
    "    \n",
    "    print(\"P = %.4e GPa, T = %.4e K, ts: %.4e year, d: %.4e m, rc: %.4e m, extended volume: %.4e, extended volume by critical radius: %.4e\"\\\n",
    "           % (P/1e9, T, time_saturated_value/year, average_grain_diameter_saturated_value, critical_radius_value, extended_volume_saturated_value, extended_volume_critial_saturated_value))\n",
    "    \n",
    "    # Start plot\n",
    "    fig = plt.figure(figsize=(2.1*8*scaling_factor, 2.1*5*scaling_factor), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "    # plot the grain number and total diameter\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    ax.semilogy(time/year/1e3, total_grain_number, color=default_colors[idx], label='Grain Number, P=%.2f Gpa, T=%.2f K' %(P/1e9, T))\n",
    "    ax.set_xlabel('Time (kyr)')\n",
    "    ax.set_ylabel('Grain Number (m^-3)')\n",
    "    ax.tick_params(axis='y')\n",
    "    \n",
    "    ax.set_xlim(x_lim)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax1 = ax.twinx()\n",
    "    ax1.semilogy(time/year/1e3, total_grain_diameter, color=default_colors[idx], label='Grain Diameter, P=%.2f Gpa, T=%.2f K' %(P/1e9, T), linestyle=\"--\")\n",
    "    ax1.set_ylabel('Total Grain Diameter (m^-2)')\n",
    "\n",
    "    # plot the average grain size\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "    ax.plot(time/year/1e3, np.log10(average_grain_diameter), color=default_colors[idx], label='Average Grain Size, P=%.2f Gpa, T=%.2f K' %(P/1e9, T))\n",
    "    ax.hlines(np.log10(average_grain_diameter_saturated_value), x_lim[0], x_lim[1], label='(Saturation)', color=default_colors[idx], linestyle=\"--\")\n",
    "    ax.set_xlabel('Time (kyr)')\n",
    "    ax.set_ylabel('log10(Grain Size (m))')\n",
    "    ax.tick_params(axis='y')\n",
    "    \n",
    "    ax.set_xlim(x_lim)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    # plot the volume and the extended volume\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "    ax.plot(time/year/1e3, volume, color=default_colors[idx], label='Volume, P=%.2f Gpa, T=%.2f K' %(P/1e9, T))\n",
    "    ax.set_xlabel('Time (kyr)')\n",
    "    ax.set_ylabel('Volume')\n",
    "    ax.tick_params(axis='y')\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim((0.0, 1.0))\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(0.2/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax.grid()\n",
    "\n",
    "    ax1 = ax.twinx()\n",
    "    ax1.plot(time/year/1e3, extended_volume, linestyle=\"--\", color=default_colors[idx], label=\"Extended Volume\")\n",
    "    ax1.set_ylim((0.0, 5.0))\n",
    "    ax1.yaxis.set_major_locator(MultipleLocator(1.0))\n",
    "    ax1.yaxis.set_minor_locator(MultipleLocator(1.0/(n_minor_ticks+1)))\n",
    "    ax1.set_ylabel('Extended Volume')\n",
    "\n",
    "    handles1, labels1 = ax.get_legend_handles_labels()\n",
    "    handles2, labels2 = ax1.get_legend_handles_labels()\n",
    "    ax.legend(handles1 + handles2, labels1 + labels2, loc=\"best\")\n",
    "\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_solving_point:\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 2.0 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (0.0, 1e4)\n",
    "    y_lim1 = (0.0, 1.0)\n",
    "    y_lim2 = (-10.0, 10.0)\n",
    "    x_tick_interval = 2e3   # tick interval along x\n",
    "    y_tick_interval1 = 0.25  # tick interval along y\n",
    "    y_tick_interval2 = 5.0  # tick interval along y\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    }) \n",
    "        \n",
    "    fig = plt.figure(figsize=(16*scaling_factor, 10*scaling_factor), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(2, 2)\n",
    "    ax1 = fig.add_subplot(gs[0, 0]) # V\n",
    "    ax2 = ax1.twinx() # Extended V\n",
    "    ax3 = fig.add_subplot(gs[1, 0]) # grain size\n",
    "    ax4 = fig.add_subplot(gs[0, 1]) # V and grain size\n",
    "    ax5 = ax4.twinx() # grain size\n",
    "    \n",
    "    for i in range(len(Ps)):\n",
    "\n",
    "        P = Ps[i]\n",
    "        T = Ts[i]\n",
    "\n",
    "        # parse result for one P, T condition\n",
    "        results = result_array[i]\n",
    "        time = results[:, 0]\n",
    "        total_grain_number = results[:, 1]\n",
    "        total_grain_diameter = results[:, 2]\n",
    "        volume = results[:, 5]\n",
    "        extended_volume = results[:, 4]\n",
    "        is_saturated_a = results[:, 6]\n",
    "        time_saturated_a = results[:, 7]\n",
    "\n",
    "        print(\"P: \", P)\n",
    "        print(\"T: \", T)\n",
    "        print(\"total_grain_number: \", total_grain_number)\n",
    "        \n",
    "        # find_average_grain_diameter\n",
    "        total_grain_number_saturated_value = Mo_Kinetics.X_saturated[0]\n",
    "        total_grain_diameter_saturated_value = Mo_Kinetics.X_saturated[1]\n",
    "        extended_volume_saturated_value = Mo_Kinetics.X_saturated[3]\n",
    "\n",
    "        # find_average_grain_diameter\n",
    "        average_grain_diameter_saturated_value = total_grain_diameter_saturated_value / total_grain_number_saturated_value\n",
    "        average_grain_diameter = ((volume / total_grain_number) * 6.0 / np.pi)**(1.0/3.0)\n",
    "\n",
    "        # find the critical radius\n",
    "        critical_radius_value = Mo_Kinetics.compute_rc(0)\n",
    "\n",
    "        # find where cite situation \n",
    "        indices = np.where(is_saturated_a == 1.0)[0]\n",
    "        try:\n",
    "            time_saturated_value = time_saturated_a[indices[0]]\n",
    "        except IndexError:\n",
    "            time_saturated_value = None\n",
    "\n",
    "        if time_saturated_value is not None:\n",
    "            extended_volume_critial_saturated_value = 4 * np.pi / 3 * critical_radius_value**3.0 * total_grain_number_saturated_value\n",
    "        else:\n",
    "            extended_volume_critial_saturated_value = None\n",
    "\n",
    "        def fmt(val, scale=1.0):\n",
    "            return \"None\" if val is None else f\"{val/scale:.4e}\"\n",
    "\n",
    "        print(\n",
    "            \"P = %s GPa, T = %s K, ts: %s year, d: %s m, rc: %s m, \"\n",
    "            \"extended volume: %s, extended volume by critical radius: %s\"\n",
    "            % (\n",
    "                fmt(P, 1e9),\n",
    "                fmt(T),\n",
    "                fmt(time_saturated_value, year),\n",
    "                fmt(average_grain_diameter_saturated_value),\n",
    "                fmt(critical_radius_value),\n",
    "                fmt(extended_volume_saturated_value),\n",
    "                fmt(extended_volume_critial_saturated_value),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Plot on the left y-axis\n",
    "        ax1.plot(time/year/1e3, volume, color=default_colors[i], linewidth=4, label='Volume, P=%.2f Gpa, T=%.2f K' %(P/1e9, T))\n",
    "        ax1.set_xlabel('Time (kyr)')\n",
    "        ax1.set_ylabel('Volume', color='tab:blue')\n",
    "        ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "        # Create twin axis for right y-axis\n",
    "        if i == 0:\n",
    "            _label = 'Extended Volume'\n",
    "        else:\n",
    "            _label = None\n",
    "\n",
    "        # ax2.plot(time/year/1e3, extended_volume, color=default_colors[i], label=_label)\n",
    "        ax2.plot(time/year/1e3, np.log10(extended_volume), color=default_colors[i], label=_label)\n",
    "        ax2.set_ylabel('log(Extended Volume)', color='tab:red')\n",
    "        ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "        # Optional: Add grid and title\n",
    "        fig.suptitle('Volume and Extended Volume vs Time')\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # Optional: Combine legends\n",
    "        lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "        lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "        ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper left')\n",
    "\n",
    "        # Adjust spine thickness for this plot\n",
    "        for spine in ax1.spines.values():\n",
    "            spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "        for spine in ax2.spines.values():\n",
    "            spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "        \n",
    "        # average grain size \n",
    "        ax3.plot(time/year/1e3, np.log10(average_grain_diameter), color=default_colors[i], linewidth=4, label='Dav, P=%.2f Gpa, T=%.2f K' %(P/1e9, T))\n",
    "        ax3.set_xlabel('Time (kyr)')\n",
    "        ax3.set_ylabel('log10(Average Grain Size)')\n",
    "\n",
    "        # V and grain size\n",
    "        ax4.plot(time/year/1e3, volume, color=default_colors[i], linewidth=4, label='Volume, P=%.2f Gpa, T=%.2f K' %(P/1e9, T))\n",
    "        ax4.set_xlabel('Time (kyr)')\n",
    "        ax4.set_ylabel('Volume')\n",
    "        ax4.tick_params(axis='y')\n",
    "        ax5.plot(time/year/1e3, np.log10(average_grain_diameter), color=default_colors[i], linestyle=\"--\", linewidth=4, label='Dav, P=%.2f Gpa, T=%.2f K' %(P/1e9, T))\n",
    "        ax5.set_ylabel('log10(Average Grain Size)')\n",
    "        \n",
    "        lines_4, labels_4 = ax4.get_legend_handles_labels()\n",
    "        lines_5, labels_5 = ax5.get_legend_handles_labels()\n",
    "        ax4.legend(lines_4 + lines_5, labels_4 + labels_5)\n",
    "\n",
    "    # axis configuration\n",
    "    ax1.set_xlim(x_lim)\n",
    "    ax1.set_ylim(y_lim1)\n",
    "    ax2.set_ylim(y_lim2)\n",
    "    ax3.set_xlim(x_lim)\n",
    "    ax4.set_xlim([0, 1000.0])\n",
    "    ax4.set_ylim([0.0, 1.05])\n",
    "    ax5.set_ylim([-10.0, 0.5])\n",
    "\n",
    "    ax1.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax1.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax1.yaxis.set_major_locator(MultipleLocator(y_tick_interval1))\n",
    "    ax1.yaxis.set_minor_locator(MultipleLocator(y_tick_interval1/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax2.yaxis.set_major_locator(MultipleLocator(y_tick_interval2))\n",
    "    ax2.yaxis.set_minor_locator(MultipleLocator(y_tick_interval2/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax3.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax3.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax3.yaxis.set_major_locator(MultipleLocator(2.5))\n",
    "    ax3.yaxis.set_minor_locator(MultipleLocator(2.5/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax4.xaxis.set_major_locator(MultipleLocator(200.0))\n",
    "    ax4.xaxis.set_minor_locator(MultipleLocator(200.0/(n_minor_ticks+1)))\n",
    "    ax4.yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "    ax4.yaxis.set_minor_locator(MultipleLocator(0.2/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax5.yaxis.set_major_locator(MultipleLocator(2.0))\n",
    "    ax5.yaxis.set_minor_locator(MultipleLocator(2.0/(n_minor_ticks+1)))\n",
    "\n",
    "    ax4.grid()\n",
    "\n",
    "    # maintain a tight layout     \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # show figure \n",
    "    plt.show()\n",
    "\n",
    "    # save figure\n",
    "    fig_path = os.path.join(results_dir, \"metastable_illustration_nu_%d_d0_%2e_Coh_%.2e.pdf\" % (nucleation_type, d0, Coh))\n",
    "    fig.savefig(fig_path)\n",
    "    print(\"Save figure %s\" % fig_path)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the kinetics for a grid\n",
    "\n",
    "(Supplementary Material: description related to the diagram)\n",
    "\n",
    "To synthetically solve the metastable transition of $ol \\rightarrow wd$ at different $P$–$T$ conditions and present the key diagnostics in a diagram .\n",
    "Here, we made the simplification to omit latent heat.\n",
    "Initially, we made the transformed volume grows from 0 at all the test points.\n",
    "With different length of time elapsed, we include a color plot at a constant time (e.g. 50 Myr), contours of the transformed volume at different model time.\n",
    "The effects from the transition could be seen such that at a later time, the predicted transition forefront progressively shifts toward cooler temperatures.\n",
    "\n",
    "Following this analysis, we then plot contours of the site saturation timescale $t_s$ and the growth timescale $t_g$ (i.e $t_{0.5}$ assuming early site saturation). The diagram is divided into four categories based on kinetic regimes: M — metastable, G — growth-controlled kinetics, N — nucleation-controlled kinetics, and E — equilibrium transition, using the following criteria:\n",
    "\n",
    "$$ M: \\quad t_s > 100~\\mathrm{Ma},\\ t_g > 100~\\mathrm{Ma} $$\n",
    "$$ G: \\quad t_s \\leq t_g,\\ \\min\\left(t_s, t_g\\right) < 100~\\mathrm{Ma} $$\n",
    "$$ N: \\quad t_s > t_g,\\ \\min\\left(t_s, t_g\\right) < 100~\\mathrm{Ma} $$\n",
    "$$ E: \\quad t_s < 10~\\mathrm{kyr},\\ t_g < 10~\\mathrm{kyr} $$\n",
    "\n",
    "Contours of the Avrami number equal to 1 are also plotted.\n",
    "These contours illustrate the balance between the diffusion timescale and the kinetic transition timescale.\n",
    "The two different boundary thicknesses represent the characteristic thermal diffusion length scales: 100~km for the entire lithospheric plate (black dashed line) and 5~km for the effective boundary of the metastable olivine wedge (grey dashed line).\n",
    "\n",
    "There are two types of process:\n",
    "* serial: this runs with just one process. It has the advantage of reporting the progress. It could be used to estimate the running speed.\n",
    "* parallel: this runs in parallel to save time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate the model\n",
    "\n",
    "Here the numerical setup is defined by:\n",
    "- `n_t` — number of time discretization steps  \n",
    "- `n_span` — number of sub-steps used to solve the ODEs (set to 20)\n",
    "\n",
    "The resolution of the diagram is defined by:\n",
    "- `N_P` — number of points along the pressure (P) axis  \n",
    "- `N_T` — number of points along the temperature (T) axis  \n",
    "\n",
    "The constant time used for inspecting the diagram is given by:\n",
    "- `N_P_1` - number of points along the pressure (P) axis after remeshing\n",
    "- `N_T_1` - number of points along the pressure (T) axis after remeshing\n",
    "- `t_constant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo_diagram\n",
    "\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "\n",
    "is_kinetics_diagram = False  # if we solve new dataset and merge to old ones\n",
    "\n",
    "if is_kinetics_diagram:\n",
    "\n",
    "\n",
    "    import hamageolib.research.haoyuan_2d_subduction.metastable as Meta\n",
    "\n",
    "\n",
    "    # Running options\n",
    "    # option 1: solve and also read in previous dataset (not updated, but exported as another file)\n",
    "    # is_solving_kinetics_diagram = True  # if we solve new dataset and merge to old ones\n",
    "    # is_solving_kinetics_diagram_parallel = True # Solve results in python parallel\n",
    "    # is_read_dataset = True;  is_read_new_dataset = False; is_update_dataset = True\n",
    "    # option 2: only read the new dataset\n",
    "    is_solving_kinetics_diagram = False  # if we solve new dataset and merge to old ones\n",
    "    is_solving_kinetics_diagram_parallel = False # Solve results in python parallel\n",
    "    is_read_dataset = True;  is_read_new_dataset = True; is_update_dataset = False\n",
    "    \n",
    "\n",
    "    # Equilibrium values\n",
    "    Peq = 13.5e9\n",
    "    Teq = 1740.0\n",
    "    Cl = 2e6\n",
    "    \n",
    "    # Kinetic values\n",
    "    Coh = 150.0 # ppm H2O\n",
    "    d0 = 1e-2 # m, grain size\n",
    "    nucleation_type = 1\n",
    "\n",
    "    # Timesteps and resolution\n",
    "    t_max = 1e6 * year\n",
    "    # t_max = 10 * 1e6 * year # for plotting figure in the supplementary material\n",
    "\n",
    "    # Range of P, T and resolution\n",
    "    full_mesh_PT = False # Use the full ranges of P, T to creat mesh\n",
    "    if full_mesh_PT:\n",
    "        P_min = 0.0; P_max = 20e9\n",
    "        T_min = 673.15; T_max = 1873.15 # K\n",
    "    else:\n",
    "        # P_min = 12e9; P_max = 14e9; T_min = 800.0; T_max = 1873.15 # Pa, K\n",
    "        P_min = 11e9; P_max = 14e9; T_min = 600.0; T_max = 1200.0\n",
    "        # prescribe values by user options\n",
    "        pass\n",
    "    N_P = 201; N_T = 101 # resolution of P, T\n",
    "\n",
    "    # Numerical constants\n",
    "    n_t = 10; n_span = 20  # resolution of time\n",
    "\n",
    "    # Grid remeshing and constant time to inspect the kinetics\n",
    "    N_P_1 = 801\n",
    "    N_T_1 = 401\n",
    "    t_constant = 1e6*year     # Time in seconds\n",
    "\n",
    "    # slab temperature profile to overlay on plots\n",
    "    slab_T_file = \"/home/lochy/ASPECT_PROJECT/HaMaGeoLib/dtemp/foo_contour_data.txt\"\n",
    "\n",
    "    # Initiiation\n",
    "    # Note: Pressure in Pascals, Temperature in Kelvin, Time in seconds\n",
    "    # Create a meshgrid\n",
    "    N_t = n_t * n_span + 1 # total number in t dimension\n",
    "\n",
    "    P_values = np.linspace(P_min, P_max, N_P)  # global mesh\n",
    "    T_values = np.linspace(T_min, T_max, N_T)\n",
    "    \n",
    "    t_values = np.linspace(0, t_max, n_t*n_span+1)     \n",
    "\n",
    "    T_grid, P_grid, t_grid = np.meshgrid(T_values, P_values, t_values, indexing=\"ij\")\n",
    "    V_grid = np.zeros(P_grid.shape)\n",
    "\n",
    "    # Read the slab profile \n",
    "    if slab_T_file is not None:\n",
    "        assert(os.path.isfile(slab_T_file))\n",
    "    slab_data = np.loadtxt(slab_T_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solve the kinetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the class\n",
    "if is_kinetics_diagram:\n",
    "    _, _constants1 = Meta.get_kinetic_constants(nucleation_type)\n",
    "    Mo_Kinetics = Meta.MO_KINETICS(_constants1, post_process=[\"ts\", \"tg\"])\n",
    "    Mo_Kinetics.set_initial_grain_size(d0)\n",
    "\n",
    "    Mo_Kinetics.set_PT_eq(Peq, Teq, Cl)\n",
    "    Mo_Kinetics.link_and_set_kinetics_model(Meta.PTKinetics)\n",
    "\n",
    "    # Column names\n",
    "    data_columns = Mo_Kinetics.result_columns + [\"Av\", \"Av_c\", \"Iv\", \"Y\", \"ts\", \"tg\"]\n",
    "    columns = [\"P\", \"T\"] + data_columns\n",
    "\n",
    "    # Function to solve for a given T, P\n",
    "    def solve_metastable_kinetics(P, T, Coh, t_max, n_t, n_span, Mo_Kinetics):\n",
    "        # if P < P_eq:\n",
    "        #     return np.zeros(n_t * n_span, 7)\n",
    "        Mo_Kinetics.set_kinetics_fixed(P, T, Coh)\n",
    "\n",
    "        t_values = np.linspace(0, t_max, n_t*n_span+1)\n",
    "        # compute the nucleation and growth rates\n",
    "        Iv_values = np.zeros(n_t*n_span+1)\n",
    "        Y_values = np.zeros(n_t*n_span+1)\n",
    "        ts_values = np.zeros(n_t*n_span+1)\n",
    "        tg_values = np.zeros(n_t*n_span+1)\n",
    "        for i, t in enumerate(t_values): \n",
    "            Iv_values[i] = Mo_Kinetics.compute_Iv(t)\n",
    "            Y_values[i] = Mo_Kinetics.compute_Y(t)\n",
    "            ts_values[i] = Mo_Kinetics.compute_ts(t)\n",
    "            tg_values[i] = Mo_Kinetics.compute_tg(t)\n",
    "\n",
    "\n",
    "        # compute the Avrami number\n",
    "        Av_values = np.zeros(n_t*n_span+1)\n",
    "        Av_c_values = np.zeros(n_t*n_span+1)\n",
    "        for i, t in enumerate(t_values): \n",
    "            Av_values[i] = Mo_Kinetics.compute_Av(t)\n",
    "            Av_c_values[i] = Mo_Kinetics.compute_Av(t, D=5e3)\n",
    "\n",
    "        # solve the ODEs\n",
    "        results = Mo_Kinetics.solve(P, T, 0.0, t_max, n_t, n_span)\n",
    "\n",
    "        # stack all results \n",
    "        results = np.hstack((results, Av_values[:, np.newaxis], Av_c_values[:, np.newaxis], Iv_values[:, np.newaxis],\\\n",
    "                            Y_values[:, np.newaxis], ts_values[:, np.newaxis], tg_values[:, np.newaxis]))\n",
    "        return results\n",
    "\n",
    "    # Serial or Parallelize computation\n",
    "    if is_solving_kinetics_diagram:\n",
    "        start = time.time()\n",
    "\n",
    "        if is_solving_kinetics_diagram_parallel:\n",
    "            # Solve in parallel\n",
    "            num_processes = multiprocessing.cpu_count()  # Print the number of available processes\n",
    "            print(f\"Number of available processes: {num_processes}\")\n",
    "\n",
    "            results_raw = Parallel(n_jobs=-1)(\n",
    "                delayed(solve_metastable_kinetics)(\n",
    "                    P_grid[i, j, 0], T_grid[i, j, 0], Coh,t_max, n_t, n_span, Mo_Kinetics\n",
    "                )\n",
    "                for i in range(T_grid.shape[0]) for j in range(T_grid.shape[1])\n",
    "            )\n",
    "\n",
    "            # Convert results_raw to a structured grid\n",
    "            grid_shape = (T_grid.shape[0], T_grid.shape[1])  # Grid size\n",
    "            time_steps = results_raw[0].shape[0]  # Number of time steps\n",
    "            num_columns = results_raw[0].shape[1]  # Number of variables\n",
    "\n",
    "            results_array = np.array(results_raw)  # Convert list to NumPy array\n",
    "            results_grid = results_array.reshape(*grid_shape, time_steps, num_columns)  # Reshape to grid\n",
    "\n",
    "            # Access specific data\n",
    "            V_grid = results_grid[:, :, :, 5]  # Extract column 0 across all grid points\n",
    "        else:\n",
    "            # Precompute equilibrium pressures\n",
    "            P_eq_values = [Meta.compute_eq_P(Mo_Kinetics.PT_eq, T) for T in T_values]\n",
    "\n",
    "            # Solve\n",
    "            V_grid = np.zeros(P_grid.shape)\n",
    "            for i in range(T_grid.shape[0]):\n",
    "                for j in range(T_grid.shape[1]):\n",
    "                    V_array = solve_metastable_kinetics(P_grid[i, j, 0], T_grid[i, j, 0], Coh,t_max, n_t, n_span, Mo_Kinetics, P_eq_values[i])\n",
    "                    V_grid[i, j, :] = V_array\n",
    "                    sys.stdout.write(\"\\rsolved %d / %d\" % (i*T_grid.shape[1]+j, T_grid.shape[0]*T_grid.shape[1]-1)) # debug\n",
    "                    sys.stdout.flush()\n",
    "            sys.stdout.write(\"\\nSolve Metastable Kinetics take %.2f s\" % (end-start))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"\\nSolve Metastable Kinetics took %.2f s\" % (end - start))\n",
    "\n",
    "\n",
    "        # Convert to pandas object\n",
    "        # P and T in the grid are flatten to a vector along with the result on volume,\n",
    "        # then these are parsed to a pandas 2-d array\n",
    "        data_raw = []\n",
    "\n",
    "        for i in range(T_grid.shape[0]):\n",
    "            for j in range(T_grid.shape[1]):\n",
    "                # Extract the pressure and temperature for this grid point\n",
    "                P_value = P_grid[i, j, 0]\n",
    "                T_value = T_grid[i, j, 0]\n",
    "                \n",
    "                # Extract the corresponding results\n",
    "                result = results_raw[i * T_grid.shape[1] + j]  # Flattened indexing\n",
    "                \n",
    "                # Combine P, T with each row of the results\n",
    "                for k in range(result.shape[0]):  # Iterate over time steps\n",
    "                    row = [P_value, T_value] + result[k].tolist()  # Combine P, T, and the result row\n",
    "                    data_raw.append(row)\n",
    "\n",
    "        data_array = np.array(data_raw) # Convert the list of rows into a 2D NumPy array\n",
    "\n",
    "\n",
    "\n",
    "        new_data = pd.DataFrame(data_array, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import or export results to a grid data if required\n",
    "\n",
    "Here we first check whether a previous file exists.  \n",
    "If so, the data in that file are updated with newly computed data points.  \n",
    "Otherwise, a new file is created and saved with a date stamp.\n",
    "\n",
    "To update an existing dataset, copy the newly generated data file and replace the old one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_kinetics_diagram:\n",
    "\n",
    "    from datetime import datetime\n",
    "    from shutil import copy\n",
    "\n",
    "    # working directory and file\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "    current_results_dir = os.path.join(results_dir, \"grid_data_09102025\")\n",
    "    if not os.path.isdir(current_results_dir):\n",
    "        os.mkdir(current_results_dir)\n",
    "\n",
    "    data_file = os.path.join(current_results_dir, \"metastable_grid_data.parquet\")\n",
    "    data_file_new = os.path.join(current_results_dir, f\"metastable_grid_data_{timestamp}.parquet\")\n",
    "    data_file_csv = os.path.join(current_results_dir, \"metastable_grid_data.csv\")\n",
    "\n",
    "    if is_read_dataset:\n",
    "        assert(os.path.isfile(data_file))\n",
    "\n",
    "        if is_read_new_dataset:\n",
    "            data = pd.read_parquet(data_file_new)\n",
    "        else:\n",
    "            data = pd.read_parquet(data_file)\n",
    "        \n",
    "        print(\"loaded data file %s\" % data_file)\n",
    "\n",
    "        if is_solving_kinetics_diagram:\n",
    "\n",
    "            # Identify existing combinations of P and T in data\n",
    "            existing_combinations = set(zip(data[\"P\"], data[\"T\"]))\n",
    "\n",
    "            # Filter new_data to exclude rows with existing P and T combinations\n",
    "            filtered_new_data = new_data[~new_data.apply(lambda row: (row[\"P\"], row[\"T\"]) in existing_combinations, axis=1)]\n",
    "\n",
    "            # Merge the filtered new_data into data\n",
    "            data = pd.concat([data, filtered_new_data], ignore_index=True)\n",
    "\n",
    "    else:\n",
    "        data = new_data\n",
    "            \n",
    "    # Save data\n",
    "    # First, generate a backup\n",
    "    if is_update_dataset:\n",
    "        copy(data_file, data_file_new)\n",
    "        print(\"created new file %s\" % data_file_new)\n",
    "        \n",
    "        data.to_parquet(data_file, index=False) # fail to run because of missing packages\n",
    "        data.to_csv(data_file_csv, index=False)\n",
    "\n",
    "        print(\"saved parquet file %s\" % data_file)\n",
    "        print(\"saved csv file %s\" % data_file_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the diagram\n",
    "\n",
    "With the interpolation scheme, we define both a near-neighbor interpolation and a inverse distance weighting (IDW) interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_kinetics_diagram:\n",
    "\n",
    "    from scipy.interpolate import NearestNDInterpolator\n",
    "\n",
    "    def categorize_the_diagram(ts, tg):\n",
    "        '''\n",
    "        categorize the diagram from known time\n",
    "        Inputs:\n",
    "            ts - time for site situation\n",
    "            tg - time for grain growth\n",
    "        '''\n",
    "        # assign a limit for metastability in geodynamic timescale \n",
    "        t_eq = 1e4* year\n",
    "        t_meta = 1e8* year\n",
    "\n",
    "        # switch between float and numpy objects\n",
    "        if type(ts) in [float, np.float64]:\n",
    "            if ts > t_meta and tg > t_meta:\n",
    "                value = 0\n",
    "            elif ts <= tg:\n",
    "                value = 1\n",
    "            else:\n",
    "                value = 2 \n",
    "        elif type(ts) == np.ndarray:\n",
    "            # in case of a numpy array, first assign a mask\n",
    "            value = np.full(ts.shape, 0, dtype=int)\n",
    "            mask0 = (ts > t_meta) & (tg > t_meta)\n",
    "            mask1 = ((ts < t_meta) | (tg < t_meta)) & (ts <= tg)\n",
    "            mask2 = ((ts < t_meta) | (tg < t_meta)) & (ts > tg)\n",
    "            mask3 = (ts < t_eq) & (tg < t_eq)\n",
    "            value[mask1] = 1\n",
    "            value[mask2] = 2\n",
    "            value[mask3] = 3\n",
    "        else:\n",
    "            return NotImplementedError()\n",
    "\n",
    "        return value\n",
    "\n",
    "    ## Remesh the grid from data\n",
    "    P_values_1 = np.linspace(0.0, 30e9, N_P_1)  # Pressure in Pascals\n",
    "    T_values_1 = np.linspace(273.15, 1873.15, N_T_1)  # Temperature in Kelvin\n",
    "\n",
    "    T_grid_1, P_grid_1 = np.meshgrid(T_values_1, P_values_1)\n",
    "\n",
    "    T_flat_1 = T_grid_1.flatten()\n",
    "    P_flat_1 = P_grid_1.flatten()\n",
    "\n",
    "    # compute equilibrium values\n",
    "    P_eq_values_1 = Meta.compute_eq_P(Mo_Kinetics.PT_eq, T_values_1)\n",
    "\n",
    "    # perform interpolation\n",
    "    # use scaling factors for T, P, t to normalize the values\n",
    "    interpolators = {}\n",
    "    \n",
    "    P0 = 1e9 # Pa\n",
    "    T0 = 100.0 # K\n",
    "    t0 = 1000 * year # s\n",
    "\n",
    "    for col in data_columns:\n",
    "        interpolators[col] = NearestNDInterpolator(\n",
    "        np.column_stack((data[\"T\"]/T0, data[\"P\"]/P0, data[\"t\"]/t0)),\n",
    "        data[col]\n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Plot the volumetric nucleation rate, grain growth rate and the Av number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_kinetics_diagram:\n",
    "\n",
    "    import matplotlib.colors as mcolors\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    from matplotlib import rcdefaults\n",
    "\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 2.0 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (400.0, 1800.0)\n",
    "    x_tick_interval = 200.0   # tick interval along x\n",
    "    y_lim = (10.0, 30.0)\n",
    "    y_tick_interval = 5.0  # tick interval along y\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    idx = np.arange(0, N_P * N_T * N_t, N_t)\n",
    "\n",
    "    # Iv_grid = data[\"Iv\"].to_numpy()[np.ix_(idx)].reshape(T_grid_1.shape)\n",
    "    # Y_grid = data[\"Y\"].to_numpy()[np.ix_(idx)].reshape(T_grid_1.shape)\n",
    "    # Av_grid = data[\"Av\"].to_numpy()[np.ix_(idx)].reshape(T_grid_1.shape)\n",
    "\n",
    "    # perform interpolation\n",
    "    Iv_flat_1 = interpolators[\"Iv\"](T_flat_1/T0, P_flat_1/P0, np.full(T_flat_1.shape, 0.0))\n",
    "    Iv_grid = Iv_flat_1.reshape(T_grid_1.shape)\n",
    "    Y_flat_1 = interpolators[\"Y\"](T_flat_1/T0, P_flat_1/P0, np.full(T_flat_1.shape, 0.0))\n",
    "    Y_grid = Y_flat_1.reshape(T_grid_1.shape)\n",
    "    Av_flat_1 = interpolators[\"Av\"](T_flat_1/T0, P_flat_1/P0, np.full(T_flat_1.shape, 0.0))\n",
    "    Av_grid = Av_flat_1.reshape(T_grid_1.shape)\n",
    "    Av_c_flat_1 = interpolators[\"Av_c\"](T_flat_1/T0, P_flat_1/P0, np.full(T_flat_1.shape, 0.0))\n",
    "    Av_c_grid = Av_c_flat_1.reshape(T_grid_1.shape)\n",
    "    ts_flat_1 = interpolators[\"ts\"](T_flat_1/T0, P_flat_1/P0, np.full(T_flat_1.shape, 0.0))\n",
    "    ts_grid = ts_flat_1.reshape(T_grid_1.shape)\n",
    "    tg_flat_1 = interpolators[\"tg\"](T_flat_1/T0, P_flat_1/P0, np.full(T_flat_1.shape, 0.0))\n",
    "    tg_grid = tg_flat_1.reshape(T_grid_1.shape)\n",
    "\n",
    "    # Create subplots\n",
    "    fig = plt.figure(figsize=(14*scaling_factor, 14*scaling_factor), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "    # Plot Iv\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    contours = ax.contour(T_grid_1, P_grid_1 / 1e9, np.log10(Iv_grid), (-10, 0, 10, 20), vmin=-20, vmax=30, colors='k', linestyles=\"-\")\n",
    "    ax.clabel(contours, fmt='%d', colors='k')\n",
    "    contours_1 = ax.contour(T_grid_1, P_grid_1 / 1e9, np.log10(Y_grid), (-14, -12, -10, -8, -6, -4), colors='c', linestyles=\"-\")\n",
    "    ax.clabel(contours_1, fmt='%d', colors='c')\n",
    "    ax.plot(T_values_1, P_eq_values_1/1e9, \"-.\")  # plot the equilibrium phase boundary\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_xlabel(\"Temperature (K)\")\n",
    "    ax.set_ylabel(\"Pressure (GPa)\")\n",
    "    ax.set_title(r\"$I_v$ and $Y$\")\n",
    "\n",
    "    # Plot ts, tg.\n",
    "    # Then categorize the diagrame based on these values\n",
    "    # Also append the controus of Av\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "    contours = ax.contour(T_grid_1, P_grid_1 / 1e9, np.log10(ts_grid/year), (2, 4, 6, 8), colors='k', linestyles=\"-\")\n",
    "    ax.clabel(contours, fmt='%d', colors='k')\n",
    "    contours = ax.contour(T_grid_1, P_grid_1 / 1e9, np.log10(tg_grid/year), (2, 4, 6, 8), colors='c', linestyles=\"-\")\n",
    "    ax.clabel(contours, fmt='%d', colors='c')\n",
    "    ax.plot(T_values_1, P_eq_values_1/1e9, \"-.\")  # plot the equilibrium phase boundary\n",
    "\n",
    "    category_grid = categorize_the_diagram(ts_grid, tg_grid)\n",
    "    norm = mcolors.BoundaryNorm(boundaries=[-0.5, 0.5, 1.5, 2.5, 3.5], ncolors=4)\n",
    "    cmap = plt.get_cmap('Pastel1', 4)\n",
    "    cmesh = ax.pcolormesh(T_grid_1, P_grid_1 / 1e9, category_grid, cmap=cmap, norm=norm, shading='auto')\n",
    "    # cbar = plt.colorbar(cmesh, ax=ax, ticks=[0, 1, 2, 3])\n",
    "\n",
    "    contours = ax.contour(T_grid_1, P_grid_1 / 1e9, np.log10(Av_grid), (0), colors='k', linestyles=\"--\")\n",
    "    # ax.clabel(contours, fmt='%d', colors='k')\n",
    "    contours = ax.contour(T_grid_1, P_grid_1 / 1e9, np.log10(Av_c_grid), (0), colors='tab:gray', linestyles=\"--\")\n",
    "    # ax.clabel(contours, fmt='%d', colors='c')\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_xlabel(\"Temperature (K)\")\n",
    "    ax.set_ylabel(\"Pressure (GPa)\")\n",
    "    ax.set_title(r\"$t_s$ and $t_g$\")\n",
    "\n",
    "    # fig.colorbar(h4, ax=ax, label=\"ts\")\n",
    "\n",
    "    # Plot Av\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "    contours = ax.contour(T_grid_1, P_grid_1 / 1e9, np.log10(Av_grid), (-4, 0, 4), colors='k', linestyles=\"-\")\n",
    "    ax.clabel(contours, fmt='%d', colors='k')\n",
    "    contours = ax.contour(T_grid_1, P_grid_1 / 1e9, np.log10(Av_c_grid), (-4, 0, 4), colors='c', linestyles=\"-\")\n",
    "    ax.clabel(contours, fmt='%d', colors='c')\n",
    "    ax.plot(T_values_1, P_eq_values_1/1e9, \"-.\")  # plot the equilibrium phase boundary\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_xlabel(\"Temperature (K)\")\n",
    "    ax.set_ylabel(\"Pressure (GPa)\")\n",
    "    ax.set_title(\"Av\")\n",
    "    # fig.colorbar(h3, ax=ax, label=\"Av\")\n",
    "\n",
    "    fig_path = os.path.join(results_dir, \"Mo_kinetics_diagram_nu_%d_Coh_%.2f_d_%.2f.pdf\" % (Mo_Kinetics.Kinetics.nucleation_type, Coh, d0))\n",
    "    fig.savefig(fig_path)\n",
    "\n",
    "    print(\"Save figure: %s\" % fig_path)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Inspect a given time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we plot at a given time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_kinetics_diagram:\n",
    "\n",
    "    from scipy.ndimage import zoom\n",
    "    from cmcrameri import cm as ccm \n",
    "\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (600.0, 1800.0)\n",
    "    x_tick_interval = 200.0   # tick interval along x\n",
    "    y_lim = (10.0, 20.0)\n",
    "    y_tick_interval = 5.0  # tick interval along y\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "\n",
    "    # interpolate volumn\n",
    "    V_flat_1 = interpolators[\"V\"](T_flat_1/T0, P_flat_1/P0, np.full(T_flat_1.shape, t_constant/t0))\n",
    "    V_grid = V_flat_1.reshape(T_grid_1.shape)\n",
    "    \n",
    "    # interpolate N\n",
    "    N_flat_1 = interpolators[\"N\"](T_flat_1/T0, P_flat_1/P0, np.full(T_flat_1.shape, t_constant/t0))\n",
    "    N_grid = N_flat_1.reshape(T_grid_1.shape)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14*scaling_factor, 12*scaling_factor), constrained_layout=True)\n",
    "\n",
    "    # Plot V\n",
    "    h1 = axes[0, 0].pcolormesh(T_grid_1, P_grid_1 / 1e9, V_grid, cmap=\"viridis\", shading=\"auto\")\n",
    "    axes[0, 0].contour(T_grid_1, P_grid_1 / 1e9, V_grid, (0.5, 0.99), colors=['tab:gray', 'k'], linestyles=\"-\")\n",
    "    axes[0, 0].plot(T_values_1, P_eq_values_1/1e9, \"-.\")  # plot the equilibrium phase boundary\n",
    "    axes[0, 0].plot(slab_data[:, 1], slab_data[:, 0]/1e9, \"--\", color=\"r\")  # plot the slab temperature profile\n",
    "\n",
    "    axes[0, 0].grid()\n",
    "\n",
    "    axes[0, 0].set_xlim(x_lim)\n",
    "    axes[0, 0].set_ylim(y_lim)\n",
    "\n",
    "    axes[0, 0].xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    axes[0, 0].xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    axes[0, 0].yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    axes[0, 0].yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    axes[0, 0].invert_yaxis()\n",
    "\n",
    "    axes[0, 0].set_xlabel(\"Temperature (K)\")\n",
    "    axes[0, 0].set_ylabel(\"Pressure (GPa)\")\n",
    "    axes[0, 0].set_title(\"V\")\n",
    "    fig.colorbar(h1, ax=axes[0, 0], label=\"V\")\n",
    "\n",
    "    # Plot N\n",
    "    N_log_grid = np.log10(N_grid)\n",
    "    N_log_grid[N_log_grid<10.0] = np.nan\n",
    "    h1 = axes[0, 1].pcolormesh(T_grid_1, P_grid_1 / 1e9, N_log_grid, cmap=ccm.batlow, shading=\"auto\", vmin=0, vmax=30)\n",
    "    axes[0, 1].plot(T_values_1, P_eq_values_1/1e9, \"-.\")  # plot the equilibrium phase boundary\n",
    "    axes[0, 0].plot(slab_data[:, 1], slab_data[:, 0]/1e9, \"--\", color=\"r\")  # plot the slab temperature profile\n",
    "\n",
    "    axes[0, 1].grid()\n",
    "\n",
    "    axes[0, 1].set_xlim(x_lim)\n",
    "    axes[0, 1].set_ylim(y_lim)\n",
    "\n",
    "    axes[0, 1].xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    axes[0, 1].xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    axes[0, 1].yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    axes[0, 1].yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    axes[0, 1].invert_yaxis()\n",
    "\n",
    "    axes[0, 1].set_xlabel(\"Temperature (K)\")\n",
    "    axes[0, 1].set_ylabel(\"Pressure (GPa)\")\n",
    "    axes[0, 1].set_title(\"N\")\n",
    "    fig.colorbar(h1, ax=axes[0, 1], label=\"N\")\n",
    "\n",
    "    # Average grain size\n",
    "    D_av_grid = np.full(N_grid.shape, np.nan)\n",
    "    mask = (N_grid > 100)\n",
    "    D_av_grid[mask] = ((V_grid[mask] / N_grid[mask]) * 6.0 / np.pi)**(1/3.0)\n",
    "\n",
    "    h1 = axes[1, 0].pcolormesh(T_grid_1, P_grid_1 / 1e9, np.log10(D_av_grid), cmap=ccm.devon, shading=\"auto\", vmin=-10, vmax=0)\n",
    "    axes[1, 0].plot(T_values_1, P_eq_values_1/1e9, \"-.\")  # plot the equilibrium phase boundary\n",
    "    axes[1, 0].plot(slab_data[:, 1], slab_data[:, 0]/1e9, \"--\", color=\"r\")  # plot the slab temperature profile\n",
    "\n",
    "    # add contours\n",
    "    levels = [-9, -7, -5, -3]\n",
    "    c1 = axes[1, 0].contour(\n",
    "        T_grid_1,\n",
    "        P_grid_1 / 1e9,\n",
    "        np.log10(D_av_grid),\n",
    "        levels=levels,\n",
    "        colors=\"black\",\n",
    "        linewidths=1.2\n",
    "    )\n",
    "    axes[1, 0].clabel(c1, inline=True, fontsize=16)\n",
    "    c2 = axes[1, 0].contour(\n",
    "        T_grid_1,\n",
    "        P_grid_1 / 1e9,\n",
    "        V_grid,\n",
    "        levels=[0.5],\n",
    "        colors=\"tab:gray\",\n",
    "        linestyles=\"-\",\n",
    "        linewidths=1.5\n",
    "    )\n",
    "    axes[1, 0].clabel(c2, inline=True, fontsize=16)\n",
    "\n",
    "    axes[1, 0].grid()\n",
    "\n",
    "    axes[1, 0].set_xlim(x_lim)\n",
    "    axes[1, 0].set_ylim(y_lim)\n",
    "\n",
    "    axes[1, 0].xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    axes[1, 0].xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    axes[1, 0].yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    axes[1, 0].yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    axes[1, 0].invert_yaxis()\n",
    "\n",
    "    axes[1, 0].set_xlabel(\"Temperature (K)\")\n",
    "    axes[1, 0].set_ylabel(\"Pressure (GPa)\")\n",
    "    axes[1, 0].set_title(\"D_av\")\n",
    "    fig.colorbar(h1, ax=axes[1, 0], label=\"D_av\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # save figure\n",
    "    fig_path = os.path.join(results_dir, \"PTV_nu_%d_Coh_%.2e_d_%.2e_t%.2f.pdf\" % (Mo_Kinetics.Kinetics.nucleation_type, Coh, d0, t_constant/1e6/year))\n",
    "    fig.savefig(fig_path)\n",
    "\n",
    "    print(\"Saved figure %s\" % fig_path)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Then we handle plots of contours at different time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_kinetics_diagram:\n",
    "\n",
    "    from scipy.ndimage import zoom\n",
    "    from matplotlib.lines import Line2D\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (400.0, 1800.0)\n",
    "    x_tick_interval = 200.0   # tick interval along x\n",
    "    y_lim = (10.0, 30.0)\n",
    "    y_tick_interval = 5.0  # tick interval along y\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "\n",
    "    # constant time\n",
    "    ts = np.array([5e4, 1e5, 1e6]) * year\n",
    "\n",
    "    # Create subplots\n",
    "    fig, ax = plt.subplots(figsize=(7, 6), constrained_layout=True)\n",
    "\n",
    "    ax.plot(T_values_1, P_eq_values_1/1e9, \"-.\")  # plot the equilibrium phase boundary\n",
    "\n",
    "    # Initialize a list for legend entries\n",
    "    legend_lines = []\n",
    "    legend_labels = []\n",
    "\n",
    "    for i, t_constant in enumerate(ts):\n",
    "\n",
    "        # perform interpolation 1: near neighber\n",
    "        V_flat_1 = interpolators[\"V\"](T_flat_1/T0, P_flat_1/P0, np.full(T_flat_1.shape, t_constant/t0))\n",
    "\n",
    "        # reshape to V_grid\n",
    "        V_grid = V_flat_1.reshape(T_grid_1.shape)\n",
    "\n",
    "        # Add entry to legend list\n",
    "        legend_lines.append(Line2D([0], [0], color=default_colors[i+1], linestyle=\"--\"))\n",
    "        legend_labels.append(\"%.1e year\" % (t_constant/year))\n",
    "\n",
    "    ax.legend(legend_lines, legend_labels)\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_xlabel(\"Temperature (K)\")\n",
    "    ax.set_ylabel(\"Pressure (GPa)\")\n",
    "    ax.set_title(\"Smoothed Grid (Upsampled)\")\n",
    "\n",
    "\n",
    "    # Adjust spine thickness for this plot\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # save figure\n",
    "    fig_path = os.path.join(results_dir, \"PTV_contours.png\")\n",
    "    fig.savefig(fig_path)\n",
    "\n",
    "    print(\"Saved figure %s\" % fig_path)\n",
    "\n",
    "    fig_path_pdf = os.path.join(results_dir, \"PTV_contours_nu_%d_Coh_%.2e_d_%.2e.pdf\" % (Mo_Kinetics.Kinetics.nucleation_type, Coh, d0))\n",
    "    fig.savefig(fig_path_pdf)\n",
    "\n",
    "    print(\"Saved figure %s\" % fig_path_pdf)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the results from cpp code\n",
    "\n",
    "(OneNote \"My cpp script\". Append the technical requirments)\n",
    "\n",
    "To run the cpp code\n",
    "\n",
    "Navigate to HaMaGeoLib/cpp\n",
    "\n",
    "Create a build directory and \"cd build\"\n",
    "\n",
    "    cmake ..\n",
    "\n",
    "Run and test\n",
    "\n",
    "Run and create a diagram\n",
    "\n",
    "\t  make metastable_diagram\n",
    "\n",
    "    ./metastable_diagram\n",
    "\n",
    "### Plot the diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cpp_diagram_results = False\n",
    "\n",
    "if plot_cpp_diagram_results:\n",
    "\n",
    "    from scipy.interpolate import UnivariateSpline\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    root_path = os.path.join(Path().resolve().parent.parent)\n",
    "    package_path = os.path.join(root_path, \"hamageolib\")\n",
    "\n",
    "    if str(package_path) not in sys.path:\n",
    "        sys.path.insert(0, str(package_path))\n",
    "\n",
    "\n",
    "    from utils.exception_handler import my_assert\n",
    "    import utils.plot_helper as plot_helper\n",
    "\n",
    "    base_dir = Path().resolve()\n",
    "\n",
    "    results_dir = os.path.join(root_path, \"dtemp\")\n",
    "    if not os.path.isdir(results_dir):\n",
    "        os.mkdir(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the data file generated by the cpp script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_cpp_diagram_results:\n",
    "\n",
    "    file_path = \"/home/lochy/ASPECT_PROJECT/HaMaGeoLib/dtemp/metastable_diagram_cpp.txt\"\n",
    "\n",
    "    assert(os.path.isfile(file_path))\n",
    "\n",
    "    data_in = np.loadtxt(file_path, delimiter=',', dtype=float, skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, remake the plot for transition volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_cpp_diagram_results:\n",
    "\n",
    "    from scipy.interpolate import NearestNDInterpolator\n",
    "\n",
    "    ## for a global mesh\n",
    "    P_values_1 = np.linspace(0.0, 30e9, 200)  # Pressure in Pascals\n",
    "    T_values_1 = np.linspace(273.15, 1873.15, 100)  # Temperature in Kelvin\n",
    "\n",
    "    # scaling factors\n",
    "    P0 = 1e9 # Pa\n",
    "    T0 = 100.0 # K\n",
    "    t0 = 10000 * year # s\n",
    "\n",
    "    # make a new grid\n",
    "    T_grid_1, P_grid_1 = np.meshgrid(T_values_1, P_values_1)\n",
    "\n",
    "    T_flat_1 = T_grid_1.flatten()\n",
    "    P_flat_1 = P_grid_1.flatten()\n",
    "\n",
    "    # compute equilibrium values\n",
    "    P_eq_values_1 = Meta.compute_eq_P(PT410, T_values_1)\n",
    "\n",
    "    # perform interpolation\n",
    "    interpolator = NearestNDInterpolator(\n",
    "        np.column_stack((data_in[:, 1]/T0, data_in[:, 0]/P0, data_in[:, 2]/t0)),\n",
    "        data_in[:, 7]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot at a given time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_cpp_diagram_results:\n",
    "\n",
    "    from scipy.ndimage import zoom\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (273.15, 1773.15)\n",
    "    x_tick_interval = 200.0   # tick interval along x\n",
    "    y_lim = (0.0, 30.0)\n",
    "    y_tick_interval = 5.0  # tick interval along y\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # constant time\n",
    "    t_constant = 5e4*year     # Time in seconds\n",
    "\n",
    "    # perform interpolation 1: near neighber\n",
    "    V_flat_1 = interpolator(T_flat_1/T0, P_flat_1/P0, np.full(T_flat_1.shape, t_constant/t0))\n",
    "\n",
    "    # # perform interpolation 2: IDW\n",
    "    # V_flat = idw_interpolation(np.column_stack((data[\"T\"]/T0, data[\"P\"]/P0, data[\"t\"]/t0)), data[\"V\"],\\\n",
    "    #                             np.column_stack((T_flat / T0, P_flat / P0, np.full(T_flat.shape, t_constant / t0))), k=5, power=2)\n",
    "\n",
    "    # reshape to V_grid\n",
    "    V_grid = V_flat_1.reshape(T_grid_1.shape)\n",
    "\n",
    "    # Upsample the V_grid for smoothing\n",
    "    # Define finer grid based on zoom factor\n",
    "    zoom_factor = 2  # Upscaling factor\n",
    "    V_smooth_grid = zoom(V_grid, zoom_factor, order=3)  # Cubic spline interpolation\n",
    "\n",
    "    T_fine = np.linspace(np.min(T_values_1), np.max(T_values_1), V_smooth_grid.shape[1])\n",
    "    P_fine = np.linspace(np.min(P_values_1), np.max(P_values_1), V_smooth_grid.shape[0])\n",
    "    T_fine_grid, P_fine_grid = np.meshgrid(T_fine, P_fine)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6), constrained_layout=True)\n",
    "\n",
    "    # Plot original coarse grid\n",
    "    h1 = axes[0].pcolormesh(T_grid_1, P_grid_1 / 1e9, V_grid, cmap=\"viridis\", shading=\"auto\")\n",
    "    axes[0].contour(T_grid_1, P_grid_1 / 1e9, V_grid, (0.4, 0.8), colors=['tab:gray', 'k'], linestyles=\"--\")\n",
    "    axes[0].plot(T_values_1, P_eq_values_1/1e9, \"-.\")  # plot the equilibrium phase boundary\n",
    "\n",
    "    axes[0].grid()\n",
    "\n",
    "    axes[0].set_xlim(x_lim)\n",
    "    axes[0].set_ylim(y_lim)\n",
    "\n",
    "    axes[0].xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    axes[0].xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    axes[0].yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    axes[0].yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    axes[0].set_xlabel(\"Temperature (K)\")\n",
    "    axes[0].set_ylabel(\"Pressure (GPa)\")\n",
    "    axes[0].set_title(\"Original Coarse Grid\")\n",
    "    fig.colorbar(h1, ax=axes[0], label=\"V\")\n",
    "\n",
    "    # Plot smoothed grid\n",
    "    h2 = axes[1].pcolormesh(T_fine_grid, P_fine_grid / 1e9, V_smooth_grid, cmap=\"viridis\", shading=\"auto\", vmin=0.0, vmax=1.0)\n",
    "    axes[1].contour(T_fine_grid, P_fine_grid / 1e9, V_smooth_grid,\\\n",
    "                    (0.6321, 0.864), # 1 - exp(-1), 1 - exp(-2)\n",
    "                    colors=['tab:gray', 'k'], linestyles=\"--\")\n",
    "    axes[1].plot(T_values_1, P_eq_values_1/1e9, \"-.\")  # plot the equilibrium phase boundary\n",
    "\n",
    "    axes[1].grid()\n",
    "\n",
    "    axes[1].set_xlim(x_lim)\n",
    "    axes[1].set_ylim(y_lim)\n",
    "\n",
    "    axes[1].xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    axes[1].xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    axes[1].yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    axes[1].yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    axes[1].set_xlabel(\"Temperature (K)\")\n",
    "    axes[1].set_ylabel(\"Pressure (GPa)\")\n",
    "    axes[1].set_title(\"Smoothed Grid (Upsampled)\")\n",
    "    fig.colorbar(h2, ax=axes[1], label=\"V\")\n",
    "\n",
    "    # Adjust spine thickness for this plot\n",
    "    for ax in axes:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # save figure\n",
    "    fig_path = os.path.join(results_dir, \"PTV_cpp_t%.2f.png\" % (t_constant/1e6/year))\n",
    "    fig.savefig(fig_path)\n",
    "\n",
    "    print(\"Saved figure %s\" % fig_path)\n",
    "\n",
    "    # fig_path_pdf = os.path.join(results_dir, \"PTV_cpp_t%.2f.pdf\" % (t_constant/1e6/year))\n",
    "    # fig.savefig(fig_path_pdf)\n",
    "\n",
    "    # print(\"Saved figure %s\" % fig_path_pdf)\n",
    "\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run analytic MOW contents from aspect P, T conditions\n",
    "\n",
    "Next we calculate synthetic MOW contents in slab based on the kinetics implemented in ASPECT.\n",
    "To do this, we follow these steps:\n",
    "* Run a test case\n",
    "* Export the dataset from the pvtu files\n",
    "* Apply a nearneighbor interpolation\n",
    "* Plot the colormap and the contours on T, metastable contents and grain sizes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "wb_sp_velocity - subducting plate velocity\n",
    "wb_sp_age - subducting plate age\n",
    "wb_trench_x - position of the trench (this surfaces to fix the trench even we vary the age and velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_run_aspect = False\n",
    "\n",
    "if is_run_aspect:\n",
    "    import re\n",
    "    import json\n",
    "    from shutil import copy\n",
    "    from hamageolib.utils.dealii_param_parser import parse_parameters_to_dict, save_parameters_from_dict\n",
    "    from hamageolib.utils.world_builder_file_parser import find_feature_by_name, update_or_add_feature\n",
    "\n",
    "    # Define paths to the ASPECT executable and the case directory\n",
    "    aspect_executable = \"/home/lochy/Softwares/aspect/build_master_TwoD/aspect\"\n",
    "    group_dir = \"/mnt/lochz/ASPECT_DATA/TwoDSubduction/MO_kinetics_test\"\n",
    "    template_dir = os.path.join(group_dir, \"test_case_template\")  # Directory containing templates\n",
    "    # case_dir = \"/mnt/lochz/ASPECT_DATA/TwoDSubduction/MO_kinetics_test/test_case_ini\"  # Initial case, larger geometry\n",
    "\n",
    "    # Ensure the case directory exists\n",
    "    assert(os.path.isdir(template_dir))\n",
    "\n",
    "    prm_template_path = os.path.join(template_dir, \"case.prm\")\n",
    "    assert(os.path.isfile(prm_template_path))\n",
    "\n",
    "    wb_template_path = os.path.join(template_dir, \"case.wb\")\n",
    "    assert(os.path.isfile(wb_template_path))\n",
    "\n",
    "    # Case setups\n",
    "    wb_sp_velocity = 0.08 # m/yr\n",
    "    wb_sp_age = 80e6 # yr\n",
    "    wb_trench_x = 200e3 # m\n",
    "    wb_ridge_x = wb_trench_x - wb_sp_age * wb_sp_velocity\n",
    "\n",
    "    case_dir = os.path.join(group_dir, \"test_case_sp%.1f_v%.1e\" % (wb_sp_age/1e6, wb_sp_velocity*100))  # Directory containing templates\n",
    "    if not os.path.isdir(case_dir):\n",
    "        os.mkdir(case_dir)\n",
    "    print(\"case_dir: \", case_dir)\n",
    "\n",
    "    # Modify the template\n",
    "    # Also read important parameters like the size of the model\n",
    "\n",
    "    with open(prm_template_path, 'r') as file:\n",
    "        params_dict = parse_parameters_to_dict(file)\n",
    "\n",
    "    params_dict[\"Output directory\"] = os.path.join(case_dir, \"output\")\n",
    "    params_dict[\"World builder file\"] = os.path.join(case_dir, \"case.wb\")\n",
    "\n",
    "    x_extent = float(params_dict[\"Geometry model\"][\"Box\"][\"X extent\"])\n",
    "    y_extent = float(params_dict[\"Geometry model\"][\"Box\"][\"Y extent\"])\n",
    "\n",
    "    with open(wb_template_path, 'r') as fin:\n",
    "        wb_dict = json.load(fin)\n",
    "        \n",
    "    slab_dict = find_feature_by_name(wb_dict, \"Slab\") # Extract the \"Slab\" feature from the World Builder data\n",
    "    sp_dict = find_feature_by_name(wb_dict, \"Subducting plate\")\n",
    "\n",
    "    slab_dict[\"coordinates\"] = [[wb_trench_x, -1000.0], [wb_trench_x, 1000.0]]\n",
    "    slab_dict[\"temperature models\"][0][\"plate velocity\"] = wb_sp_velocity\n",
    "    slab_dict[\"temperature models\"][0][\"ridge coordinates\"][0] = [[wb_ridge_x , 1000.0], [wb_ridge_x , 1000.0]]\n",
    "\n",
    "    sp_dict[\"temperature models\"][0][\"plate age\"] = wb_sp_age \n",
    "\n",
    "    wb_dict = update_or_add_feature(wb_dict, \"Slab\", slab_dict)\n",
    "    wb_dict = update_or_add_feature(wb_dict, \"Subducting plate\", sp_dict)\n",
    "\n",
    "    # Define paths to the parameter file and world builder file within the case directory\n",
    "\n",
    "    prm_path = os.path.join(case_dir, \"case.prm\")\n",
    "    wb_path = os.path.join(case_dir, \"case.wb\")\n",
    "\n",
    "    with open(prm_path, 'w') as output_file:\n",
    "        save_parameters_from_dict(output_file, params_dict)\n",
    "\n",
    "    with open(wb_path, 'w') as fout:\n",
    "        json.dump(wb_dict, fout, indent=4)\n",
    "\n",
    "    # Ensure the parameter file exists\n",
    "    assert(os.path.isfile(prm_path))\n",
    "    assert(os.path.isfile(wb_path))\n",
    "\n",
    "    # Run the ASPECT executable with the parameter file\n",
    "    # The function ensures that both the expected outputs are generated and no errors are produced\n",
    "    # 'capture_output=True' collects both stdout and stderr for further checks\n",
    "    completed_process = subprocess.run([aspect_executable, prm_path], capture_output=True, text=True)\n",
    "\n",
    "    # Capture the standard output and error streams\n",
    "    stdout = completed_process.stdout\n",
    "    stderr = completed_process.stderr\n",
    "\n",
    "    # Uncomment the following lines for debugging purposes to inspect the output\n",
    "    # print(stdout)  # Debugging: Prints the standard output\n",
    "    # print(stderr)  # Debugging: Prints the standard error\n",
    "\n",
    "    # Check if the expected line indicating wallclock time appears in the output\n",
    "    # The expected line format is something like:\n",
    "    # -- Total wallclock time elapsed including restarts: 1s\n",
    "    assert(re.match(\".*Total wallclock\", stdout.split('\\n')[-6]))\n",
    "\n",
    "    # Ensure that the error stream is empty, indicating no issues during the run\n",
    "    assert(stderr == \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data and plot\n",
    "\n",
    "This script reads simulation data from a `.pvtu` file, processes it using VTK and NumPy, and sets up interpolators for various physical fields such as temperature, pressure, and resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect:\n",
    "\n",
    "    import vtk\n",
    "    from vtk.util.numpy_support import vtk_to_numpy\n",
    "    from hamageolib.utils.vtk_utilities import calculate_resolution\n",
    "    import time\n",
    "    import numpy as np\n",
    "    from scipy.interpolate import NearestNDInterpolator\n",
    "\n",
    "    # Define the input file path and field names to extract\n",
    "    pvtu_file = os.path.join(case_dir, \"output\", \"solution\", \"solution-00005.pvtu\")\n",
    "    field_names = [\"T\", \"p\"]  # Field names to extract: temperature (T) and pressure (p)\n",
    "\n",
    "    # Read the pvtu file\n",
    "    reader = vtk.vtkXMLPUnstructuredGridReader()\n",
    "    reader.SetFileName(pvtu_file)\n",
    "    reader.Update()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Get the output data from the reader\n",
    "    grid = reader.GetOutput()  # Access the unstructured grid\n",
    "    data_set = reader.GetOutputAsDataSet()  # Access the dataset representation\n",
    "    points = grid.GetPoints()  # Extract the points (coordinates)\n",
    "    cells = grid.GetCells()  # Extract the cell connectivity information\n",
    "    point_data = data_set.GetPointData()  # Access point-wise data\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Reading files takes %.2f s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Calculate resolution for each cell or point in the grid\n",
    "    resolutions = calculate_resolution(grid)  # Custom function (not defined here)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Calculating resolution takes %.2f s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Construct a vtkPolyData object to hold points and cell information\n",
    "    i_poly_data = vtk.vtkPolyData()\n",
    "    i_poly_data.SetPoints(points)  # Add points to the PolyData object\n",
    "    i_poly_data.SetPolys(cells)  # Add cell connectivity to the PolyData object\n",
    "\n",
    "    # Add point data fields to the vtkPolyData\n",
    "    for idx, field_name in enumerate(field_names):\n",
    "        array = point_data.GetArray(field_name)  # Retrieve the field array\n",
    "        if array:\n",
    "            if idx == 0:  # The first field becomes Scalars\n",
    "                i_poly_data.GetPointData().SetScalars(array)\n",
    "            else:  # Additional fields are added as arrays\n",
    "                i_poly_data.GetPointData().AddArray(array)\n",
    "        else:\n",
    "            print(f\"Warning: Field {field_name} not found.\")  # Warn if field is missing\n",
    "\n",
    "    # Validate that points were successfully added to the vtkPolyData object\n",
    "    noP = i_poly_data.GetNumberOfPoints()\n",
    "    if noP == 0:\n",
    "        raise ValueError(\"No points were added to i_poly_data!\")\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Constructing polydata takes %.2f s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Export data to NumPy arrays for easier processing\n",
    "    points_np = vtk_to_numpy(i_poly_data.GetPoints().GetData())  # Convert points to NumPy\n",
    "    Ts = vtk_to_numpy(i_poly_data.GetPointData().GetArray(\"T\"))  # Temperature array\n",
    "    Ps = vtk_to_numpy(i_poly_data.GetPointData().GetArray(\"p\"))  # Pressure array\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Exporting data to NumPy arrays takes %.2f s\" % (end - start))\n",
    "\n",
    "    # Extract 2D coordinates (x, y) from the points\n",
    "    points_2d = points_np[:, :2]  # Use only the first two columns for 2D coordinates\n",
    "\n",
    "    # Create interpolators for temperature, pressure, and resolution\n",
    "    interpolator = NearestNDInterpolator(points_2d, Ts)  # Interpolator for temperature\n",
    "    interpolator_P = NearestNDInterpolator(points_2d, Ps)  # Interpolator for pressure\n",
    "    interpolator_r = NearestNDInterpolator(points_2d, resolutions)  # Interpolator for resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate to a regular grid\n",
    "\n",
    "This block interpolates simulation data (e.g., temperature, resolution) onto a regular 2D grid and visualizes it using various plots, including colormaps and contour plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect:\n",
    "\n",
    "    # Interpolate to regular grid\n",
    "    # Assuming `points` is an (n, 3) array of (x, y, z) coordinates\n",
    "    # and `Ts` is a (n,) array with corresponding T values\n",
    "\n",
    "    import numpy as np\n",
    "    from scipy.interpolate import NearestNDInterpolator\n",
    "\n",
    "    # Define the interval for the grid (in meters)\n",
    "    interval = 5e3  # 10 km grid interval\n",
    "\n",
    "    # Determine the bounding box of the 2D points\n",
    "    x_min, y_min = np.min(points_2d, axis=0)\n",
    "    x_max, y_max = np.max(points_2d, axis=0)\n",
    "\n",
    "    # Define a regular grid within the bounding box\n",
    "    x_grid = np.arange(x_min, x_max, interval)\n",
    "    y_grid = np.arange(y_min, y_max, interval)\n",
    "    xv, yv = np.meshgrid(x_grid, y_grid, indexing=\"ij\")  # Create a grid of (x, y) points\n",
    "\n",
    "    # Flatten the grid for interpolation\n",
    "    grid_points_2d = np.vstack([xv.ravel(), yv.ravel()]).T\n",
    "\n",
    "    # Interpolate temperature (T) values onto the regular grid\n",
    "    T_grid = interpolator(grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    T_grid = T_grid.reshape(xv.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate temperature (P) values onto the regular grid\n",
    "    P_grid = interpolator_P(grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    P_grid = P_grid.reshape(xv.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate resolutions onto the regular grid\n",
    "    resolutions_grid = interpolator_r(grid_points_2d)\n",
    "    resolutions_grid = resolutions_grid.reshape(xv.shape)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Interpolating to regular grid takes %.2f s\" % (end - start))\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read WorldBuilder information\n",
    "\n",
    "- Load World Builder Data:\n",
    "Reads the slab definition from a JSON file.\n",
    "Extracts slab segments, trench location, and subduction velocity.\n",
    "Segment Analysis:\n",
    "\n",
    "- Computes segment lengths, depths, and dip angles.\n",
    "Determines distances to the slab curve for visualization purposes.\n",
    "Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect:\n",
    "\n",
    "    import json\n",
    "\n",
    "    # Load the World Builder (wb) configurations\n",
    "    # Extract the \"Slab\" feature from the World Builder data\n",
    "    # Process the slab segments to compute relevant properties\n",
    "    # Calculate subduction times\n",
    "    slab_dict = find_feature_by_name(wb_dict, \"Slab\")\n",
    "\n",
    "    slab_segments = slab_dict[\"segments\"]  # Retrieve slab segment definitions\n",
    "    trench_x = slab_dict[\"coordinates\"][0][0]  # Extract trench x-coordinate\n",
    "    subduct_velocity_cm_yr = slab_dict[\"temperature models\"][0][\"plate velocity\"] * 100.0 # Convert velocity to cm/yr\n",
    "    subduct_velocity = slab_dict[\"temperature models\"][0][\"plate velocity\"] / year  # Convert velocity to m/s\n",
    "\n",
    "    lengths, depths, dip_angles, Xs = process_segments(slab_segments, n_spacing=2000)  # Segment analysis\n",
    "\n",
    "    sub_ts = lengths / subduct_velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data grid\n",
    "\n",
    "Key Steps\n",
    "\n",
    "1. **Depth Grid Calculation**:\n",
    "   - Converts $y$-coordinates to depths ($\\text{depth}_{\\text{grid}} = y_{\\text{max}} - y_v$).\n",
    "   - Interpolates segment lengths along the depth grid.\n",
    "\n",
    "2. **Slab Internal Masking**:\n",
    "   - Defines the slab's internal region based on distances from the slab surface (-5 km to 100 km).\n",
    "\n",
    "3. **Subduction Time Calculation**:\n",
    "   - Computes subduction time ($t_{\\text{sub}}$) for points inside the slab using:\n",
    "     $$ t_{\\text{sub}} = \\frac{\\text{length}}{\\text{subduction velocity}} $$\n",
    "\n",
    "4. **Contour Generation**:\n",
    "   - Generates contours at specified distances (e.g., 5 km) from the slab surface.\n",
    "\n",
    "Constants and Assumptions\n",
    "\n",
    "- **Slab Internal Mask**:\n",
    "  - Distance range for slab internals: $-5 \\, \\text{km} \\leq \\text{distance} \\leq 100 \\, \\text{km}$.\n",
    "- **Contour Distance**:\n",
    "  - A single contour at $5 \\, \\text{km}$ from the slab surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect:\n",
    "\n",
    "    # Derive the slab internal points, create contours on distance to the slab surface\n",
    "    # and plot subduction time (`t_sub`) along profiles\n",
    "    # 1. Compute distances to the slab curve\n",
    "    # 2. Compute the depth grid\n",
    "    # 3. Interpolate length values along the depth grid\n",
    "    # 4. Create a mask for slab internals based on distance to the slab surface\n",
    "    # 5. Compute subduction time (`t_sub`) for points inside the slab\n",
    "    distance_v = distances_to_curve(Xs + trench_x, y_max - depths, xv.ravel(), yv.ravel())\n",
    "    distance_grid = distance_v.reshape(xv.shape)  # Reshape distances to grid shape\n",
    "\n",
    "    depth_grid = y_max - yv  # Convert y-coordinates to depths\n",
    "    depth_grid_flat = depth_grid.ravel()  # Flatten depth grid for interpolation\n",
    "\n",
    "    length_grid_flat = np.interp(depth_grid_flat, depths, lengths)  # Interpolate lengths at depth values\n",
    "    length_grid = length_grid_flat.reshape(depth_grid.shape)  # Reshape back to grid format\n",
    "\n",
    "    mask_slab1 = (distance_grid >= -5e3) & (distance_grid <= 100e3)  # Slab internal region: -5 km to 100 km\n",
    "    xv_slab = xv[mask_slab1]\n",
    "    yv_slab = yv[mask_slab1]\n",
    "\n",
    "    t_sub_grid = np.full(xv.shape, float(\"inf\"))  # Initialize with infinity for points outside the slab\n",
    "    t_sub_grid[mask_slab1] = length_grid[mask_slab1] / subduct_velocity  # Compute `t_sub` where the mask applies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagnose a profile with a distance to the slab surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect:\n",
    "\n",
    "    # Parameters for contouring\n",
    "    contour_distance = [20e3]  # Contour distance of 5 km\n",
    "\n",
    "    # Generate contours at specified distances from the slab surface\n",
    "    foo_contour_Xs, foo_contour_Ys = offset_curve(Xs + trench_x, y_max - depths, contour_distance)\n",
    "\n",
    "    foo_contour_depths = y_extent - foo_contour_Ys\n",
    "\n",
    "    foo_grid_points_2d = np.vstack([foo_contour_Xs.ravel(), foo_contour_Ys.ravel()]).T\n",
    "\n",
    "    foo_contour_Ts = interpolator(foo_grid_points_2d)\n",
    "    foo_contour_Ps = interpolator_P(foo_grid_points_2d)\n",
    "\n",
    "    foo_contour_Ps_eq = (foo_contour_Ts - PT410[\"T\"]) * PT410[\"cl\"] + PT410[\"P\"]\n",
    "    foo_contour_Ts_eq = (foo_contour_Ps - PT410[\"P\"]) / PT410[\"cl\"] + PT410[\"T\"]\n",
    "    foo_mask_eq = (foo_contour_Ps > foo_contour_Ps_eq)\n",
    "        \n",
    "    foo_contour_lengths = np.interp(foo_contour_depths, depths, lengths)  # Interpolate lengths at depth values\n",
    "    foo_contour_ts = foo_contour_lengths / subduct_velocity\n",
    "\n",
    "    o_file = os.path.join(results_dir, \"foo_contour_data.txt\")\n",
    "\n",
    "    # Make sure all arrays are 1D and of the same length\n",
    "    odata = np.column_stack((foo_contour_Ps, foo_contour_Ts, foo_contour_ts))\n",
    "\n",
    "    # Save to text file with headers\n",
    "    np.savetxt(o_file, odata, header=\"Ps Ts ts\", fmt=\"%.6e\")\n",
    "\n",
    "    print(\"Saved file %s\" % o_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Plot the initial conditions\n",
    "\n",
    "A. temperature, subduction time, mesh resolution\n",
    "\n",
    "(Editing in AI)\n",
    "append the color bar of subduction time from the plot at gs([1, 0]);\n",
    "\n",
    "add vectors of velocity in the slab internal\n",
    "\n",
    "B. profile properties\n",
    "\n",
    "(Editing in AI)\n",
    "combine the results on Mo extent in the following block\n",
    "append the annotation of subduction time to Y axis from printed outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect:\n",
    "\n",
    "    # Initialize plots\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    from matplotlib import gridspec\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (0.0, 1000.0)\n",
    "    x_tick_interval = 250   # tick interval along x\n",
    "    y_lim = (0.0, 1000.0)\n",
    "    y_tick_interval = 250  # tick interval along y\n",
    "    v_lim = (0.0, 20000)\n",
    "    v_lim3 = (0.0, 20.0)\n",
    "    v_level = 50  # number of levels in contourf plot\n",
    "    v_tick_interval = 5000.0  # tick interval along v\n",
    "    v_tick_interval3 = 5.0  # tick interval along v\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # Create a figure with a 2x2 grid layout\n",
    "    fig = plt.figure(figsize=(12, 10), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "    # First plot Plot a colormap of T with contour\n",
    "    # Then a plot of sub_t inside the slab\n",
    "    # Add contour lines of T to the colormap\n",
    "    # Add quiver plot of assumed subducting velocity\n",
    "    levels = np.linspace(v_lim[0], v_lim[1], v_level)\n",
    "    ticks=np.arange(v_lim[0], v_lim[1], v_tick_interval)\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    color_map = ax.contourf(xv/1e3, yv/1e3, resolutions_grid,  vmin=v_lim[0], vmax=v_lim[1], levels=levels, cmap=\"plasma_r\")  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"Resolution\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    levels3 = np.linspace(v_lim3[0], v_lim3[1], v_level)\n",
    "    ticks3=np.arange(v_lim3[0], v_lim3[1], v_tick_interval3)\n",
    "    color_map3 = ax.contourf(xv/1e3, yv/1e3, t_sub_grid/year/1e6, vmin=v_lim3[0], vmax=v_lim3[1], levels=levels3, cmap=\"viridis\") # sub_t\n",
    "    # cbar3 = fig.colorbar(color_map3, ax=ax, label=\"time from trench (Ma)\")\n",
    "    # cbar3.set_ticks(ticks3)\n",
    "\n",
    "    contours = ax.contour(\n",
    "        xv/1e3, yv/1e3, T_grid-273.15, levels=np.arange(100.0, 1473.15 + 100.0, 200.0), colors=\"black\", linewidths=0.5\n",
    "    )\n",
    "    ax.clabel(contours, inline=True, fontsize=8, fmt=\"%.1f\")  # Add labels to the contours\n",
    "\n",
    "    # Quiver plot: maybe append at a last step of editing\n",
    "    # dip_angle_in_slab = np.interp(y_extent-yv_slab, depths, dip_angles)\n",
    "    # vx = subduct_velocity_cm_yr * np.cos(dip_angle_in_slab)\n",
    "    # vy = -subduct_velocity_cm_yr * np.sin(dip_angle_in_slab)\n",
    "    # skip = (slice(None, None, 40)) # plot with interval by skipping\n",
    "    # Q_map = ax.quiver(xv_slab[skip]/1e3, yv_slab[skip]/1e3, vx[skip], vy[skip], angles='xy', color=\"black\", scale=400.0*scaling_factor)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.plot((Xs + trench_x)/1e3, (y_max - depths)/1e3, \".\", markersize=2*scaling_factor, color=default_colors[0]) # slab surface\n",
    "    mask_l = np.abs((distance_grid - 100e3)) < 2e3\n",
    "    ax.plot(xv[mask_l]/1e3, yv[mask_l]/1e3, \".\", markersize=2*scaling_factor, color=default_colors[2]) # slab surface\n",
    "    ax.plot(foo_contour_Xs/1e3, foo_contour_Ys/1e3, '.',  markersize=2*scaling_factor, color=default_colors[3]) # internal profile\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X (km)\")\n",
    "    ax.set_ylabel(\"Y (km)\")\n",
    "\n",
    "    # Second plot: properties along the profile, P, T\n",
    "    T_lim = (400.0, 1200.0)\n",
    "    P_lim = (5.0, 25.0)\n",
    "    T_tick_interval = 100.0\n",
    "    P_tick_interval = 5.0\n",
    "    depth_lim = (300.0, 700)\n",
    "    depth_tick_inverval = 100.0\n",
    "\n",
    "    ax4 = fig.add_subplot(gs[0, 1])\n",
    "    ax4.plot(foo_contour_Ts-273.15, foo_contour_depths/1e3, linewidth=4*scaling_factor, color=default_colors[1], label=\"T\")\n",
    "\n",
    "\n",
    "    ax4.set_xlim(T_lim)\n",
    "    ax4.set_ylim(depth_lim)\n",
    "\n",
    "    ax4.xaxis.set_major_locator(MultipleLocator(T_tick_interval))\n",
    "    ax4.xaxis.set_minor_locator(MultipleLocator(T_tick_interval/(n_minor_ticks+1)))\n",
    "    ax4.yaxis.set_major_locator(MultipleLocator(depth_tick_inverval))\n",
    "    ax4.yaxis.set_minor_locator(MultipleLocator(depth_tick_inverval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax5 = ax4.twiny()\n",
    "    ax5.plot(foo_contour_Ps/1e9, foo_contour_depths/1e3, color=default_colors[1], label=\"P\")\n",
    "\n",
    "    ax5.set_xlim(P_lim)\n",
    "    ax5.set_ylim(depth_lim)\n",
    "\n",
    "    ax5.xaxis.set_major_locator(MultipleLocator(P_tick_interval))\n",
    "    ax5.xaxis.set_minor_locator(MultipleLocator(P_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax4.invert_yaxis()\n",
    "    ax4.grid()\n",
    "\n",
    "    ax5.legend()\n",
    "\n",
    "    ax4.set_xlabel(r\"Temperature ($^{\\circ}C$)\")\n",
    "    ax5.set_xlabel(\"Pressure (GPa)\")\n",
    "    ax4.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    q_depths = [400e3, 500e3, 600e3, 700e3] # print the time from subduction \n",
    "    for i, q_depth in enumerate(q_depths):\n",
    "        q_t_sub = np.interp(q_depth, depths, lengths) / subduct_velocity\n",
    "        print(\"Depth = %.1f km, t_sub = %.4e Ma\" % (q_depth/1e3, q_t_sub/year/1e6))\n",
    "\n",
    "    # Additional plot: slab morphology\n",
    "    # Create the first subplot for lengths\n",
    "    # Create a twin y-axis for dip angles\n",
    "    # Add legends and customize the plot\n",
    "    ax1 = fig.add_subplot(gs[1, 1])\n",
    "    color1 = 'tab:blue'\n",
    "    ax1.plot(depths/1e3, lengths/1e3, label=\"Lengths\", color=color1, linewidth=2)  # Plot lengths\n",
    "\n",
    "    ax1.set_xlim([0.0, 1000.0])\n",
    "    ax1.set_ylim([0.0, 1400.0])\n",
    "\n",
    "    x_tick_interval1 = 200.0; y_tick_interval1 = 200.0\n",
    "    ax1.xaxis.set_major_locator(MultipleLocator(x_tick_interval1))\n",
    "    ax1.xaxis.set_minor_locator(MultipleLocator(x_tick_interval1/(n_minor_ticks+1)))\n",
    "    ax1.yaxis.set_major_locator(MultipleLocator(y_tick_interval1))\n",
    "    ax1.yaxis.set_minor_locator(MultipleLocator(y_tick_interval1/(n_minor_ticks+1)))\n",
    "\n",
    "    ax1.set_xlabel(\"Depth (m)\")\n",
    "    ax1.set_ylabel(\"Lengths (m)\", color=color1)\n",
    "    ax1.tick_params(axis='y', labelcolor=color1)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color2 = 'tab:orange'\n",
    "    ax2.plot(depths/1e3, np.degrees(dip_angles), label=\"Dip Angles\", color=color2, linewidth=2.0*scaling_factor, linestyle=\"--\")  # Plot dip angles\n",
    "\n",
    "    ax2.set_ylim([0.0, 90.0])\n",
    "\n",
    "    y_tick_interval2 = 10.0\n",
    "    ax2.yaxis.set_major_locator(MultipleLocator(y_tick_interval2))\n",
    "    ax2.yaxis.set_minor_locator(MultipleLocator(y_tick_interval2/(n_minor_ticks+1)))\n",
    "\n",
    "    ax2.set_ylabel(\"Dip Angles (°)\", color=color2)\n",
    "    ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    ax1.set_title(\"Lengths and Dip Angles vs Depths\")\n",
    "    ax1.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # plot the subduction time\n",
    "\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "    ax3.plot((Xs + trench_x)/1e3, (y_max - depths)/1e3, \".\", markersize=2*scaling_factor, color=default_colors[0]) # slab surface\n",
    "    ax3.plot(xv[mask_l]/1e3, yv[mask_l]/1e3, \".\", markersize=2*scaling_factor, color=default_colors[2]) # slab surface\n",
    "\n",
    "    levels3 = np.linspace(v_lim3[0], v_lim3[1], v_level)\n",
    "    ticks3=np.arange(v_lim3[0], v_lim3[1], v_tick_interval3)\n",
    "    color_map3 = ax3.contourf(xv/1e3, yv/1e3, t_sub_grid/year/1e6, vmin=v_lim3[0], vmax=v_lim3[1], levels=levels3, cmap=\"viridis\") # sub_t\n",
    "    cbar3 = fig.colorbar(color_map3, ax=ax3, label=\"time from trench (Ma)\")\n",
    "    cbar3.set_ticks(ticks3)\n",
    "\n",
    "    ax3.set_xlim(x_lim)\n",
    "    ax3.set_ylim(y_lim)\n",
    "\n",
    "    ax3.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax3.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax3.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax3.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax3.set_xlabel(\"X (km)\")\n",
    "    ax3.set_ylabel(\"Y (km)\")\n",
    "\n",
    "    # Show figure\n",
    "    plt.show()\n",
    "\n",
    "    # Save figure to a PDF file\n",
    "    pdf_path = os.path.join(case_dir, \"T.pdf\")\n",
    "    fig.savefig(pdf_path)\n",
    "    print(\"Saved figure %s\" % pdf_path)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Plotting color map takes %.2f s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Adjust spine thickness for this plot\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    for spine in ax2.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    for spine in ax3.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    for spine in ax4.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    for spine in ax5.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive MO contents for the profile defined previously\n",
    "\n",
    "This script first queries into the position of the extracted profile with a distance to the surface. Then compute both the equilibrium phases and metastable phases\n",
    "\n",
    "Different methods\n",
    "\n",
    "1. Hosoya_2005, following the analytical method in Hosoya_2005\n",
    "2. Blocking temperature of 725 C, from Quiteros_Sobolev_2012\n",
    "3. Kinetics defined by metastable.py\n",
    "\n",
    "### Compute of latent heat\n",
    "\n",
    "We compute the latent heat release and the temperature change based on\n",
    "$$\n",
    "\\begin{aligned}\n",
    "C_p &= c_p\\, M, \\\\\n",
    "\\Delta T &= f \\frac{T\\,\\Delta S}{C_p}\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $c_p$ is the mass heat capacity, M is the molar mass. $C_p$ is the molar heat capacity, $\\Delta S$ is the change of entropy, T is the transition temperature. f is the volume fraction of transition. Here are the values of the variables:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "M &= 0.149\\ \\mathrm{kg\\,mol^{-1}}, \\quad \n",
    "c_p = 800 \\mathrm{Jkg^{-1}K^{-1}}\\\\\n",
    "\\Delta S &= 7.7\\ \\mathrm{J\\,mol^{-1}\\,K^{-1}}, \\quad\n",
    "T = 1740\\ \\mathrm{K}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Assuming fully transition:\n",
    "$\\Delta T = \\frac{1740 \\times 7.7}{120}\n",
    "\\approx 1.12 \\times 10^{2}\\ \\mathrm{K}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect:\n",
    "    from hamageolib.core.GrainSize import GrainGrowthModel, GrainGrowthParams\n",
    "    \n",
    "    ## Method 1: MO kinetics with a model\n",
    "    # MO_method = \"hosoya_2005\"; blocking_T = None; nucleation_type=1\n",
    "    # n_t = None; n_span = None\n",
    "    \n",
    "    ## Method 2: blocking temperature\n",
    "    # MO_method = \"blockT\";\n",
    "    # blocking_T = 725.0 + 273.15; nucleation_type=1;\n",
    "    # n_t=None; n_span = None\n",
    "\n",
    "    ## Method 3: Using the kinetic relations\n",
    "    MO_method = \"kinetics\"; blocking_T = None; nucleation_type=1; \n",
    "    n_t = 1; n_span = 10\n",
    "\n",
    "    Coh = 150.0 # wt% for methods with mo kinetics\n",
    "    d_ol = 10e-3 # m background grain size for methods with mo kinetics\n",
    "\n",
    "    # kinetics to use for post-transitio grain growth\n",
    "    use_post_grain_growth_kinetics = \"wadleyite\"\n",
    "\n",
    "    # whether to include latent heat\n",
    "    with_latent_heat = False\n",
    "\n",
    "    # affects the discretization in the following code blocks\n",
    "    # interval between contour of slab profiles. e.g. if set to 5e3, adjacent profiles have 3 km distance measured from the slab surface.\n",
    "    # use 0.5e3 to finalize plot\n",
    "    contour_interval = 0.5e3\n",
    "    # grid along x and y dimention in the final integrated grid\n",
    "    # use 400 to finalize plot and scale it with \"contour_interval\"\n",
    "    n_grid = 400\n",
    "\n",
    "\n",
    "    output_dir = os.path.join(case_dir, MO_method)\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    output_dir = os.path.join(output_dir, \"dol_%.2e_coh_%.1f_l_%d\" % (d_ol, Coh, with_latent_heat))\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    # initialize grain growth model\n",
    "    # make use of a synthetic relation\n",
    "    if use_post_grain_growth_kinetics == \"wadleyite\":\n",
    "        params = GrainGrowthParams(\n",
    "            grain_growth_rate_constant=3.02e-4,\n",
    "            m=3,\n",
    "            grain_growth_activation_energy=6.62e5,\n",
    "            grain_growth_activation_volume=0.0,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # equilibrium contents\n",
    "    foo_contents_wl_eq = np.zeros(foo_contour_Ts.shape)\n",
    "    foo_contents_wl_eq[foo_mask_eq] = 1.0\n",
    "\n",
    "    # metastable contents\n",
    "    foo_contents_wl_mo = None\n",
    "    if MO_method == \"blockT\":\n",
    "        foo_contents_wl_mo = foo_contents_wl_eq.copy()\n",
    "        foo_mask_mo = (foo_contour_Ts < blocking_T)\n",
    "        foo_contents_wl_mo[foo_mask_mo] = 0.0\n",
    "    elif MO_method == \"hosoya_2005\":\n",
    "        # initiate the kinetics class \n",
    "        _constants, _ = Meta.get_kinetic_constants(nucleation_type)\n",
    "        pTKinetics = Meta.PTKinetics(_constants)\n",
    "\n",
    "        growth_rates = np.zeros(foo_contour_Ps.shape)\n",
    "        mask = (foo_contour_Ps > foo_contour_Ps_eq)\n",
    "        growth_rates[mask] = pTKinetics.growth_rate_interface_P2(foo_contour_Ps[mask], foo_contour_Ts[mask],\\\n",
    "                                                                foo_contour_Ps_eq[mask], foo_contour_Ts_eq[mask], Coh)\n",
    "        foo_contents_wl_mo = MO_Vfraction_classic(growth_rates, foo_contour_ts, d_ol)\n",
    "    elif MO_method == \"kinetics\":\n",
    "        # initiate the kinetics class \n",
    "        _, _constants1 = Meta.get_kinetic_constants(nucleation_type)\n",
    "        Mo_Kinetics = Meta.MO_KINETICS(_constants1, post_process=[\"ts\", \"tg\"])\n",
    "        Mo_Kinetics.set_initial_grain_size(d_ol)\n",
    "\n",
    "        Mo_Kinetics.set_PT_eq(PT410['P'], PT410['T'], PT410['cl'])\n",
    "        Mo_Kinetics.link_and_set_kinetics_model(Meta.PTKinetics)\n",
    "\n",
    "        # set metastable contents along the profile\n",
    "        foo_contents_wl_mo = np.zeros(foo_contour_Ps.size)\n",
    "        foo_contents_wl_gz = np.zeros(foo_contour_Ps.size)\n",
    "        time_saturated = None # time of site situation, initialize as None\n",
    "        depth_saturated = None\n",
    "        is_saturated = False # flag to record site situation\n",
    "        for i in range(foo_contour_Ps.size-1):\n",
    "            # parse variables:\n",
    "            # P, T\n",
    "            # t0, t1 - start and end of the time step\n",
    "            P = foo_contour_Ps[i]\n",
    "            T = foo_contour_Ts[i]\n",
    "            depth0 = foo_contour_depths[i]\n",
    "            depth1 = foo_contour_depths[i+1]\n",
    "            t0 = foo_contour_ts[i]\n",
    "            t1 = foo_contour_ts[i+1]\n",
    "            Mo_Kinetics.set_kinetics_fixed(P, T, Coh)\n",
    "\n",
    "            # solve the ODEs\n",
    "            if i == 0:\n",
    "                _initial = None\n",
    "            else:\n",
    "                _initial = results[-1, :]\n",
    "            results = Mo_Kinetics.solve(P, T, t0, t1, n_t, n_span, initial=_initial)\n",
    "\n",
    "            # extract useful results\n",
    "            volume_fraction = results[-1, 5]\n",
    "            grain_density = results[-1, 1]\n",
    "            saturation_time = results[-1, 7]\n",
    "\n",
    "            # record volume fraction and grain size\n",
    "            foo_contents_wl_mo[i+1] = volume_fraction\n",
    "            foo_contents_wl_gz[i+1] = 2.0 * (volume_fraction / grain_density / (4.0/3.0 * np.pi))**(1.0/3.0)\n",
    "\n",
    "            # use latent heat release to modify temperature profile\n",
    "            if with_latent_heat:\n",
    "                _, dT = Mo_Kinetics.compute_latent_heat(T, volume_fraction)\n",
    "                foo_contour_Ts[i+1] += dT\n",
    "\n",
    "            # determine site situation and time of situation\n",
    "            is_saturated_a = results[-1, 6]\n",
    "            if not is_saturated and np.allclose(is_saturated_a, 1.0, rtol=1e-6):\n",
    "                time_saturated = t0 + results[-1, 7] # time of site situation\n",
    "                depth_saturated = depth0 + (depth1 - depth0) * saturation_time / (t1 - t0)\n",
    "                is_saturated = True\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect:\n",
    "\n",
    "    # Initialize plots\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    from matplotlib import gridspec\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (0.0, 1.0) # volume fraction\n",
    "    # x_lim1 = (0.0, 1.0) # time in Ma\n",
    "    # x_tick_interval1 = 0.25  \n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # Create a new figure and axis\n",
    "    fig = plt.figure(figsize=(8, 8), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "    # Plot transfered volumn and grain size\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    ax_1 = ax.twiny()\n",
    "    \n",
    "    ax.plot(foo_contents_wl_mo, foo_contour_depths/1e3, linestyle=\"-\", color=default_colors[2], label=\"Contents Wd MO (%s)\" % MO_method)\n",
    "    ax.plot(foo_contents_wl_eq, foo_contour_depths/1e3,  linestyle=\"-\", color=default_colors[2], label=\"Contents Wd EQ\")\n",
    "    ax.axhline(depth_saturated/1e3, linestyle=\"-.\", color=default_colors[2], label=\"Site Situation\")\n",
    "    ax_1.plot(np.log10(foo_contents_wl_gz), foo_contour_depths/1e3,  \".\", color=default_colors[2], label=\"Grain Size Wd MO (%s)\" % MO_method)\n",
    "\n",
    "    ax.set_xlim([0, 1.04])\n",
    "    ax.set_ylim([300, 600])\n",
    "\n",
    "    y_tick_interval = 100; x_tick_interval = 0.2\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"Transformed Volume\")\n",
    "    ax.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    \n",
    "    ax_1.set_xlabel(\"Grain Size\")\n",
    "\n",
    "    # ax_1.set_ylim([-10, 0.4])\n",
    "    ax_1.set_xlim([-8, -5.5+0.1])\n",
    "\n",
    "    x_tick_interval = 0.5\n",
    "    ax_1.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax_1.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    for spine in ax_1.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # Plot subduction time\n",
    "    ax1 = fig.add_subplot(gs[0, 1])\n",
    "    \n",
    "    ax1.plot(foo_contour_ts/year/1e6, foo_contour_depths/1e3, linestyle=\"-\", color=default_colors[2], label=\"Subducting Time (%s)\" % MO_method)\n",
    "\n",
    "    # ax1.set_xlim(x_lim1)\n",
    "    ax1.set_ylim((300.0, 600.0))\n",
    "\n",
    "    x_tick_interval = 0.25   # tick interval along x\n",
    "    y_tick_interval = 100  # tick interval along y\n",
    "    # ax1.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    # ax1.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax1.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax1.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax1.set_xlabel(\"Time (Ma)\")\n",
    "    ax1.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax1.invert_yaxis()\n",
    "\n",
    "    ax1.legend()\n",
    "\n",
    "    ax1.grid()\n",
    "    \n",
    "    for spine in ax1.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Plot subduction time vs transformed volume\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    ax2.plot(foo_contour_ts/year/1e6, foo_contents_wl_mo, linestyle=\"-\", color=default_colors[2], label=\"Contents Wd MO (%s)\" % MO_method)\n",
    "    ax2.axvline(time_saturated/year/1e6, linestyle=\"-.\", color=default_colors[2], label=\"Site situation\")\n",
    "\n",
    "    ax2.set_xlim((6.0, 16.0))\n",
    "    ax2.set_ylim((0.0, 1.04))\n",
    "\n",
    "    x_tick_interval = 1.0   # tick interval along x\n",
    "    y_tick_interval = 0.25  # tick interval along y\n",
    "    ax2.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax2.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax2.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax2.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax2.set_xlabel(\"Time (Ma)\")\n",
    "    ax2.set_ylabel(\"Transformed Volume\")\n",
    "\n",
    "    ax2.legend()\n",
    "\n",
    "    ax2.grid()\n",
    "    \n",
    "    for spine in ax2.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Plot P and T with depth\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    ax3.plot(foo_contour_Ts - 273.15, foo_contour_depths/1e3, linestyle=\"-\", color=default_colors[2], label=\"Temperature (Latent Heat = %d)\" % with_latent_heat)\n",
    "    ax3.set_xlim([400, 1200.0])\n",
    "    ax3.set_ylim([300.0, 600.0])\n",
    "    ax3.invert_yaxis()\n",
    "    ax3.set_xlabel(\"Temperature (C)\")\n",
    "    ax3.set_ylabel(\"Depth (km)\")\n",
    "    x_tick_interval = 100.0   # tick interval along x\n",
    "    y_tick_interval = 100.0  # tick interval along y\n",
    "    ax3.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax3.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax3.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax3.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "    ax3.grid()\n",
    "    ax3.legend()\n",
    "\n",
    "\n",
    "    # Save figure\n",
    "    pdf_path = os.path.join(output_dir, \"profile_Wd_contents_%s_%.1fkm.pdf\" % (MO_method, contour_distance[0]/1e3))\n",
    "    fig.savefig(pdf_path)\n",
    "    print(\"Saved figure %s\" % pdf_path)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical test: stepping variable\n",
    "\n",
    "Here we test the numerical effects of the stepping variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_run_stepping_test = False\n",
    "if is_run_aspect and is_run_stepping_test:\n",
    "\n",
    "    # test parameters \n",
    "    n_t = 1\n",
    "    n_span_array = [2, 3, 5, 10, 20]\n",
    "\n",
    "    # array to save test results\n",
    "    foo_contents_wl_mo_array = []    \n",
    "\n",
    "    # run profile analysis on different parameters \n",
    "    for i, n_span in enumerate(n_span_array):\n",
    "        # initiate the kinetics class \n",
    "        _, _constants1 = Meta.get_kinetic_constants(nucleation_type)\n",
    "        Mo_Kinetics = Meta.MO_KINETICS(_constants1)\n",
    "        Mo_Kinetics.set_initial_grain_size(d_ol)\n",
    "\n",
    "        Mo_Kinetics.set_PT_eq(PT410['P'], PT410['T'], PT410['cl'])\n",
    "        Mo_Kinetics.link_and_set_kinetics_model(Meta.PTKinetics)\n",
    "\n",
    "        # set metastable contents along the profile\n",
    "        foo_contents_wl_mo = np.zeros(foo_contour_Ps.size)\n",
    "        for i in range(foo_contour_Ps.size-1):\n",
    "            # parse variables:\n",
    "            # P, T\n",
    "            # t0, t1 - start and end of the time step\n",
    "            P = foo_contour_Ps[i]\n",
    "            T = foo_contour_Ts[i]\n",
    "            t0 = foo_contour_ts[i]\n",
    "            t1 = foo_contour_ts[i+1]\n",
    "            Mo_Kinetics.set_kinetics_fixed(P, T, Coh)\n",
    "\n",
    "            # solve the ODEs\n",
    "            if i == 0:\n",
    "                _initial = None\n",
    "            else:\n",
    "                _initial = results[-1, :]\n",
    "            results = Mo_Kinetics.solve(P, T, t0, t1, n_t, n_span, initial=_initial)\n",
    "            # results = Mo_Kinetics.solve(P, T, 0, t1, n_t, n_span)\n",
    "            foo_contents_wl_mo[i+1] = results[-1, 5]\n",
    "        \n",
    "        foo_contents_wl_mo_array.append(foo_contents_wl_mo)\n",
    "\n",
    "    # assess the differences\n",
    "    # use the last result as standard\n",
    "    i_query = 238\n",
    "    print(\"Depth = \", foo_contour_depths[i_query])  # output\n",
    "    print(\"ts = %.4e Ma\" % (foo_contour_ts[i_query]/year/1e6))\n",
    "    \n",
    "    foo_contents_wl_mo_std = foo_contents_wl_mo_array[-1] \n",
    "    std_result = foo_contents_wl_mo_std[i_query]\n",
    "\n",
    "    foo_contents_wl_mo_q_array = [] # array to solve the query results\n",
    "    foo_relative_error_q_array = []\n",
    "    for i, foo_contents_wl_mo in enumerate(foo_contents_wl_mo_array):\n",
    "\n",
    "        query_result = foo_contents_wl_mo[i_query]\n",
    "        relative_error = np.abs((query_result - std_result)/std_result)\n",
    "\n",
    "        foo_contents_wl_mo_q_array.append(query_result)\n",
    "        foo_relative_error_q_array.append(relative_error)\n",
    "        \n",
    "        print(\"    i = \", i) # output\n",
    "        print(\"    foo_contents_wl_mo[%d] = \" % i_query)\n",
    "        print(foo_contents_wl_mo[i_query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect and is_run_stepping_test:\n",
    "\n",
    "    # Initialize plots\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    from matplotlib import gridspec\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (0.0, 20) # volume fraction\n",
    "    x_tick_interval = 5   # tick interval along x\n",
    "    y_lim1 = (0.0, 0.2) # Relative error\n",
    "    y_tick_interval1 = 0.05\n",
    "    y_lim = (0.4, 0.5)\n",
    "    y_tick_interval = 0.025  # tick interval along y\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # Plot the solution and relative error in twin axis\n",
    "    fig, ax = plt.subplots(figsize = (8*scaling_factor, 5*scaling_factor))\n",
    "\n",
    "    ax.plot(n_span_array, foo_contents_wl_mo_q_array, color=default_colors[0])\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax.set_xlabel(\"stepping\")\n",
    "    ax.set_ylabel(\"Transformed Volume\")\n",
    "\n",
    "    # Adjust spine thickness for this plot\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    ax1 = ax.twinx()\n",
    "    \n",
    "    ax1.plot(n_span_array, foo_relative_error_q_array, color=default_colors[1])\n",
    "    \n",
    "    ax1.set_xlim(x_lim)\n",
    "    ax1.set_ylim(y_lim1)\n",
    "\n",
    "    ax1.yaxis.set_major_locator(MultipleLocator(y_tick_interval1))\n",
    "    ax1.yaxis.set_minor_locator(MultipleLocator(y_tick_interval1/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax1.set_ylabel(\"Relative Error\")\n",
    "\n",
    "    ax.grid() # turn on grid\n",
    "\n",
    "    # Save figure\n",
    "    pdf_path = os.path.join(output_dir, \"Wd_contants_convergence_%.1fkm.pdf\" % (contour_distance[0]/1e3))\n",
    "    fig.savefig(pdf_path)\n",
    "    print(\"Saved figure %s\" % pdf_path)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive contents with multiple curvatures and interpolate back to a 2d grid\n",
    "\n",
    "Here we make multiple profiles by different distance from the slab surface. And then connect them by interpolation back to a 2-d grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive P, T conditions of the profiles; compute kinetics; and interpolate to 2-d grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect:\n",
    "\n",
    "    from scipy.spatial import cKDTree\n",
    "    from scipy.interpolate import griddata\n",
    "    from hamageolib.core.GrainSize import GrainGrowthModel, GrainGrowthParams\n",
    "\n",
    "    def interpolate_grid_from_points(solution_Xs, solution_Ys, solution_Zs, spacing, distance_threshold):\n",
    "        # Create a 2D regular grid\n",
    "        x_min, x_max = solution_Xs.min(), solution_Xs.max()\n",
    "        y_min, y_max = solution_Ys.min(), solution_Ys.max()\n",
    "\n",
    "        # Define grid resolution\n",
    "        grid_x, grid_y = np.meshgrid(\n",
    "            np.arange(x_min, x_max, spacing),\n",
    "            np.arange(y_min, y_max, spacing)\n",
    "        )\n",
    "\n",
    "        # Flatten the grid points for easier querying\n",
    "        grid_points = np.column_stack((grid_x.ravel(), grid_y.ravel()))\n",
    "\n",
    "        # Build a KDTree with the original data points\n",
    "        tree = cKDTree(np.column_stack((solution_Xs, solution_Ys)))\n",
    "\n",
    "        # Query nearest neighbors for each grid point\n",
    "        distances, indices = tree.query(grid_points, distance_upper_bound=distance_threshold)\n",
    "\n",
    "        # Initialize grid values with NaN\n",
    "        grid_z = np.full(grid_points.shape[0], np.nan)\n",
    "\n",
    "        # Assign values only for points within the threshold\n",
    "        valid_mask = distances <= distance_threshold\n",
    "        grid_z[valid_mask] = solution_Zs[indices[valid_mask]]\n",
    "\n",
    "        # Reshape the result to match the grid\n",
    "        grid_z = grid_z.reshape(grid_x.shape)\n",
    "\n",
    "        return grid_x, grid_y, grid_z\n",
    "\n",
    "\n",
    "    # Generate contours at specified distances from the slab surface\n",
    "    # Specify a distance in between\n",
    "    contour_distance_array = np.arange(0, 100e3, contour_interval)\n",
    "\n",
    "    solution_Xs = np.array([])\n",
    "    solution_Ys = np.array([])\n",
    "    solution_wl_eq = np.array([])\n",
    "    solution_wl_mo = np.array([])\n",
    "    solution_wl_gz_log = np.array([])\n",
    "    solution_wl_gz_pg_log = np.array([])\n",
    "    contour_traces = [[] for i in range(contour_distance_array.size)]\n",
    "\n",
    "    # initiate class for gz evolution\n",
    "    use_kinetics_for_gz = \"wadleyite\"\n",
    "    if use_kinetics_for_gz == \"wadleyite\":\n",
    "        params = GrainGrowthParams(\n",
    "            grain_growth_rate_constant=3.02e-4,\n",
    "            m=3,\n",
    "            grain_growth_activation_energy=6.62e5,\n",
    "            grain_growth_activation_volume=0.0,\n",
    "        )\n",
    "    elif use_kinetics_for_gz == \"default\":\n",
    "        params = GrainGrowthParams(\n",
    "            grain_growth_rate_constant=4e-45,\n",
    "            m=10,\n",
    "            grain_growth_activation_energy=3e5,\n",
    "            grain_growth_activation_volume=0.0,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    gModel = GrainGrowthModel(params=params)\n",
    "\n",
    "    # Generate Grid results for equilibrium phase transitions\n",
    "    contents_wl_eq_grid = np.zeros(xv.shape)\n",
    "    P_eq_grid = (T_grid - PT410[\"T\"]) * PT410[\"cl\"] + PT410[\"P\"]\n",
    "    mask_eq_grid = ( P_grid > P_eq_grid)\n",
    "    contents_wl_eq_grid[mask_eq_grid] = 1.0\n",
    "\n",
    "    # Compute profile-wise results for metastable phase transitions\n",
    "    # First, initiate classes\n",
    "    pTKinetics = None; Mo_Kinetics = None\n",
    "    if MO_method == \"blockT\":\n",
    "        pass\n",
    "    elif MO_method == \"hosoya_2005\":\n",
    "        _constants, _ = Meta.get_kinetic_constants(nucleation_type)\n",
    "        pTKinetics = Meta.PTKinetics(_constants)\n",
    "    elif MO_method == \"kinetics\":\n",
    "        _, _constants1 = Meta.get_kinetic_constants(nucleation_type)\n",
    "        Mo_Kinetics = Meta.MO_KINETICS(_constants1)\n",
    "        Mo_Kinetics.set_initial_grain_size(d_ol)\n",
    "\n",
    "        Mo_Kinetics.set_PT_eq(PT410['P'], PT410['T'], PT410['cl'])\n",
    "        Mo_Kinetics.link_and_set_kinetics_model(Meta.PTKinetics)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    for i_prof in range(contour_distance_array.size):\n",
    "        contour_distance_1 = contour_distance_array[i_prof]\n",
    "        contour_Xs, contour_Ys = offset_curve(Xs + trench_x, y_max - depths, contour_distance_1)\n",
    "\n",
    "        grid_points_2d = np.vstack([contour_Xs.ravel(), contour_Ys.ravel()]).T\n",
    "\n",
    "        contour_Ts = interpolator(grid_points_2d)\n",
    "        contour_Ps = interpolator_P(grid_points_2d)\n",
    "\n",
    "        contour_Ps_eq = (contour_Ts - PT410[\"T\"]) * PT410[\"cl\"] + PT410[\"P\"]\n",
    "        contour_Ts_eq = (contour_Ps - PT410[\"P\"]) / PT410[\"cl\"] + PT410[\"T\"]\n",
    "\n",
    "        mask_eq = (contour_Ps > contour_Ps_eq)\n",
    "\n",
    "        contour_ts = lengths / subduct_velocity\n",
    "\n",
    "        # equilibrium contents\n",
    "        contents_wl_eq = np.zeros(contour_Ts.shape)\n",
    "        contents_wl_eq[mask_eq] = 1.0\n",
    "\n",
    "        # metastable contents\n",
    "        contents_wl_mo = None\n",
    "        if MO_method == \"blockT\":\n",
    "            contents_wl_mo = contents_wl_eq.copy()\n",
    "            mask_mo = (contour_Ts < blocking_T)\n",
    "            contents_wl_mo[mask_mo] = 0.0\n",
    "        elif MO_method == \"hosoya_2005\":\n",
    "            # compute growth rate and then solve for metastable contents\n",
    "            growth_rates = np.zeros(contour_Ps.shape)\n",
    "            mask = (contour_Ps > contour_Ps_eq)\n",
    "        \n",
    "            growth_rates[mask] = pTKinetics.growth_rate_interface_P2(contour_Ps[mask], contour_Ts[mask],\\\n",
    "                                                                contour_Ps_eq[mask], contour_Ts_eq[mask], Coh)\n",
    "            contents_wl_mo = MO_Vfraction_classic(growth_rates, contour_ts, d_ol)\n",
    "        elif MO_method == \"kinetics\":\n",
    "            # compute metastable contents along the profile\n",
    "            contents_wl_mo = np.zeros(contour_Ps.size)\n",
    "            contents_wl_gz_log = np.zeros(contour_Ps.size)\n",
    "            contents_wl_gz_pg_log = np.zeros(contour_Ps.size)\n",
    "            for i_p in range(contour_Ps.size-1):\n",
    "                # parse variables:\n",
    "                # P, T\n",
    "                # t0, t1 - start and end of the time step\n",
    "                P = (contour_Ps[i_p] + contour_Ps[i_p+1])/2.0\n",
    "                T = (contour_Ts[i_p] + contour_Ts[i_p+1])/2.0\n",
    "                t0 = contour_ts[i_p]\n",
    "                t1 = contour_ts[i_p+1]\n",
    "                Mo_Kinetics.set_kinetics_fixed(P, T, Coh)\n",
    "\n",
    "                # solve the ODEs\n",
    "                if i_p == 0:\n",
    "                    _initial = None\n",
    "                else:\n",
    "                    _initial = results[-1, :]\n",
    "                results = Mo_Kinetics.solve(P, T, t0, t1, n_t, n_span, initial=_initial)\n",
    "                # results = Mo_Kinetics.solve(P, T, 0, t1, n_t, n_span)\n",
    "\n",
    "                # extract useful variables\n",
    "                metastable = results[-1, 5]\n",
    "                grain_density = results[-1, 1]\n",
    "\n",
    "                # record transformed volume, grain size\n",
    "                contents_wl_mo[i_p+1] = metastable\n",
    "                if metastable > 0.01:\n",
    "                    initial_grain_size = (6.0 * metastable / grain_density / np.pi)**(1.0/3.0)\n",
    "                    P_for_grain_size = contour_Ps[i_p+1] \n",
    "                    T_for_grain_size = contour_Ts[i_p+1]\n",
    "                    t_for_grain_size = 1e6 * year\n",
    "                    contents_wl_gz_log[i_p+1] = np.log10(initial_grain_size)\n",
    "                    contents_wl_gz_pg_log[i_p+1] = np.log10(gModel.grain_size_at_time(initial_grain_size, 1e6*year, P_for_grain_size, T_for_grain_size))\n",
    "                else:\n",
    "                    contents_wl_gz_log[i_p+1] = np.nan \n",
    "                    contents_wl_gz_pg_log[i_p+1] = np.nan\n",
    "\n",
    "                # derive latent heat release\n",
    "                if with_latent_heat:\n",
    "                    _, dT = Mo_Kinetics.compute_latent_heat(T, metastable)\n",
    "                    contour_Ts[i_p+1] += dT\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        # append to a solution\n",
    "        solution_Xs = np.concatenate([solution_Xs, contour_Xs])\n",
    "        solution_Ys = np.concatenate([solution_Ys, contour_Ys])\n",
    "        solution_wl_eq = np.concatenate([solution_wl_eq, contents_wl_eq])\n",
    "        solution_wl_mo = np.concatenate([solution_wl_mo, contents_wl_mo])\n",
    "        solution_wl_gz_log = np.concatenate([solution_wl_gz_log, contents_wl_gz_log])\n",
    "        solution_wl_gz_pg_log = np.concatenate([solution_wl_gz_pg_log, contents_wl_gz_pg_log])\n",
    "        contour_traces[i_prof] += [contour_Xs, contour_Ys, contents_wl_eq, contents_wl_mo,\\\n",
    "                                   contents_wl_gz_log, contents_wl_gz_pg_log, contour_Ps, contour_Ts]\n",
    "\n",
    "    # interpolate solution to a grid\n",
    "    xi = np.linspace(solution_Xs.min(), solution_Xs.max(), n_grid+1)\n",
    "    yi = np.linspace(solution_Ys.min(), solution_Ys.max(), n_grid-1)\n",
    "\n",
    "\n",
    "    solution_X_grid, solution_Y_grid = np.meshgrid(xi, yi)\n",
    "\n",
    "    solution_distance_grid = distances_to_curve(Xs + trench_x, y_max - depths, solution_X_grid.ravel(), solution_Y_grid.ravel())\n",
    "    solution_distance_grid = solution_distance_grid.reshape(solution_X_grid.shape)\n",
    "    mask_slab_grid = (solution_distance_grid >= -5e3) & (solution_distance_grid <= 100e3)  # Slab internal region: -5 km to 100 km\n",
    "\n",
    "    # Interpolate the scattered data\n",
    "    solution_wl_mo_grid = griddata(\n",
    "        (solution_Xs, solution_Ys),\n",
    "        solution_wl_mo,\n",
    "        (solution_X_grid, solution_Y_grid),\n",
    "        method='linear'   # or 'cubic' for even smoother\n",
    "    )\n",
    "    solution_wl_mo_grid[~mask_slab_grid] = np.nan # set nan value for value out of the slab\n",
    "\n",
    "    # Interpolate the initial grain size\n",
    "    solution_wl_gz_log_grid = griddata(\n",
    "        (solution_Xs, solution_Ys),\n",
    "        solution_wl_gz_log,\n",
    "        (solution_X_grid, solution_Y_grid),\n",
    "        method='linear'   # or 'cubic' for even smoother\n",
    "    )\n",
    "    solution_wl_gz_log_grid[~mask_slab_grid] = np.nan # set nan value for value out of the slab\n",
    "    \n",
    "    # Interpolate the grain size after grain growth\n",
    "    solution_wl_gz_pg_log_grid = griddata(\n",
    "        (solution_Xs, solution_Ys),\n",
    "        solution_wl_gz_pg_log,\n",
    "        (solution_X_grid, solution_Y_grid),\n",
    "        method='linear'   # or 'cubic' for even smoother\n",
    "    )\n",
    "    solution_wl_gz_pg_log_grid[~mask_slab_grid] = np.nan # set nan value for value out of the slab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the transformed volumen, grain size, in 2-d grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect:\n",
    "\n",
    "    # Initialize plots\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    import matplotlib.ticker as ticker\n",
    "    from matplotlib import gridspec\n",
    "    from cmcrameri import cm as ccm\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (0.0, 1000.0)\n",
    "    x_tick_interval = 250   # tick interval along x\n",
    "    y_lim = (0.0, 1000.0)\n",
    "    y_tick_interval = 250  # tick interval along y\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    # Plot equilibrium & metastable phase transition\n",
    "    fig = plt.figure(figsize=(8, 24), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(4, 1)\n",
    "\n",
    "    # Equilibrium phases outside of the slab\n",
    "    # Metastable phases inside the slab\n",
    "    #   1. use the scatter plot from calculated points\n",
    "    #   2. use the contourf plot from the grid data\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    color_map3 = ax.contourf(xv/1e3, (y_extent - yv)/1e3, contents_wl_eq_grid, levels=100, cmap=\"viridis\", vmin=0.0, vmax=1.0)\n",
    "    cbar3 = fig.colorbar(color_map3, ax=ax, label=\"Wd contents\")\n",
    "    cbar3.set_ticks([0.0, 0.5, 1.0]) # colorbar ticks options\n",
    "    minor_locator = ticker.MultipleLocator(0.1)  # This gives 4 minor ticks between major ticks spaced by 0.5\n",
    "    cbar3.ax.yaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "    ax.plot((Xs + trench_x)/1e3, depths/1e3, \"--k\") # slab surface\n",
    "    ax.plot(contour_traces[-1][0]/1e3, (y_extent - contour_traces[-1][1])/1e3, \"--k\") # slab surface\n",
    "    # contours = ax.contour(xv, yv, distance_grid, levels=[0, 100e3], colors=['black', 'black'], linewidths=2) # curve of the slab\n",
    "\n",
    "    contours = ax.contour(\n",
    "        xv/1e3, (y_extent - yv)/1e3, T_grid-273.15, levels=np.arange(100.0, 1473.15 + 100.0, 200.0), colors=\"black\", linewidths=0.5\n",
    "    ) # temperature contours\n",
    "    ax.clabel(contours, inline=True, fontsize=8, fmt=\"%.1f\")  # Add labels to the contours\n",
    "\n",
    "    # ax.scatter(solution_Xs/1e3, (y_extent - solution_Ys)/1e3, c=solution_wl_mo, cmap='viridis', s=20, vmin=0.0, vmax=1.0) # slab surface\n",
    "    cset = ax.contourf(solution_X_grid/1e3, (y_extent - solution_Y_grid)/1e3, solution_wl_mo_grid, levels=50, cmap='viridis', vmin=0.0, vmax=1.0)\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_xlabel(\"X (km)\")\n",
    "    ax.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "    # Equilibrium & metastable phases, zoom in\n",
    "    ax1 = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "    color_map1 = ax1.contourf(xv/1e3, (y_extent - yv)/1e3, contents_wl_eq_grid, levels=200, cmap=\"viridis\", vmin=0.0, vmax=1.0)\n",
    "    cbar1 = fig.colorbar(color_map1, ax=ax1, label=\"Wd contents\")\n",
    "    cbar1.set_ticks([0.0, 0.5, 1.0]) # colorbar ticks options\n",
    "    minor_locator = ticker.MultipleLocator(0.1)  # This gives 4 minor ticks between major ticks spaced by 0.5\n",
    "    cbar1.ax.yaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "    ax1.plot((Xs + trench_x)/1e3, depths/1e3, \"--k\") # slab surface\n",
    "    ax1.plot(contour_traces[-1][0]/1e3, (y_extent - contour_traces[-1][1])/1e3, \"--k\") # slab surface\n",
    "\n",
    "    # ax1.scatter(solution_Xs/1e3, (y_extent - solution_Ys)/1e3, c=solution_wl_mo, cmap='viridis', s=20, vmin=0.0, vmax=1.0) # slab surface\n",
    "    ax1.contourf(solution_X_grid/1e3, (y_extent - solution_Y_grid)/1e3, solution_wl_mo_grid, levels=50, cmap='viridis', vmin=0.0, vmax=1.0)\n",
    "\n",
    "    cset1 = ax1.contour(solution_X_grid/1e3, (y_extent - solution_Y_grid)/1e3, solution_wl_mo_grid,\\\n",
    "                        levels=(0.01, 0.5, 0.99), colors=[\"lightblue\", \"pink\", \"black\"])\n",
    "\n",
    "    # x_center = np.interp(500e3, y_max - depths, Xs + trench_x) # find the pin point center, issue: interpolation doesn't work\n",
    "    x_center = 700\n",
    "\n",
    "    ax1.set_xlim([x_center-200, x_center+200])\n",
    "    ax1.set_ylim([300, 700])\n",
    "\n",
    "    contours = ax1.contour(\n",
    "        xv/1e3, (y_extent - yv)/1e3, T_grid-273.15, levels=np.arange(100.0, 1473.15 + 100.0, 200.0), colors=\"black\", linewidths=0.5\n",
    "    ) # temperature contours\n",
    "    ax1.clabel(contours, inline=True, fontsize=8, fmt=\"%.1f\")  # Add labels to the contours\n",
    "\n",
    "    x_tick_interval1 = 100.0\n",
    "    y_tick_interval1 = 100.0\n",
    "    ax1.xaxis.set_major_locator(MultipleLocator(x_tick_interval1))\n",
    "    ax1.xaxis.set_minor_locator(MultipleLocator(x_tick_interval1/(n_minor_ticks+1)))\n",
    "    ax1.yaxis.set_major_locator(MultipleLocator(y_tick_interval1))\n",
    "    ax1.yaxis.set_minor_locator(MultipleLocator(y_tick_interval1/(n_minor_ticks+1)))\n",
    "\n",
    "    ax1.invert_yaxis()\n",
    "\n",
    "    ax1.set_xlabel(\"X (km)\")\n",
    "    ax1.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax1.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    \n",
    "    # metastable grain sizes, zoom in\n",
    "    ax2 = fig.add_subplot(gs[2, 0])\n",
    "\n",
    "    levels = np.linspace(-10, 0, 200)\n",
    "    color_map1 = ax2.contourf(\n",
    "        solution_X_grid / 1e3,\n",
    "        (y_extent - solution_Y_grid) / 1e3,\n",
    "        solution_wl_gz_log_grid,\n",
    "        levels=levels,\n",
    "        cmap=ccm.devon,\n",
    "        vmin=-10,\n",
    "        vmax=0,\n",
    "        extend=\"both\"\n",
    "    )\n",
    "    cbar2 = fig.colorbar(color_map1, ax=ax2, label=\"Wd grain size\")\n",
    "    cbar2.set_ticks([-10, -5, 0])\n",
    "    minor_locator = ticker.MultipleLocator(1.0)\n",
    "    cbar2.ax.yaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "    contours_gz = ax2.contour(\n",
    "        solution_X_grid / 1e3, (y_extent - solution_Y_grid) / 1e3, solution_wl_gz_log_grid, levels=[-4], colors=\"red\", linewidths=2.0\n",
    "    ) # grain size contours\n",
    "    contours_gz = ax2.contour(\n",
    "        solution_X_grid / 1e3, (y_extent - solution_Y_grid) / 1e3, solution_wl_gz_log_grid, levels=[-5], colors=\"purple\", linewidths=1.0\n",
    "    )\n",
    "\n",
    "    # todo_letend\n",
    "    ax2.plot((Xs + trench_x)/1e3, depths/1e3, \"--k\") # slab surface\n",
    "    ax2.plot(contour_traces[-1][0]/1e3, (y_extent - contour_traces[-1][1])/1e3, \"--k\") # slab surface \n",
    "    cset2 = ax2.contour(solution_X_grid/1e3, (y_extent - solution_Y_grid)/1e3, solution_wl_mo_grid,\\\n",
    "                        levels=(0.01, 0.5, 0.99), colors=[\"lightblue\", \"pink\", \"black\"],) # mestastable contour 0.5\n",
    "\n",
    "    # ax2.contourf(solution_X_grid/1e3, (y_extent - solution_Y_grid)/1e3, solution_wl_mo_grid, levels=50, cmap='viridis', vmin=0.0, vmax=1.0)\n",
    "    # cset1 = ax2.contour(solution_X_grid/1e3, (y_extent - solution_Y_grid)/1e3, solution_wl_mo_grid, levels=(0.5,))\n",
    "\n",
    "    # x_center = np.interp(500e3, y_max - depths, Xs + trench_x) # find the pin point center, issue: interpolation doesn't work\n",
    "    x_center = 700\n",
    "\n",
    "    ax2.set_xlim([x_center-200, x_center+200])\n",
    "    ax2.set_ylim([300, 700])\n",
    "\n",
    "    contours = ax2.contour(\n",
    "        xv/1e3, (y_extent - yv)/1e3, T_grid-273.15, levels=np.arange(100.0, 1473.15 + 100.0, 200.0), colors=\"black\", linewidths=0.5\n",
    "    ) # temperature contours\n",
    "    ax2.clabel(contours, inline=True, fontsize=8, fmt=\"%.1f\")  # Add labels to the contours\n",
    "\n",
    "    x_tick_interval1 = 100.0\n",
    "    y_tick_interval1 = 100.0\n",
    "    ax2.xaxis.set_major_locator(MultipleLocator(x_tick_interval1))\n",
    "    ax2.xaxis.set_minor_locator(MultipleLocator(x_tick_interval1/(n_minor_ticks+1)))\n",
    "    ax2.yaxis.set_major_locator(MultipleLocator(y_tick_interval1))\n",
    "    ax2.yaxis.set_minor_locator(MultipleLocator(y_tick_interval1/(n_minor_ticks+1)))\n",
    "\n",
    "    ax2.invert_yaxis()\n",
    "\n",
    "    ax2.set_xlabel(\"X (km)\")\n",
    "    ax2.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax2.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "    # metastable grain sizes after post-metastable grain growth, zoom in\n",
    "    ax3 = fig.add_subplot(gs[3, 0])\n",
    "\n",
    "    levels = np.linspace(-10, 0, 200)\n",
    "    color_map1 = ax3.contourf(\n",
    "        solution_X_grid / 1e3,\n",
    "        (y_extent - solution_Y_grid) / 1e3,\n",
    "        solution_wl_gz_pg_log_grid,\n",
    "        levels=levels,\n",
    "        cmap=ccm.devon,\n",
    "        vmin=-10,\n",
    "        vmax=0,\n",
    "        extend=\"both\"\n",
    "    )\n",
    "    cbar2 = fig.colorbar(color_map1, ax=ax3, label=\"Wd grain size\")\n",
    "    cbar2.set_ticks([-10, -5, 0])\n",
    "    minor_locator = ticker.MultipleLocator(1.0)\n",
    "    cbar2.ax.yaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "    contours_gz = ax3.contour(\n",
    "        solution_X_grid / 1e3, (y_extent - solution_Y_grid) / 1e3, solution_wl_gz_pg_log_grid, levels=[-4], colors=\"red\", linewidths=2.0\n",
    "    ) # grain size contours\n",
    "\n",
    "\n",
    "    ax3.plot((Xs + trench_x)/1e3, depths/1e3, \"--k\") # slab surface\n",
    "    ax3.plot(contour_traces[-1][0]/1e3, (y_extent - contour_traces[-1][1])/1e3, \"--k\") # slab surface \n",
    "    cset2 = ax3.contour(solution_X_grid/1e3, (y_extent - solution_Y_grid)/1e3, solution_wl_mo_grid, levels=(0.5,)) # mestastable contour 0.5\n",
    "\n",
    "    # ax3.contourf(solution_X_grid/1e3, (y_extent - solution_Y_grid)/1e3, solution_wl_mo_grid, levels=50, cmap='viridis', vmin=0.0, vmax=1.0)\n",
    "    # cset1 = ax3.contour(solution_X_grid/1e3, (y_extent - solution_Y_grid)/1e3, solution_wl_mo_grid, levels=(0.5,))\n",
    "\n",
    "    # x_center = np.interp(500e3, y_max - depths, Xs + trench_x) # find the pin point center, issue: interpolation doesn't work\n",
    "    x_center = 700\n",
    "\n",
    "    ax3.set_xlim([x_center-200, x_center+200])\n",
    "    ax3.set_ylim([300, 700])\n",
    "\n",
    "    contours = ax3.contour(\n",
    "        xv/1e3, (y_extent - yv)/1e3, T_grid-273.15, levels=np.arange(100.0, 1473.15 + 100.0, 200.0), colors=\"black\", linewidths=0.5\n",
    "    ) # temperature contours\n",
    "    ax3.clabel(contours, inline=True, fontsize=8, fmt=\"%.1f\")  # Add labels to the contours\n",
    "\n",
    "    x_tick_interval1 = 100.0\n",
    "    y_tick_interval1 = 100.0\n",
    "    ax3.xaxis.set_major_locator(MultipleLocator(x_tick_interval1))\n",
    "    ax3.xaxis.set_minor_locator(MultipleLocator(x_tick_interval1/(n_minor_ticks+1)))\n",
    "    ax3.yaxis.set_major_locator(MultipleLocator(y_tick_interval1))\n",
    "    ax3.yaxis.set_minor_locator(MultipleLocator(y_tick_interval1/(n_minor_ticks+1)))\n",
    "\n",
    "    ax3.invert_yaxis()\n",
    "\n",
    "    ax3.set_xlabel(\"X (km)\")\n",
    "    ax3.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax3.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "    # save figure\n",
    "    pdf_path = os.path.join(output_dir, \"wd_contents_%s.pdf\" % MO_method)\n",
    "    fig.savefig(pdf_path)\n",
    "    print(\"Saved figure %s\" % pdf_path)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Adjust spine thickness for this plot\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot transfromed volume, in cross section\n",
    "\n",
    "Here we plot the transformed volume fraction and the grain size distribution. With both plots, we mark the boundary of the MOW (by looking at a threshold value of the transformed volume fraction). The temperature cross section is also plotted with the grain size for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect:\n",
    "\n",
    "    wd_threshold = 0.5 # set a threshold value to extract extent of MOW\n",
    "\n",
    "    wd_n_profile = np.zeros([depths.size, len(contour_traces)])\n",
    "    gz_log_n_profile = np.zeros([depths.size, len(contour_traces)])\n",
    "    pg_gz_log_n_profile = np.zeros([depths.size, len(contour_traces)])\n",
    "    T_n_profile = np.zeros([depths.size, len(contour_traces)])\n",
    "\n",
    "    for i, depth in enumerate(depths):\n",
    "        for j, contour_trace in enumerate(contour_traces):\n",
    "            wd_n_profile[i, j] = contour_trace[3][i]\n",
    "            gz_log_n_profile[i, j] = contour_trace[4][i]\n",
    "            pg_gz_log_n_profile[i, j] = contour_trace[5][i]\n",
    "            T_n_profile[i, j] = contour_trace[7][i]\n",
    "\n",
    "    # show cross-section at a query depth\n",
    "    query_depth_array = [400e3, 450e3, 550e3, 660e3, 800e3, 900e3, 1000e3]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "\n",
    "    ax = fig.add_subplot(gs[0, 0]) \n",
    "    ax1 =  fig.add_subplot(gs[0, 1])\n",
    "    handles1 = []\n",
    "    ax1_1 = ax1.twinx()\n",
    "    handles1_1 = []\n",
    "\n",
    "    for i_q, query_depth in enumerate(query_depth_array):\n",
    "        i = np.argmin(np.abs(depths - query_depth))\n",
    "        depth_q = depths[i]\n",
    "        \n",
    "        distance0, distance1 = None, None # process the distance of the MOW extent\n",
    "        indices_less = np.where(wd_n_profile[i, :] < wd_threshold)[0]\n",
    "        if indices_less.size > 0:\n",
    "            distance0, distance1 = \\\n",
    "                contour_distance_array[indices_less[0]], contour_distance_array[indices_less[-1]]\n",
    "        \n",
    "        ax.plot(contour_distance_array/1e3, wd_n_profile[i, :], color=default_colors[i_q], label=\"depth %.1f km\" % (query_depth/1e3))\n",
    "        if distance0 is not None:\n",
    "            ax.axvline(distance0/1e3, linestyle=\"-.\", color=default_colors[i_q])\n",
    "            ax.axvline(distance1/1e3, linestyle=\"-.\", color=default_colors[i_q])\n",
    "            ax1.axvline(distance0/1e3, linestyle=\"-.\", color=default_colors[i_q])\n",
    "            ax1.axvline(distance1/1e3, linestyle=\"-.\", color=default_colors[i_q])\n",
    "        h1, = ax1.plot(contour_distance_array/1e3, gz_log_n_profile[i, :], linestyle=\"--\", linewidth=2, color=default_colors[i_q], label=\"depth %.1f km, gz\" % (query_depth/1e3))\n",
    "        h2, = ax1.plot(contour_distance_array/1e3, pg_gz_log_n_profile[i, :], linewidth=2, color=default_colors[i_q], label=\"depth %.1f km, pg gz\" % (query_depth/1e3))\n",
    "        h1_1 = ax1_1.plot(contour_distance_array/1e3, T_n_profile[i, :] - 273.15, linewidth=1, color=default_colors[i_q], label=\"temperature %.1f km, pg gz\" % (query_depth/1e3))\n",
    "        handles1.append(h1)\n",
    "        handles1.append(h2)\n",
    "        handles1_1.append(h1_1)\n",
    "        \n",
    "    ax.set_xlabel(\"Distance to Slab Surface (km)\")\n",
    "    ax.set_ylabel(\"Wd Contnents\")\n",
    "    ax.set_xlim([0, 100.0])\n",
    "    ax.set_ylim([0, 1.04])\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    x_tick_interval = 20; y_tick_interval = 0.2\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax1.set_xlabel(\"Distance to Slab Surface (km)\")\n",
    "    ax1.set_ylabel(\"log10(Grain Size)\")\n",
    "    ax1.set_xlim([0, 100.0])\n",
    "    ax1.set_ylim([-10, 0])\n",
    "    ax1.legend(handles=handles1[0:2]+handles1_1[0])\n",
    "    ax1.grid()\n",
    "    x_tick_interval = 20; y_tick_interval = 2.0\n",
    "    ax1.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax1.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax1.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax1.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "    \n",
    "    ax1_1.set_ylabel(\"Temperature (C)\")\n",
    "    ax1_1.set_ylim([500, 3000])\n",
    "    y_tick_interval = 500.0\n",
    "    ax1_1.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax1_1.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    # save figure\n",
    "    pdf_path = os.path.join(output_dir, \"MO_wedge_profile1.pdf\")\n",
    "    fig.savefig(pdf_path)\n",
    "    print(\"Saved figure %s\" % pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the outline of the MOW wedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect:\n",
    "    # show cross-section at a query depth\n",
    "    query_depth_array = np.arange(300e3, 700e3, 10e3)\n",
    "\n",
    "    get_depth_array = np.zeros(query_depth_array.shape)\n",
    "    get_distance_array = np.full([query_depth_array.size , 2], np.nan)\n",
    "    for i_q, query_depth in enumerate(query_depth_array):\n",
    "        i = np.argmin(np.abs(depths - query_depth))\n",
    "        get_depth_array[i_q] = depths[i]\n",
    "        indices_less = np.where(wd_n_profile[i, :] < wd_threshold)[0]\n",
    "        if indices_less.size > 0:\n",
    "            get_distance_array[i_q, 0], get_distance_array[i_q, 1] = \\\n",
    "                contour_distance_array[indices_less[0]], contour_distance_array[indices_less[-1]]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "\n",
    "    # wedge shape\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    ax.plot(get_distance_array[:, 0]/1e3, get_depth_array/1e3, color=\"b\", label=\"Olivine Wedge\")     \n",
    "    ax.plot(get_distance_array[:, 1]/1e3, get_depth_array/1e3, color=\"b\")\n",
    "\n",
    "    ax.set_xlim([0, contour_distance_array[-1]/1e3])\n",
    "    ax.set_ylim([300.0, 600.0])\n",
    "\n",
    "    ax.set_xlabel(\"Distance to Slab Surface (km)\")\n",
    "    ax.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # wedge widge\n",
    "    ax1 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    ax1.plot((get_distance_array[:, 1] - get_distance_array[:, 0])/1e3, get_depth_array/1e3, color=\"c\", label=\"Wedge Width\")     \n",
    "\n",
    "    ax1.set_xlim([0, contour_distance_array[-1]/1e3])\n",
    "    ax1.set_ylim([300.0, 600.0])\n",
    "\n",
    "    ax1.set_xlabel(\"Wd Width (km)\")\n",
    "    ax1.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax1.grid()\n",
    "\n",
    "    ax1.invert_yaxis()\n",
    "\n",
    "    ax1.legend()\n",
    "\n",
    "    ax1.set_aspect('equal')\n",
    "\n",
    "    # save figure\n",
    "    pdf_path = os.path.join(output_dir, \"MO_wedge_profile_wd%.2f.pdf\" % (wd_threshold))\n",
    "    fig.savefig(pdf_path)\n",
    "    print(\"Saved figure %s\" % pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grain Size Evolution Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASPECT test grain_size_growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_run_ggrowth_case = False\n",
    "\n",
    "if create_and_run_ggrowth_case:\n",
    "\n",
    "    from shutil import rmtree\n",
    "    from hamageolib.utils.dealii_param_parser import parse_parameters_to_dict, save_parameters_from_dict\n",
    "    from hamageolib.utils.world_builder_file_parser import find_feature_by_name, update_or_add_feature\n",
    "\n",
    "    # Case options\n",
    "    create_and_run_ggrowth_case_solve = True # whether to run or not\n",
    "    parent_dir = \"/mnt/lochy/ASPECT_DATA/MOW/mow_tests1\"\n",
    "    end_time = 1e6 # yr\n",
    "    maximum_timestep = 1e4 # yr \n",
    "    visualization_timestep = 1e4 # yr \n",
    "\n",
    "    adiabatic_surfT = 1000 # default - 1600.0 K\n",
    "\n",
    "    Vx_m_yr = 0.1\n",
    "\n",
    "    use_kinetics = \"wadleyite\" # use kinetic relations for wd\n",
    "    initial_grain_size = 1e-8 # default - 8e-5 \n",
    "\n",
    "    # Growth kinetics\n",
    "    if use_kinetics == \"wadleyite\":\n",
    "        growth_E = 6.62e5   # Eg (J/mol)\n",
    "        growth_exponent = 3   # pg\n",
    "        growth_rate_constant = 3.02e-4  # k0 (m^pg / s)\n",
    "        # growth_geometric_constant = 3.0     # c\n",
    "        # growth_work_fraction_for_boundary_area_change = 0.1     # lambda\n",
    "        # growth_average_specific_grain_boundary_area_energy = 1.0    # gamma\n",
    "    elif use_kinetics == \"default\":\n",
    "        growth_E = 3e5   # Eg (J/mol)\n",
    "        growth_exponent = 10   # pg\n",
    "        growth_rate_constant = 4e-45  # k0 (m^pg / s)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    # aspect directory and executable\n",
    "    aspect_dir = \"/home/lochy/Softwares/aspect\" # change this to your installed location of aspect\n",
    "    aspect_executable = os.path.join(aspect_dir, \"build_master_TwoD_rebase/aspect\")\n",
    "\n",
    "    # template path of the test\n",
    "    prm_template_path = os.path.join(aspect_dir, \"tests/grain_size_growth.prm\")\n",
    "\n",
    "    # create directories\n",
    "    case_dir = os.path.join(parent_dir, \"grain_size_growth_%s_ig%.2e_adT%.2f\" % (use_kinetics, initial_grain_size, adiabatic_surfT))\n",
    "    if not os.path.isdir(case_dir):\n",
    "        os.mkdir(case_dir)\n",
    "    img_dir = os.path.join(case_dir, \"img\")\n",
    "    if not os.path.isdir(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "\n",
    "    # Modify the template\n",
    "    # Also read important parameters like the size of the model\n",
    "\n",
    "    with open(prm_template_path, 'r') as file:\n",
    "        params_dict = parse_parameters_to_dict(file)\n",
    "\n",
    "    params_dict[\"Output directory\"] = os.path.join(case_dir, \"output\")\n",
    "\n",
    "    # Add maximum timestep and End time\n",
    "    params_dict[\"End time\"] = str(end_time) # yr\n",
    "    params_dict[\"Maximum time step\"] = str(maximum_timestep) # yr\n",
    "\n",
    "    # Assign adiabatic surface temperature\n",
    "    params_dict[\"Adiabatic surface temperature\"] = str(adiabatic_surfT)\n",
    "\n",
    "    # Assign initial grain size\n",
    "    params_dict[\"Initial composition model\"][\"Function\"][\"Function expression\"] =\\\n",
    "        \"if(z<50000,%.6e,%.6e)\" % (initial_grain_size, initial_grain_size*(1+1e-5))\n",
    "\n",
    "    # Assign growth kinetics\n",
    "    grain_size_model = params_dict[\"Material model\"][\"Grain size model\"]\n",
    "\n",
    "    grain_size_model[\"Grain growth activation energy\"] = str(growth_E)\n",
    "    grain_size_model[\"Grain growth rate constant\"] = str(growth_rate_constant)\n",
    "    grain_size_model[\"Grain growth exponent\"] = str(growth_exponent)\n",
    "    grain_size_model[\"Minimum grain size\"] = str(1e-9)\n",
    "\n",
    "    params_dict[\"Material model\"][\"Grain size model\"] = grain_size_model\n",
    "\n",
    "    # Add outputs\n",
    "    params_dict[\"Postprocess\"][\"List of postprocessors\"] += \", visualization\"\n",
    "    params_dict[\"Postprocess\"][\"Visualization\"] = {\n",
    "        \"List of output variables\": \"material properties, named additional outputs, nonadiabatic pressure, strain rate, stress, heating\",\n",
    "        \"Output format\": \"vtu\",\n",
    "        \"Time between graphical output\": str(visualization_timestep)\n",
    "    }\n",
    "\n",
    "    # Write to a prm file in the new case directory\n",
    "    prm_path = os.path.join(case_dir, \"case.prm\")\n",
    "\n",
    "    with open(prm_path, 'w') as output_file:\n",
    "        save_parameters_from_dict(output_file, params_dict)\n",
    "\n",
    "    assert(os.path.isfile(prm_path))\n",
    "\n",
    "    print(\"Created case in %s\" % (case_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_and_run_ggrowth_case and create_and_run_ggrowth_case_solve:\n",
    "\n",
    "    import subprocess\n",
    "\n",
    "    # Run the ASPECT executable with the parameter file\n",
    "    # The function ensures that both the expected outputs are generated and no errors are produced\n",
    "    # 'capture_output=True' collects both stdout and stderr for further checks\n",
    "    completed_process = subprocess.run([aspect_executable, prm_path], capture_output=True, text=True)\n",
    "\n",
    "    # Capture the standard output and error streams\n",
    "    stdout = completed_process.stdout\n",
    "    stderr = completed_process.stderr\n",
    "\n",
    "    # Uncomment the following lines for debugging purposes to inspect the output\n",
    "    # print(stdout)  # Debugging: Prints the standard output\n",
    "    # print(stderr)  # Debugging: Prints the standard error\n",
    "\n",
    "    # Check if the expected line indicating wallclock time appears in the output\n",
    "    # The expected line format is something like:\n",
    "    # -- Total wallclock time elapsed including restarts: 1s\n",
    "    assert(re.match(\".*Total wallclock\", stdout.split('\\n')[-6]))\n",
    "\n",
    "    # Ensure that the error stream is empty, indicating no issues during the run\n",
    "    assert(stderr.strip() == \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_and_run_ggrowth_case and create_and_run_ggrowth_case_solve:\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose one step to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_run_ggrowth_case_plot_one_step = True\n",
    "\n",
    "if create_and_run_ggrowth_case and create_and_run_ggrowth_case_plot_one_step:\n",
    "\n",
    "    plot_time = 0.0 # yr\n",
    "    vtu_timestep = int(plot_time / visualization_timestep)\n",
    "\n",
    "    import vtk\n",
    "    from vtk.util.numpy_support import vtk_to_numpy\n",
    "    from hamageolib.utils.vtk_utilities import calculate_resolution\n",
    "    import time\n",
    "    from scipy.interpolate import LinearNDInterpolator\n",
    "\n",
    "    pvtu_file = os.path.join(case_dir, \"output\", \"solution\", \"solution-%05d.pvtu\" % vtu_timestep)\n",
    "    assert(os.path.isfile(pvtu_file))\n",
    "\n",
    "    # Read the pvtu file\n",
    "    start = time.time()\n",
    "\n",
    "    reader = vtk.vtkXMLPUnstructuredGridReader()\n",
    "    reader.SetFileName(pvtu_file)\n",
    "    reader.Update()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Initiating reader takes %.2e s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Get the output data from the reader\n",
    "    grid = reader.GetOutput()  # Access the unstructured grid\n",
    "    data_set = reader.GetOutputAsDataSet()  # Access the dataset representation\n",
    "    points = grid.GetPoints()  # Extract the points (coordinates)\n",
    "    cells = grid.GetCells()  # Extract the cell connectivity information\n",
    "    point_data = data_set.GetPointData()  # Access point-wise data\n",
    "\n",
    "    n_points = grid.GetNumberOfPoints() # Number of points and cells\n",
    "    n_cells = grid.GetNumberOfCells()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Reading files takes %.2e s\" % (end - start))\n",
    "    print(f\"\\tNumber of points: {n_points}\")\n",
    "    print(f\"\\tNumber of cells: {n_cells}\")\n",
    "    print(\"\\tAvailable point data fields:\")\n",
    "    for i in range(point_data.GetNumberOfArrays()):\n",
    "        # Field names in point data\n",
    "        name = point_data.GetArrayName(i)\n",
    "        print(f\"\\t  - {name}\")\n",
    "    start = end\n",
    "\n",
    "    # Convert data to numpy array\n",
    "    # Get coordinates (points)\n",
    "    # Get field \"T\"\n",
    "\n",
    "    vtk_points = grid.GetPoints().GetData()\n",
    "    points_np = vtk_to_numpy(vtk_points)  # Shape: (n_points, 3)\n",
    "    points_2d = points_np[:, :2]  # Use only the first two columns for 2D coordinates\n",
    "\n",
    "    # Initialize dictionary for interpolators\n",
    "    interpolators = {}\n",
    "\n",
    "    # Loop over all arrays in point data\n",
    "    num_arrays = point_data.GetNumberOfArrays()\n",
    "    for i in range(num_arrays):\n",
    "        array_name = point_data.GetArrayName(i)\n",
    "        vtk_array = point_data.GetArray(i)\n",
    "        \n",
    "        if vtk_array is None:\n",
    "            print(f\"Warning: Array {array_name} is None, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Convert VTK array to NumPy\n",
    "        np_array = vtk_to_numpy(vtk_array)\n",
    "        \n",
    "        # Create interpolator and add to dict\n",
    "        interpolators[array_name] = LinearNDInterpolator(points_2d, np_array, fill_value=np.nan)\n",
    "\n",
    "    # Calculate resolution for each cell or point in the grid\n",
    "    resolution_np = calculate_resolution(grid)  # Custom function (not defined here)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Calculating resolution takes %.2e s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Create interpolators for temperature, pressure, and resolution\n",
    "    interpolators[\"resolution\"] = LinearNDInterpolator(points_2d, resolution_np)  # Interpolator for resolution\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Construct linear ND interpolator takes %.2e s\" % (end - start))\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create grid to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_and_run_ggrowth_case and create_and_run_ggrowth_case_plot_one_step:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Define the interval for the grid (in meters)\n",
    "    interval = 0.1e3\n",
    "\n",
    "    # Determine the bounding box of the 2D points\n",
    "    x_min, y_min = np.min(points_2d, axis=0)\n",
    "    x_max, y_max = np.max(points_2d, axis=0)\n",
    "\n",
    "    # Define a regular grid within the bounding box\n",
    "    # allow a little different in interval in x\n",
    "    # and y axis, thereform making the two dimensions\n",
    "    # unequal to make fewer mistakes ...\n",
    "    xs = np.arange(x_min, x_max, interval*0.99)\n",
    "    ys = np.arange(y_min, y_max, interval*1.01)\n",
    "    x_grid, y_grid = np.meshgrid(xs, ys, indexing=\"ij\")  # Create a grid of (x, y) points\n",
    "\n",
    "    # Flatten the grid for interpolation\n",
    "    grid_points_2d = np.vstack([x_grid.ravel(), y_grid.ravel()]).T\n",
    "\n",
    "    # Interpolate temperature (T) values onto the regular grid\n",
    "    T_grid = interpolators[\"T\"](grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    T_grid = T_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate temperature (P) values onto the regular grid\n",
    "    P_grid = interpolators[\"p\"](grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    P_grid = P_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "    \n",
    "    # Interpolate grain size values onto the regular grid\n",
    "    grain_size_grid = interpolators[\"grain_size\"](grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    grain_size_grid = grain_size_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate resolutions onto the regular grid\n",
    "    resolutions_grid = interpolators[\"resolution\"](grid_points_2d)\n",
    "    resolutions_grid = resolutions_grid.reshape(x_grid.shape)\n",
    "\n",
    "    # Interpolate velocities onto the regular grid\n",
    "    velocity_grid = interpolators[\"velocity\"](grid_points_2d)\n",
    "    velocity_grid = velocity_grid.reshape([x_grid.shape[0], x_grid.shape[1],3])\n",
    "    vx_grid = velocity_grid[:, :, 0]\n",
    "    vy_grid = velocity_grid[:, :, 1]\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Interpolating to regular grid takes %.2e s\" % (end - start))\n",
    "    print(\"\\tgrid shape: (x axis, y axis): \", x_grid.shape)\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_and_run_ggrowth_case and create_and_run_ggrowth_case_plot_one_step:\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    from matplotlib import gridspec\n",
    "    from cmcrameri import cm as ccm\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (0.0, 100e3)\n",
    "    x_tick_interval = 25e3   # tick interval along x\n",
    "    y_lim = (0.0, 100e3)\n",
    "    y_tick_interval = 25e3  # tick interval along y\n",
    "\n",
    "    resolution_lim = (0.0, 10e3) # resolution\n",
    "    resolution_level = 50  # number of levels in contourf plot\n",
    "    resolution_tick_interval = 2.5e3  # tick interval along v\n",
    "\n",
    "    T_lim = (0.0, 2000) # T\n",
    "    T_level = 50  # number of levels in contourf plot\n",
    "    T_tick_interval = 500 # tick interval along v\n",
    "\n",
    "    P_lim = (-1e8, 1e8) # P\n",
    "    P_level = 50  # number of levels in contourf plot\n",
    "    P_tick_interval = 5e7  # tick interval along v\n",
    "\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # Create a figure with a 2x2 grid layout\n",
    "    fig = plt.figure(figsize=(12, 10), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "    # Plot the mesh resolution\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    levels = np.linspace(resolution_lim[0], resolution_lim[1], resolution_level)\n",
    "    ticks=np.arange(resolution_lim[0], resolution_lim[1], resolution_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid, y_grid, resolutions_grid,  vmin=resolution_lim[0], vmax=resolution_lim[1], levels=levels, cmap=\"plasma_r\")  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"Resolution\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # Plot T\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    levels = np.linspace(T_lim[0], T_lim[1], T_level)\n",
    "    ticks=np.arange(T_lim[0], T_lim[1], T_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid, y_grid, T_grid,  vmin=T_lim[0], vmax=T_lim[1], levels=levels, cmap=ccm.lapaz)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"T\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    step = 200  # plot every 5th vector\n",
    "    qv = ax.quiver(x_grid[::step, ::step], y_grid[::step, ::step],\\\n",
    "                vx_grid[::step, ::step], vy_grid[::step, ::step],\\\n",
    "                    scale=1, width=0.004, color='black')\n",
    "    ax.quiverkey(qv, X=0.85, Y=-0.1, U=0.1, label='10 cm/yr', labelpos='E')\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # Plot P\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "    levels = np.linspace(P_lim[0], P_lim[1], P_level)\n",
    "    ticks=np.arange(P_lim[0], P_lim[1], P_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid, y_grid, P_grid,  vmin=P_lim[0], vmax=P_lim[1], levels=levels, cmap=ccm.tokyo_r)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"P\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # Plot grain size\n",
    "    ax = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "    grain_size_min = -4.5\n",
    "    grain_size_max = -4\n",
    "    grain_size_tick_interval = 0.1\n",
    "    levels = np.linspace(grain_size_min, grain_size_max, 50)\n",
    "    ticks=np.arange(grain_size_min, grain_size_max*0.9999999, grain_size_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid, y_grid, np.log10(grain_size_grid), vmin=grain_size_min, vmax=grain_size_max, levels=levels, cmap=ccm.tokyo) \n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"grain size\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # save output\n",
    "    fig_path = os.path.join(img_dir, \"visualization_%.2fMa\" % (plot_time/1e6))\n",
    "    fig.savefig(fig_path + \".png\")\n",
    "    print(\"Saved figure %s\" % (fig_path + \".png\"))\n",
    "    fig.savefig(fig_path + \".pdf\")\n",
    "    print(\"Saved figure %s\" % (fig_path + \".pdf\"))\n",
    "\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop the timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create the interpolators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_run_ggrowth_case_plot_loop_steps = True\n",
    "\n",
    "if create_and_run_ggrowth_case and create_and_run_ggrowth_case_plot_loop_steps:\n",
    "    \n",
    "    import vtk\n",
    "    from vtk.util.numpy_support import vtk_to_numpy\n",
    "    from hamageolib.utils.vtk_utilities import calculate_resolution\n",
    "    import time\n",
    "    from scipy.interpolate import LinearNDInterpolator\n",
    "\n",
    "\n",
    "    plot_time_interval = 1e4 # yr\n",
    "\n",
    "    plot_times = np.arange(0.0, end_time*1.0000001, plot_time_interval)\n",
    "\n",
    "    interpolator_array = []\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    for i, plot_time in enumerate(plot_times):\n",
    "        \n",
    "        vtu_timestep = int(plot_time / visualization_timestep)\n",
    "\n",
    "        pvtu_file = os.path.join(case_dir, \"output\", \"solution\", \"solution-%05d.pvtu\" % vtu_timestep)\n",
    "        assert(os.path.isfile(pvtu_file))\n",
    "\n",
    "        # Read the pvtu file\n",
    "\n",
    "        reader = vtk.vtkXMLPUnstructuredGridReader()\n",
    "        reader.SetFileName(pvtu_file)\n",
    "        reader.Update()\n",
    "\n",
    "        # Get the output data from the reader\n",
    "        grid = reader.GetOutput()  # Access the unstructured grid\n",
    "        data_set = reader.GetOutputAsDataSet()  # Access the dataset representation\n",
    "        points = grid.GetPoints()  # Extract the points (coordinates)\n",
    "        cells = grid.GetCells()  # Extract the cell connectivity information\n",
    "        point_data = data_set.GetPointData()  # Access point-wise data\n",
    "\n",
    "        n_points = grid.GetNumberOfPoints() # Number of points and cells\n",
    "        n_cells = grid.GetNumberOfCells()\n",
    "\n",
    "        if i == 0:\n",
    "            print(\"Data in file:\")\n",
    "            print(f\"\\tNumber of points: {n_points}\")\n",
    "            print(f\"\\tNumber of cells: {n_cells}\")\n",
    "            print(\"\\tAvailable point data fields:\")\n",
    "            for i in range(point_data.GetNumberOfArrays()):\n",
    "                # Field names in point data\n",
    "                name = point_data.GetArrayName(i)\n",
    "                print(f\"\\t  - {name}\")\n",
    "\n",
    "        # Convert data to numpy array\n",
    "        # Get coordinates (points)\n",
    "        # Get field \"T\"\n",
    "\n",
    "        vtk_points = grid.GetPoints().GetData()\n",
    "        points_np = vtk_to_numpy(vtk_points)  # Shape: (n_points, 3)\n",
    "        points_2d = points_np[:, :2]  # Use only the first two columns for 2D coordinates\n",
    "\n",
    "        # Initialize dictionary for interpolators\n",
    "        interpolators = {}\n",
    "\n",
    "        # Loop over all arrays in point data\n",
    "        num_arrays = point_data.GetNumberOfArrays()\n",
    "        for i in range(num_arrays):\n",
    "            array_name = point_data.GetArrayName(i)\n",
    "            vtk_array = point_data.GetArray(i)\n",
    "            \n",
    "            if vtk_array is None:\n",
    "                print(f\"Warning: Array {array_name} is None, skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Convert VTK array to NumPy\n",
    "            np_array = vtk_to_numpy(vtk_array)\n",
    "            \n",
    "            # Create interpolator and add to dict\n",
    "            interpolators[array_name] = LinearNDInterpolator(points_2d, np_array, fill_value=np.nan)\n",
    "\n",
    "        # Calculate resolution for each cell or point in the grid\n",
    "        resolution_np = calculate_resolution(grid)  # Custom function (not defined here)\n",
    "\n",
    "        # Create interpolators for temperature, pressure, and resolution\n",
    "        interpolators[\"resolution\"] = LinearNDInterpolator(points_2d, resolution_np)  # Interpolator for resolution\n",
    "\n",
    "        interpolator_array.append(interpolators)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Reading files takes %.2e s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_and_run_ggrowth_case and create_and_run_ggrowth_case_plot_loop_steps:\n",
    "\n",
    "    grain_sizes = []\n",
    "    y = 5e4 # m\n",
    "    for i, plot_time in enumerate(plot_times):\n",
    "        interpolators = interpolator_array[i]\n",
    "        x = plot_time * Vx_m_yr\n",
    "\n",
    "        points_2d = np.array([x, y]) \n",
    "        grain_size = interpolators[\"grain_size\"](points_2d)\n",
    "\n",
    "        grain_sizes.append(grain_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_and_run_ggrowth_case and create_and_run_ggrowth_case_plot_loop_steps:\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    x_lim = [0.0, 1e6]\n",
    "\n",
    "    log_grain_sizes = np.log10(grain_sizes)\n",
    "    y_min = np.floor(np.min(log_grain_sizes)/0.1) * 0.1; y_max = np.ceil(np.max(log_grain_sizes)/0.1) * 0.1\n",
    "    y_lim = [y_min, y_max]\n",
    "    x_tick_interval = 2.5e5\n",
    "    y_tick_interval = 0.1\n",
    "    ax.plot(plot_times, np.log10(grain_sizes))\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    ax.set_xlabel(\"Time (yr)\")\n",
    "    ax.set_ylabel(\"log10(Grain Size) (m)\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    fig_path = os.path.join(img_dir, \"time_analysis\")\n",
    "    fig.savefig(fig_path + \".png\")\n",
    "    print(\"Saved figure %s\" % (fig_path + \".png\"))\n",
    "    fig.savefig(fig_path + \".pdf\")\n",
    "    print(\"Saved figure %s\" % (fig_path + \".pdf\"))\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the synthetic equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_grain_growth_synthetic = True\n",
    "if analyze_grain_growth_synthetic:\n",
    "    from hamageolib.core.GrainSize import GrainGrowthModel, GrainGrowthParams\n",
    "\n",
    "    use_kinetics = \"default\"\n",
    "\n",
    "    if use_kinetics == \"wadleyite\":\n",
    "        params = GrainGrowthParams(\n",
    "            grain_growth_rate_constant=3.02e-4,\n",
    "            m=3,\n",
    "            grain_growth_activation_energy=6.62e5,\n",
    "            grain_growth_activation_volume=0.0,\n",
    "        )\n",
    "    elif use_kinetics == \"default\":\n",
    "        params = GrainGrowthParams(\n",
    "            grain_growth_rate_constant=4e-45,\n",
    "            m=10,\n",
    "            grain_growth_activation_energy=3e5,\n",
    "            grain_growth_activation_volume=0.0,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    gModel = GrainGrowthModel(params=params)\n",
    "\n",
    "    img_dir = os.path.join(results_dir, \"analyze_grain_growth_synthetic\")\n",
    "    if not os.path.isdir(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "    \n",
    "    year = 365 * 24 * 3600.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve analytic relation for grain growth vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_grain_growth_synthetic:\n",
    "\n",
    "    P = 14e9 # Pa\n",
    "    T = 1600 # K, default-1600.0\n",
    "    initial_grain_size = 8e-5\n",
    "    t_max = 1e6 * year\n",
    "\n",
    "    ts = np.linspace(0.0, 1e6*year, 1000)\n",
    "\n",
    "    grain_sizes = gModel.grain_size_at_time(initial_grain_size, ts, P, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_grain_growth_synthetic:\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "    \n",
    "    log_grain_sizes = np.log10(grain_sizes)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(ts/year, log_grain_sizes)\n",
    "\n",
    "    x_lim = [-5e4, t_max/year]\n",
    "    x_tick_interval = 5e5\n",
    "    y_min = np.floor(np.min(log_grain_sizes)/0.1) * 0.1; y_max = np.ceil(np.max(log_grain_sizes)/0.1) * 0.1\n",
    "    y_lim = [y_min, y_max]\n",
    "    y_tick_interval = 0.1\n",
    "    n_minor_ticks = 4\n",
    "    \n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    ax.set_xlabel(\"Time (yr)\")\n",
    "    ax.set_ylabel(\"log10(Grain Size) (m)\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    fig_path = os.path.join(img_dir, \"time_analysis_%s_ig%.2e_T%.2f\" % (use_kinetics, initial_grain_size, T))\n",
    "    fig.savefig(fig_path + \".png\")\n",
    "    print(\"Saved figure %s\" % (fig_path + \".png\"))\n",
    "    fig.savefig(fig_path + \".pdf\")\n",
    "    print(\"Saved figure %s\" % (fig_path + \".pdf\"))\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the grain size at constant time with different T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_grain_growth_synthetic:\n",
    "\n",
    "    P = 14e9 # Pa\n",
    "    initial_grain_size = 1e-8\n",
    "    t_max_array = [1e4*year, 1e5*year, 1e6 * year, 1e7 * year]\n",
    "\n",
    "    Ts = np.linspace(1000.0, 2000.0, 1000) # K\n",
    "\n",
    "    grain_size_array = []\n",
    "    for i, t_max in enumerate(t_max_array):\n",
    "        grain_sizes = gModel.grain_size_at_time(initial_grain_size, t_max, P, Ts)\n",
    "        grain_size_array.append(grain_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_grain_growth_synthetic:\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    min_log_grain_sizes = None; max_log_grain_sizes = None \n",
    "    for i, t_max in enumerate(t_max_array):\n",
    "        grain_sizes = grain_size_array[i]\n",
    "        log_grain_sizes = np.log10(grain_sizes)\n",
    "\n",
    "        if i == 0:\n",
    "            min_log_grain_sizes = np.min(log_grain_sizes)\n",
    "            max_log_grain_sizes = np.max(log_grain_sizes)\n",
    "        else:\n",
    "            min_log_grain_sizes = min(min_log_grain_sizes, np.min(log_grain_sizes))\n",
    "            max_log_grain_sizes = max(max_log_grain_sizes, np.max(log_grain_sizes))\n",
    "\n",
    "        ax.plot(Ts, log_grain_sizes, color=default_colors[i], label=\"%.2e yr\" % (t_max/year))\n",
    "\n",
    "    x_lim = [np.min(Ts), np.max(Ts)]\n",
    "    x_tick_interval = 500.0\n",
    "    y_min = np.floor(np.min(log_grain_sizes)/0.1) * 0.1; y_max = np.ceil(np.max(log_grain_sizes)/0.1) * 0.1\n",
    "    y_lim = [min_log_grain_sizes, max_log_grain_sizes]\n",
    "    y_tick_interval = 0.5\n",
    "    n_minor_ticks = 4\n",
    "    \n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_xlabel(\"T (K)\")\n",
    "    ax.set_ylabel(\"log10(Grain Size) (m)\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    fig_path = os.path.join(img_dir, \"T_analysis_%s_ig%.2e\" % (use_kinetics, initial_grain_size))\n",
    "    fig.savefig(fig_path + \".png\")\n",
    "    print(\"Saved figure %s\" % (fig_path + \".png\"))\n",
    "    fig.savefig(fig_path + \".pdf\")\n",
    "    print(\"Saved figure %s\" % (fig_path + \".pdf\"))\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASPECT implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive the reference pressure profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASPECT tests\n",
    "\n",
    "(Keep updated to the \"ASPECT Implementation\" section in supplementary material)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial condition test (TwoDSubduction_metastable_initial.prm)\n",
    "\n",
    "This test serves to check the initial condition of the \"metastable\" composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_run_aspect_tests_initial = False\n",
    "\n",
    "if is_run_aspect_tests_initial:\n",
    "\n",
    "    test_composition = \"spharz\"  # background or spharz\n",
    "    n_repetition = 50  # 50 - original, 200 - high to make plots\n",
    "\n",
    "    aspect_dir = \"/home/lochy/Softwares/aspect\"\n",
    "    aspect_executable = os.path.join(aspect_dir, \"build_master_TwoD_rebase/aspect\")\n",
    "    prm_template_path = os.path.join(aspect_dir, \"tests\", \"TwoDSubduction_metastable_initial.prm\")\n",
    "\n",
    "    assert(os.path.isfile(aspect_executable))\n",
    "    assert(os.path.isfile(prm_template_path))\n",
    "\n",
    "    # assign another directory to run the case\n",
    "    case_root_dir = os.path.join(root_path, \"dtemp\") \n",
    "\n",
    "    case_dir = os.path.join(\"/mnt/lochz/ASPECT_DATA/TwoDSubduction/test_cases\", \"TwoDSubduction_metastable_initial\")  # New directory to run the case\n",
    "    if not os.path.isdir(case_dir):\n",
    "        os.mkdir(case_dir)\n",
    "\n",
    "    output_dirname = \"output_initial_%d\" % n_repetition  # output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_initial:\n",
    "\n",
    "    from hamageolib.utils.dealii_param_parser import parse_parameters_to_dict, save_parameters_from_dict\n",
    "    from hamageolib.utils.world_builder_file_parser import find_feature_by_name, update_or_add_feature\n",
    "\n",
    "\n",
    "    # Modify the template\n",
    "    # Also read important parameters like the size of the model\n",
    "\n",
    "    with open(prm_template_path, 'r') as file:\n",
    "        params_dict = parse_parameters_to_dict(file)\n",
    "\n",
    "\n",
    "    params_dict[\"Output directory\"] = os.path.join(case_dir, output_dirname)\n",
    "\n",
    "    params_dict[\"Additional shared libraries\"] = \"$ASPECT_SOURCE_DIR/build_master_TwoD_rebase/subduction_temperature2d/libsubduction_temperature2d.so, $ASPECT_SOURCE_DIR/build_master_TwoD_rebase/prescribe_field/libprescribed_temperature.so, $ASPECT_SOURCE_DIR/build_master_TwoD_rebase/visco_plastic_TwoD/libvisco_plastic_TwoD.so\"\n",
    "\n",
    "    params_dict[\"Geometry model\"][\"Box\"][\"X repetitions\"] = str(n_repetition)\n",
    "    params_dict[\"Geometry model\"][\"Box\"][\"Y repetitions\"] = str(n_repetition)\n",
    "        \n",
    "    if test_composition == \"background\":\n",
    "        pass\n",
    "    elif test_composition == \"spharz\":\n",
    "        params_dict[\"Initial composition model\"][\"Function\"][\"Function expression\"] = \"0.0 ; 1.0; 0.0 ; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0\"\n",
    "    else:\n",
    "        raise ValueError(\"test_composition must be background or spharz\")\n",
    "    \n",
    "    params_dict[\"Postprocess\"][\"Visualization\"][\"Output format\"] = \"vtu\"\n",
    "    \n",
    "    # Write to a prm file in the new case directory\n",
    "    prm_path = os.path.join(case_dir, \"case.prm\")\n",
    "\n",
    "    with open(prm_path, 'w') as output_file:\n",
    "        save_parameters_from_dict(output_file, params_dict)\n",
    "\n",
    "    assert(os.path.isfile(prm_path))\n",
    "\n",
    "    print(\"Created case in %s\" % (case_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run\n",
    "\n",
    "Use \"subprocess.run\" to run the case.\n",
    "\n",
    "Capture the standard output and error streams\n",
    "\n",
    "Check\n",
    "  * if the expected line indicating wallclock time appears in the output.\n",
    "  * There is no stderr output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_initial:\n",
    "\n",
    "    # Run theb ASPECT executable with the parameter file\n",
    "    # The function ensures that both the expected outputs are generated and no errors are produced\n",
    "    # 'capture_output=True' collects both stdout and stderr for further checks\n",
    "    completed_process = subprocess.run([aspect_executable, prm_path], capture_output=True, text=True)\n",
    "\n",
    "    # Capture the standard output and error streams\n",
    "    stdout = completed_process.stdout\n",
    "    stderr = completed_process.stderr\n",
    "\n",
    "    # Uncomment the following lines for debugging purposes to inspect the output\n",
    "    # print(stdout)  # Debugging: Prints the standard output\n",
    "    # print(stderr)  # Debugging: Prints the standard error\n",
    "\n",
    "    # Check if the expected line indicating wallclock time appears in the output\n",
    "    # The expected line format is something like:\n",
    "    # -- Total wallclock time elapsed including restarts: 1s\n",
    "    assert(re.match(\".*Total wallclock\", stdout.split('\\n')[-6]))\n",
    "\n",
    "    # Ensure that the error stream is empty, indicating no issues during the run\n",
    "    assert(stderr == \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_initial:\n",
    "\n",
    "    vtu_step = 0  # * 1ky\n",
    "\n",
    "    import vtk\n",
    "    from vtk.util.numpy_support import vtk_to_numpy\n",
    "    from hamageolib.utils.vtk_utilities import calculate_resolution\n",
    "    import time\n",
    "    from scipy.interpolate import LinearNDInterpolator\n",
    "\n",
    "    pvtu_file = os.path.join(case_dir, output_dirname, \"solution\", \"solution-%05d.pvtu\" % vtu_step)\n",
    "    assert(os.path.isfile(pvtu_file))\n",
    "\n",
    "    # Read the pvtu file\n",
    "    start = time.time()\n",
    "\n",
    "    reader = vtk.vtkXMLPUnstructuredGridReader()\n",
    "    reader.SetFileName(pvtu_file)\n",
    "    reader.Update()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Initiating reader takes %.2e s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Get the output data from the reader\n",
    "    grid = reader.GetOutput()  # Access the unstructured grid\n",
    "    data_set = reader.GetOutputAsDataSet()  # Access the dataset representation\n",
    "    points = grid.GetPoints()  # Extract the points (coordinates)\n",
    "    cells = grid.GetCells()  # Extract the cell connectivity information\n",
    "    point_data = data_set.GetPointData()  # Access point-wise data\n",
    "\n",
    "    n_points = grid.GetNumberOfPoints() # Number of points and cells\n",
    "    n_cells = grid.GetNumberOfCells()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Reading files takes %.2e s\" % (end - start))\n",
    "    print(f\"\\tNumber of points: {n_points}\")\n",
    "    print(f\"\\tNumber of cells: {n_cells}\")\n",
    "    print(\"\\tAvailable point data fields:\")\n",
    "    for i in range(point_data.GetNumberOfArrays()):\n",
    "        # Field names in point data\n",
    "        name = point_data.GetArrayName(i)\n",
    "        print(f\"\\t  - {name}\")\n",
    "    start = end\n",
    "\n",
    "    # Convert data to numpy array\n",
    "    # Get coordinates (points)\n",
    "    # Get field \"T\"\n",
    "    vtk_points = grid.GetPoints().GetData()\n",
    "    points_np = vtk_to_numpy(vtk_points)  # Shape: (n_points, 3)\n",
    "    points_2d = points_np[:, :2]  # Use only the first two columns for 2D coordinates\n",
    "\n",
    "    # Initialize dictionary for interpolators\n",
    "    interpolators = {}\n",
    "\n",
    "    # Loop over all arrays in point data\n",
    "    num_arrays = point_data.GetNumberOfArrays()\n",
    "    for i in range(num_arrays):\n",
    "        array_name = point_data.GetArrayName(i)\n",
    "        vtk_array = point_data.GetArray(i)\n",
    "        \n",
    "        if vtk_array is None:\n",
    "            print(f\"Warning: Array {array_name} is None, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Convert VTK array to NumPy\n",
    "        np_array = vtk_to_numpy(vtk_array)\n",
    "        \n",
    "        # Create interpolator and add to dict\n",
    "        interpolators[array_name] = LinearNDInterpolator(points_2d, np_array, fill_value=np.nan)\n",
    "\n",
    "    # Calculate resolution for each cell or point in the grid\n",
    "    resolution_np = calculate_resolution(grid)  # Custom function (not defined here)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Calculating resolution takes %.2e s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Create interpolators for temperature, pressure, and resolution\n",
    "    interpolators[\"resolution\"] = LinearNDInterpolator(points_2d, resolution_np)  # Interpolator for resolution\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Construct linear ND interpolator takes %.2e s\" % (end - start))\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_initial:\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    # Define the interval for the grid (in meters)\n",
    "    interval = 1000.0\n",
    "\n",
    "    # Determine the bounding box of the 2D points\n",
    "    x_min, y_min = np.min(points_2d, axis=0)\n",
    "    x_max, y_max = np.max(points_2d, axis=0)\n",
    "\n",
    "    # Define a regular grid within the bounding box\n",
    "    # allow a little different in interval in x\n",
    "    # and y axis, thereform making the two dimensions\n",
    "    # unequal to make fewer mistakes ...\n",
    "    xs = np.arange(x_min, x_max, interval*0.99)\n",
    "    ys = np.arange(y_min, y_max, interval*1.01)\n",
    "    x_grid, y_grid = np.meshgrid(xs, ys, indexing=\"ij\")  # Create a grid of (x, y) points\n",
    "\n",
    "    # Flatten the grid for interpolation\n",
    "    grid_points_2d = np.vstack([x_grid.ravel(), y_grid.ravel()]).T\n",
    "\n",
    "    # Interpolate temperature (T) values onto the regular grid\n",
    "    T_grid = interpolators[\"T\"](grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    T_grid = T_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate temperature (P) values onto the regular grid\n",
    "    P_grid = interpolators[\"p\"](grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    P_grid = P_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate resolutions onto the regular grid\n",
    "    resolutions_grid = interpolators[\"resolution\"](grid_points_2d)\n",
    "    resolutions_grid = resolutions_grid.reshape(x_grid.shape)\n",
    "\n",
    "    # Interpolate density onto the regular grid\n",
    "    density_grid = interpolators[\"density\"](grid_points_2d)\n",
    "    density_grid = density_grid.reshape(x_grid.shape)\n",
    "\n",
    "\n",
    "    # Interpolate metastable compositions onto the regular grid\n",
    "    metastable_grid = interpolators[\"metastable\"](grid_points_2d)\n",
    "    metastable_grid = metastable_grid.reshape(x_grid.shape)\n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"Interpolating to regular grid takes %.2e s\" % (end - start))\n",
    "    print(\"\\tgrid shape: (x axis, y axis): \", x_grid.shape)\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_initial:\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    from matplotlib import gridspec\n",
    "    from cmcrameri import cm as ccm\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (0.0, 800) # km\n",
    "    x_tick_interval = 100   # tick interval along x\n",
    "    y_lim = (0.0, 800) # km\n",
    "    y_tick_interval = 100  # tick interval along y\n",
    "\n",
    "    resolution_lim = (0.0, 100e3) # resolution\n",
    "    resolution_level = 50  # number of levels in contourf plot\n",
    "    resolution_tick_interval = 25e3  # tick interval along v\n",
    "\n",
    "    T_lim = (0.0, 2000.0) # T\n",
    "    T_level = 50  # number of levels in contourf plot\n",
    "    T_tick_interval = 250.0  # tick interval along v\n",
    "\n",
    "    P_lim = (np.min(P_grid), np.max(P_grid)) # P\n",
    "    P_level = 50  # number of levels in contourf plot\n",
    "    P_tick_interval = 1e9  # tick interval along P\n",
    "    \n",
    "    density_lim = (3000.0, 4000.0)\n",
    "    density_level = 50  # number of levels in contourf plot\n",
    "    density_tick_interval = 100.0  # tick interval along P\n",
    "\n",
    "    metastable_lim = (-0.01, 1.01)\n",
    "    metastable_level = 50\n",
    "    metastable_tick_interval = 0.25\n",
    "\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # Create a figure with a 2x2 grid layout\n",
    "    fig = plt.figure(figsize=(12, 15), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(3, 2)\n",
    "\n",
    "    # Plot the mesh resolution\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    levels = np.linspace(resolution_lim[0], resolution_lim[1], resolution_level)\n",
    "    ticks=np.arange(resolution_lim[0], resolution_lim[1], resolution_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, resolutions_grid,  vmin=resolution_lim[0], vmax=resolution_lim[1], levels=levels, cmap=\"plasma_r\")  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"Resolution\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # Plot T\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    levels = np.linspace(T_lim[0], T_lim[1], T_level)\n",
    "    ticks=np.arange(T_lim[0], T_lim[1], T_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, T_grid,  vmin=T_lim[0], vmax=T_lim[1], levels=levels, cmap=ccm.lapaz)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"T\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # Plot P\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "    levels = np.linspace(P_lim[0], P_lim[1], P_level)\n",
    "    ticks=np.arange(P_lim[0], P_lim[1], P_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, P_grid,  vmin=P_lim[0], vmax=P_lim[1], levels=levels, cmap=ccm.tokyo_r)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"P\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Plot density\n",
    "    ax = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "    levels = np.linspace(density_lim[0], density_lim[1], density_level)\n",
    "    ticks=np.arange(density_lim[0], density_lim[1], density_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, density_grid,  vmin=density_lim[0], vmax=density_lim[1], levels=levels, cmap=ccm.batlow)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"density\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    \n",
    "    ax = fig.add_subplot(gs[2, 0])\n",
    "\n",
    "    levels = np.linspace(metastable_lim[0], metastable_lim[1], metastable_level)\n",
    "    ticks=np.arange(metastable_lim[0], metastable_lim[1], metastable_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, metastable_grid,  vmin=metastable_lim[0], vmax=metastable_lim[1], levels=levels, cmap=\"viridis\")  # Metastable color map\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"metastable\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # save figure\n",
    "    ofile_base = os.path.join(case_dir, \"metastable_initial_nrep_%d\" % (n_repetition))\n",
    "    ofile = ofile_base + \".png\"\n",
    "    fig.savefig(os.path.join(ofile))\n",
    "    print(\"Saved figure %s\" % ofile)\n",
    "    ofile = ofile_base + \".pdf\"\n",
    "    fig.savefig(os.path.join(ofile))\n",
    "    print(\"Saved figure %s\" % ofile)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagram test (TwoDSubduction_metastable_reaction_1ky)\n",
    "\n",
    "This tests make use of\n",
    "\n",
    "    TwoDSubduction_metastable_reaction_1ky.prm\n",
    "\n",
    "### Set up\n",
    "\n",
    "Options\n",
    "\n",
    "* Change the resolution. The test is compiled with low resolution, while here a high resolution result is needed to generate results comparable to the python code results.\n",
    "\n",
    "* Here the set up allows running and plotting the results. Option for plotting only is:\n",
    "\n",
    "    is_run_aspect_tests_1ky_solving = False\n",
    "\n",
    "* For testing run time of the metastbale part, turn this option on and off and look at the run time\n",
    "\n",
    "    with_metastable = True\n",
    "\n",
    "* For testing the code of the metastable function, turn this option on and off to skip the computation\n",
    "\n",
    "    reaction_metastable_trivial = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_run_aspect_tests_1ky = False\n",
    "is_run_aspect_tests_1ky_solving = True\n",
    "\n",
    "if is_run_aspect_tests_1ky:\n",
    "\n",
    "    with_metastable = True\n",
    "    with_grain_size_evolution = True\n",
    "    reaction_metastable_trivial = False\n",
    "    test_composition = \"spharz\"  # background or spharz\n",
    "    n_repetition = 50  # 50 - original, 200 - high to make plots\n",
    "\n",
    "    aspect_dir = \"/home/lochy/Softwares/aspect\"\n",
    "    aspect_executable = os.path.join(aspect_dir, \"build_master_TwoD_rebase/aspect\")\n",
    "    if with_grain_size_evolution:\n",
    "        prm_template_path = os.path.join(aspect_dir, \"tests\", \"TwoDSubduction_metastable_reaction_grain_size.prm\")\n",
    "        case_dir = os.path.join(\"/mnt/lochy/ASPECT_DATA/MOW/mow_tests2\", \"TwoDSubduction_metastable_reaction_grain_size\")  # New directory to run the case\n",
    "    else:\n",
    "        prm_template_path = os.path.join(aspect_dir, \"tests\", \"TwoDSubduction_metastable_reaction_1ky.prm\")\n",
    "        case_dir = os.path.join(\"/mnt/lochy/ASPECT_DATA/MOW/mow_tests2\", \"TwoDSubduction_metastable_reaction_1ky\")  # New directory to run the case\n",
    "\n",
    "    assert(os.path.isfile(aspect_executable))\n",
    "    assert(os.path.isfile(prm_template_path))\n",
    "\n",
    "    # assign another directory to run the case\n",
    "    case_root_dir = os.path.join(root_path, \"dtemp\") \n",
    "\n",
    "    if not os.path.isdir(case_dir):\n",
    "        os.mkdir(case_dir)\n",
    "\n",
    "    if with_metastable:\n",
    "        if reaction_metastable_trivial:\n",
    "            output_dirname = \"output_reaction_trivial_nrep_%d\" % n_repetition  # output directory\n",
    "        else:\n",
    "            output_dirname = \"output_nrep_%d\" % n_repetition  # output directory\n",
    "    else:\n",
    "        output_dirname = \"output_trivial_nrep_%d\" % n_repetition  # output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_1ky and is_run_aspect_tests_1ky_solving:\n",
    "\n",
    "    from hamageolib.utils.dealii_param_parser import parse_parameters_to_dict, save_parameters_from_dict\n",
    "    from hamageolib.utils.world_builder_file_parser import find_feature_by_name, update_or_add_feature\n",
    "\n",
    "\n",
    "    # Modify the template\n",
    "    # Also read important parameters like the size of the model\n",
    "\n",
    "    with open(prm_template_path, 'r') as file:\n",
    "        params_dict = parse_parameters_to_dict(file)\n",
    "\n",
    "\n",
    "\n",
    "    params_dict[\"Output directory\"] = os.path.join(case_dir, output_dirname)\n",
    "\n",
    "    params_dict[\"Additional shared libraries\"] = \"$ASPECT_SOURCE_DIR/build_master_TwoD_rebase/subduction_temperature2d/libsubduction_temperature2d.so, $ASPECT_SOURCE_DIR/build_master_TwoD_rebase/prescribe_field/libprescribed_temperature.so, $ASPECT_SOURCE_DIR/build_master_TwoD_rebase/visco_plastic_TwoD/libvisco_plastic_TwoD.so\"\n",
    "\n",
    "    params_dict[\"Geometry model\"][\"Box\"][\"X repetitions\"] = str(n_repetition)\n",
    "    params_dict[\"Geometry model\"][\"Box\"][\"Y repetitions\"] = str(n_repetition)\n",
    "        \n",
    "    if test_composition == \"background\":\n",
    "        pass\n",
    "    elif test_composition == \"spharz\":\n",
    "        if with_grain_size_evolution:\n",
    "            params_dict[\"Initial composition model\"][\"Function\"][\"Function expression\"] = \"0.0 ; 1.0; 0.0 ; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0\"\n",
    "        else:\n",
    "            params_dict[\"Initial composition model\"][\"Function\"][\"Function expression\"] = \"0.0 ; 1.0; 0.0 ; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0\"\n",
    "    else:\n",
    "        raise ValueError(\"test_composition must be background or spharz\")\n",
    "\n",
    "    if not with_metastable:\n",
    "        params_dict[\"Compositional fields\"] =  \\\n",
    "        {\n",
    "            \"Number of fields\": \"4\", \"Names of fields\": \"spcrust, spharz, opcrust, opharz\",\\\n",
    "                \"Compositional field methods\" : \"particles, particles, particles, particles\",\\\n",
    "                    \"Mapped particle properties\": \"spcrust: initial spcrust, spharz:initial spharz, opharz:initial opharz, opcrust: initial opcrust\"\n",
    "        }\n",
    "\n",
    "        params_dict[\"Initial composition model\"][\"Function\"][\"Function expression\"] = \"0.0 ; 0.0; 0.0 ; 0.0\"\n",
    "        \n",
    "        params_dict[\"Material model\"][\"Visco Plastic TwoD\"][\"Reaction metastable\"] = \"false\"\n",
    "        params_dict[\"Material model\"][\"Visco Plastic TwoD\"][\"Densities\"] = \"background: 3300.0|3394.4|3442.1|3453.2|3617.6|3691.5|3774.7|3929.1,\\\n",
    "                        spharz: 3235.0|3372.3|3441.7|3441.7|3680.8|3717.8|3759.4|3836.6,\\\n",
    "                        spcrust: 3000.0|3540.0|3613.0|3871.7,\\\n",
    "                        opcrust: 3000.0, opharz: 3235.0\"\n",
    "\n",
    "        params_dict[\"Material model\"][\"Visco Plastic TwoD\"].pop(\"Metastable transition\")\n",
    "        # params_dict[\"Material model\"][\"Visco Plastic TwoD\"].pop(\"Metastable transition comp\")\n",
    "\n",
    "        params_dict[\"Particles\"][\"List of particle properties\"] = \"initial composition\"\n",
    "\n",
    "    if reaction_metastable_trivial:\n",
    "        params_dict[\"Material model\"][\"Visco Plastic TwoD\"][\"Reaction metastable trivial\"] = \"true\"\n",
    "\n",
    "    params_dict[\"Postprocess\"][\"Visualization\"][\"Output format\"] = \"vtu\"\n",
    "\n",
    "\n",
    "\n",
    "    # Write to a prm file in the new case directory\n",
    "    prm_path = os.path.join(case_dir, \"case.prm\")\n",
    "\n",
    "    with open(prm_path, 'w') as output_file:\n",
    "        save_parameters_from_dict(output_file, params_dict)\n",
    "\n",
    "    assert(os.path.isfile(prm_path))\n",
    "\n",
    "    print(\"Created case in %s\" % (case_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run\n",
    "\n",
    "Use \"subprocess.run\" to run the case.\n",
    "\n",
    "Capture the standard output and error streams\n",
    "\n",
    "Check\n",
    "  * if the expected line indicating wallclock time appears in the output.\n",
    "  * There is no stderr output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_1ky and is_run_aspect_tests_1ky_solving:\n",
    "\n",
    "    # Run theb ASPECT executable with the parameter file\n",
    "    # The function ensures that both the expected outputs are generated and no errors are produced\n",
    "    # 'capture_output=True' collects both stdout and stderr for further checks\n",
    "    completed_process = subprocess.run([aspect_executable, prm_path], capture_output=True, text=True)\n",
    "\n",
    "    # Capture the standard output and error streams\n",
    "    stdout = completed_process.stdout\n",
    "    stderr = completed_process.stderr\n",
    "\n",
    "    # Uncomment the following lines for debugging purposes to inspect the output\n",
    "    # print(stdout)  # Debugging: Prints the standard output\n",
    "    # print(stderr)  # Debugging: Prints the standard error\n",
    "\n",
    "    # Check if the expected line indicating wallclock time appears in the output\n",
    "    # The expected line format is something like:\n",
    "    # -- Total wallclock time elapsed including restarts: 1s\n",
    "    assert(re.match(\".*Total wallclock\", stdout.split('\\n')[-6]))\n",
    "\n",
    "    # Ensure that the error stream is empty, indicating no issues during the run\n",
    "    assert(stderr == \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if is_run_aspect_tests_1ky and is_run_aspect_tests_1ky_solving:\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the stdout output to a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if is_run_aspect_tests_1ky and is_run_aspect_tests_1ky_solving:\n",
    "\n",
    "    std_file = os.path.join(case_dir, \"stdout.txt\")\n",
    "\n",
    "    with open(std_file, \"w\") as fout:\n",
    "        fout.write(stdout)\n",
    "\n",
    "    print(\"Saved stdout outputs: %s\" % std_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_1ky:\n",
    "\n",
    "    vtu_step = 1  # * 1ky\n",
    "\n",
    "    import vtk\n",
    "    from vtk.util.numpy_support import vtk_to_numpy\n",
    "    from hamageolib.utils.vtk_utilities import calculate_resolution\n",
    "    import time\n",
    "    from scipy.interpolate import LinearNDInterpolator\n",
    "\n",
    "    pvtu_file = os.path.join(case_dir, output_dirname, \"solution\", \"solution-%05d.pvtu\" % vtu_step)\n",
    "    assert(os.path.isfile(pvtu_file))\n",
    "\n",
    "    # Read the pvtu file\n",
    "    start = time.time()\n",
    "\n",
    "    reader = vtk.vtkXMLPUnstructuredGridReader()\n",
    "    reader.SetFileName(pvtu_file)\n",
    "    reader.Update()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Initiating reader takes %.2e s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Get the output data from the reader\n",
    "    grid = reader.GetOutput()  # Access the unstructured grid\n",
    "    data_set = reader.GetOutputAsDataSet()  # Access the dataset representation\n",
    "    points = grid.GetPoints()  # Extract the points (coordinates)\n",
    "    cells = grid.GetCells()  # Extract the cell connectivity information\n",
    "    point_data = data_set.GetPointData()  # Access point-wise data\n",
    "\n",
    "    n_points = grid.GetNumberOfPoints() # Number of points and cells\n",
    "    n_cells = grid.GetNumberOfCells()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Reading files takes %.2e s\" % (end - start))\n",
    "    print(f\"\\tNumber of points: {n_points}\")\n",
    "    print(f\"\\tNumber of cells: {n_cells}\")\n",
    "    print(\"\\tAvailable point data fields:\")\n",
    "    for i in range(point_data.GetNumberOfArrays()):\n",
    "        # Field names in point data\n",
    "        name = point_data.GetArrayName(i)\n",
    "        print(f\"\\t  - {name}\")\n",
    "    start = end\n",
    "\n",
    "    # Convert data to numpy array\n",
    "    # Get coordinates (points)\n",
    "    # Get field \"T\"\n",
    "    vtk_points = grid.GetPoints().GetData()\n",
    "    points_np = vtk_to_numpy(vtk_points)  # Shape: (n_points, 3)\n",
    "    points_2d = points_np[:, :2]  # Use only the first two columns for 2D coordinates\n",
    "\n",
    "    # Initialize dictionary for interpolators\n",
    "    interpolators = {}\n",
    "\n",
    "    # Loop over all arrays in point data\n",
    "    num_arrays = point_data.GetNumberOfArrays()\n",
    "    for i in range(num_arrays):\n",
    "        array_name = point_data.GetArrayName(i)\n",
    "        vtk_array = point_data.GetArray(i)\n",
    "        \n",
    "        if vtk_array is None:\n",
    "            print(f\"Warning: Array {array_name} is None, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Convert VTK array to NumPy\n",
    "        np_array = vtk_to_numpy(vtk_array)\n",
    "        \n",
    "        # Create interpolator and add to dict\n",
    "        interpolators[array_name] = LinearNDInterpolator(points_2d, np_array, fill_value=np.nan)\n",
    "\n",
    "    # Calculate resolution for each cell or point in the grid\n",
    "    resolution_np = calculate_resolution(grid)  # Custom function (not defined here)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Calculating resolution takes %.2e s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Create interpolators for temperature, pressure, and resolution\n",
    "    interpolators[\"resolution\"] = LinearNDInterpolator(points_2d, resolution_np)  # Interpolator for resolution\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Construct linear ND interpolator takes %.2e s\" % (end - start))\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_1ky:\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    # Define the interval for the grid (in meters)\n",
    "    interval = 1000.0\n",
    "\n",
    "    # Determine the bounding box of the 2D points\n",
    "    x_min, y_min = np.min(points_2d, axis=0)\n",
    "    x_max, y_max = np.max(points_2d, axis=0)\n",
    "\n",
    "    # Define a regular grid within the bounding box\n",
    "    # allow a little different in interval in x\n",
    "    # and y axis, thereform making the two dimensions\n",
    "    # unequal to make fewer mistakes ...\n",
    "    xs = np.arange(x_min, x_max, interval*0.99)\n",
    "    ys = np.arange(y_min, y_max, interval*1.01)\n",
    "    x_grid, y_grid = np.meshgrid(xs, ys, indexing=\"ij\")  # Create a grid of (x, y) points\n",
    "\n",
    "    # Flatten the grid for interpolation\n",
    "    grid_points_2d = np.vstack([x_grid.ravel(), y_grid.ravel()]).T\n",
    "\n",
    "    # Interpolate temperature (T) values onto the regular grid\n",
    "    T_grid = interpolators[\"T\"](grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    T_grid = T_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate temperature (P) values onto the regular grid\n",
    "    P_grid = interpolators[\"p\"](grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    P_grid = P_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate resolutions onto the regular grid\n",
    "    resolutions_grid = interpolators[\"resolution\"](grid_points_2d)\n",
    "    resolutions_grid = resolutions_grid.reshape(x_grid.shape)\n",
    "\n",
    "    # Interpolate density onto the regular grid\n",
    "    density_grid = interpolators[\"density\"](grid_points_2d)\n",
    "    density_grid = density_grid.reshape(x_grid.shape)\n",
    "\n",
    "    # Interpolate viscosity onto the regular grid\n",
    "    viscosity_grid = interpolators[\"viscosity\"](grid_points_2d)\n",
    "    viscosity_grid = viscosity_grid.reshape(x_grid.shape)\n",
    "\n",
    "\n",
    "    # Interpolate the grain size grid\n",
    "    if with_grain_size_evolution:\n",
    "\n",
    "\n",
    "        grain_size_grid = interpolators[\"meta_grain_size\"](grid_points_2d)\n",
    "        grain_size_grid = grain_size_grid.reshape(x_grid.shape)\n",
    "\n",
    "\n",
    "    # Interpolate latent heat onto the regular grid\n",
    "    # lheat_grid = interpolators[\"latent_heat\"](grid_points_2d)\n",
    "    # lheat_grid = lheat_grid.reshape(x_grid.shape)\n",
    "\n",
    "    # Interpolate metastable compositions onto the regular grid\n",
    "    if with_metastable:\n",
    "        metastable_grid = interpolators[\"metastable\"](grid_points_2d)\n",
    "        metastable_grid = metastable_grid.reshape(x_grid.shape)\n",
    "        \n",
    "        metarate_grid = interpolators[\"meta_rate\"](grid_points_2d)\n",
    "        metarate_grid = metarate_grid.reshape(x_grid.shape)\n",
    "\n",
    "        grain_density_grid = interpolators[\"meta_x0\"](grid_points_2d)\n",
    "        grain_density_grid = grain_density_grid.reshape(x_grid.shape)\n",
    "        \n",
    "        meta_x1_grid = interpolators[\"meta_x1\"](grid_points_2d)\n",
    "        meta_x1_grid = meta_x1_grid.reshape(x_grid.shape)\n",
    "        \n",
    "        meta_x2_grid = interpolators[\"meta_x2\"](grid_points_2d)\n",
    "        meta_x2_grid = meta_x2_grid.reshape(x_grid.shape)\n",
    "        \n",
    "        meta_x3_grid = interpolators[\"meta_x3\"](grid_points_2d)\n",
    "        meta_x3_grid = meta_x3_grid.reshape(x_grid.shape)\n",
    "        \n",
    "        meta_is_grid = interpolators[\"meta_is\"](grid_points_2d)\n",
    "        meta_is_grid = meta_is_grid.reshape(x_grid.shape)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Interpolating to regular grid takes %.2e s\" % (end - start))\n",
    "    print(\"\\tgrid shape: (x axis, y axis): \", x_grid.shape)\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the metastable kinetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_1ky:\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    from matplotlib import gridspec\n",
    "    from cmcrameri import cm as ccm\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (0.0, 800) # km\n",
    "    x_tick_interval = 100   # tick interval along x\n",
    "    y_lim = (0.0, 1200) # km\n",
    "    y_tick_interval = 100  # tick interval along y\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # Create a figure with a 2x2 grid layout\n",
    "    fig = plt.figure(figsize=(12, 25), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(5, 2)\n",
    "\n",
    "    # meta_x0\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    grain_density_grid_min = np.min(grain_density_grid)\n",
    "    grain_density_grid_max = np.max(grain_density_grid)\n",
    "    levels = np.linspace(grain_density_grid_min, grain_density_grid_max, 50)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, grain_density_grid,  cmap=\"viridis\", levels=levels)\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"meta_x0\")  # Add colorbar\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # meta_x1\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "    meta_x1_grid_min = np.min(meta_x1_grid)\n",
    "    meta_x1_grid_max = np.max(meta_x1_grid)\n",
    "    levels = np.linspace(meta_x1_grid_min, meta_x1_grid_max, 50)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, meta_x1_grid,  cmap=\"viridis\", levels=levels)\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"meta_x1\")  # Add colorbar\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # meta_x2\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "    meta_x2_grid_min = np.min(meta_x2_grid)\n",
    "    meta_x2_grid_max = np.max(meta_x2_grid)\n",
    "    levels = np.linspace(meta_x2_grid_min, meta_x2_grid_max, 50)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, meta_x2_grid,  cmap=\"viridis\", levels=levels)\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"meta_x2\")  # Add colorbar\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # meta_x3\n",
    "    ax = fig.add_subplot(gs[1, 1])\n",
    "    meta_x3_grid_min = np.min(meta_x3_grid)\n",
    "    meta_x3_grid_max = np.max(meta_x3_grid)\n",
    "    levels = np.linspace(meta_x3_grid_min, meta_x3_grid_max, 50)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, meta_x3_grid,  cmap=\"viridis\", levels=levels)\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"meta_x3\")  # Add colorbar\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # metastable\n",
    "    ax = fig.add_subplot(gs[2, 0])\n",
    "    metastable_grid_min = np.min(metastable_grid)\n",
    "    metastable_grid_max = np.max(metastable_grid)\n",
    "    levels = np.linspace(metastable_grid_min, metastable_grid_max, 50)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, metastable_grid,  cmap=\"viridis\", levels=levels)\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"metastable\")  # Add colorbar\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # save figure\n",
    "    if reaction_metastable_trivial:\n",
    "        ofile_base = os.path.join(case_dir, \"metastable_diagram_trivial_nrep_%d_vstep_%05d_raw_kinetics\" % (n_repetition, vtu_step))\n",
    "    else:\n",
    "        ofile_base = os.path.join(case_dir, \"metastable_diagram_nrep_%d_vstep_%05d_raw_kinetics\" % (n_repetition, vtu_step))\n",
    "    ofile = ofile_base + \".png\"\n",
    "    fig.savefig(os.path.join(ofile))\n",
    "    print(\"Saved figure %s\" % ofile)\n",
    "    ofile = ofile_base + \".pdf\"\n",
    "    fig.savefig(os.path.join(ofile))\n",
    "    print(\"Saved figure %s\" % ofile)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_1ky:\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    from matplotlib import gridspec\n",
    "    from cmcrameri import cm as ccm\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (0.0, 800) # km\n",
    "    x_tick_interval = 100   # tick interval along x\n",
    "    y_lim = (0.0, 1200) # km\n",
    "    y_tick_interval = 100  # tick interval along y\n",
    "\n",
    "    resolution_lim = (0.0, 100e3) # resolution\n",
    "    resolution_level = 50  # number of levels in contourf plot\n",
    "    resolution_tick_interval = 25e3  # tick interval along v\n",
    "\n",
    "    T_lim = (0.0, 2000.0) # T\n",
    "    T_level = 50  # number of levels in contourf plot\n",
    "    T_tick_interval = 250.0  # tick interval along v\n",
    "\n",
    "    P_lim = (np.min(P_grid), np.max(P_grid)) # P\n",
    "    P_level = 50  # number of levels in contourf plot\n",
    "    P_tick_interval = 1e9  # tick interval along P\n",
    "    \n",
    "    density_lim = (3000.0, 4000.0)\n",
    "    density_level = 50  # number of levels in contourf plot\n",
    "    density_tick_interval = 100.0  # tick interval along P\n",
    "\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # Create a figure with a 2x2 grid layout\n",
    "    fig = plt.figure(figsize=(12, 25), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(5, 2)\n",
    "\n",
    "    # Plot the mesh resolution\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    levels = np.linspace(resolution_lim[0], resolution_lim[1], resolution_level)\n",
    "    ticks=np.arange(resolution_lim[0], resolution_lim[1], resolution_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, resolutions_grid,  vmin=resolution_lim[0], vmax=resolution_lim[1], levels=levels, cmap=\"plasma_r\")  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"Resolution\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # Plot T\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    levels = np.linspace(T_lim[0], T_lim[1], T_level)\n",
    "    ticks=np.arange(T_lim[0], T_lim[1], T_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, T_grid,  vmin=T_lim[0], vmax=T_lim[1], levels=levels, cmap=ccm.lapaz)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"T\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # Plot P\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "    levels = np.linspace(P_lim[0], P_lim[1], P_level)\n",
    "    ticks=np.arange(P_lim[0], P_lim[1], P_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, P_grid,  vmin=P_lim[0], vmax=P_lim[1], levels=levels, cmap=ccm.tokyo_r)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"P\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Plot density\n",
    "    ax = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "    levels = np.linspace(density_lim[0], density_lim[1], density_level)\n",
    "    ticks=np.arange(density_lim[0], density_lim[1], density_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, density_grid,  vmin=density_lim[0], vmax=density_lim[1], levels=levels, cmap=ccm.batlow)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"density\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    \n",
    "    # Plot heating term\n",
    "    # ax = fig.add_subplot(gs[2, 0])\n",
    "\n",
    "    # heating_lim = (-2e-3, 2e-3)\n",
    "    # heating_level = 50\n",
    "    # heating_tick_interval = 5e-4\n",
    "\n",
    "    # levels = np.linspace(heating_lim[0], heating_lim[1], heating_level)\n",
    "    # ticks=np.arange(heating_lim[0], heating_lim[1], heating_tick_interval) \n",
    "    \n",
    "    # color_map = ax.contourf(x_grid/1e3, y_grid/1e3, lheat_grid, levels=levels)\n",
    "    # cbar = fig.colorbar(color_map, ax=ax, label=\"latent heat\", cmap=ccm.glasgow)  # Add colorbar\n",
    "    # cbar.set_ticks(ticks)\n",
    "    \n",
    "    # ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    # ax.set_xlim(x_lim)\n",
    "    # ax.set_ylim(y_lim)\n",
    "\n",
    "    # ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    # ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    # ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    # ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    # ax.set_xlabel(\"X\")\n",
    "    # ax.set_ylabel(\"Y\")\n",
    "    \n",
    "    # for spine in ax.spines.values():\n",
    "    #     # Adjust spine thickness for this plot\n",
    "    #     spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    \n",
    "    # Plot meta rate\n",
    "    ax = fig.add_subplot(gs[2, 1])\n",
    "\n",
    "    metarate_lim = (0, 1e-11)\n",
    "    # levels = np.linspace(metarate_lim[0], metarate_lim[1], 50)\n",
    "    # metarate_tick_interval = 2.5e-12\n",
    "    # ticks=np.arange(metarate_lim[0], metarate_lim[1], metarate_tick_interval)\n",
    "    # levels = np.linspace(0.0, np.max(metarate_grid), 50)\n",
    "    # ticks = np.linspace(0.0, np.max(metarate_grid), 10)\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, metarate_grid, cmap=ccm.buda) #, cmap=ccm.buda, vmin=0.0, vmax=1.0) #, level=levels) \n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"meta rate\")  # Add colorbar\n",
    "    # cbar.set_ticks(ticks)\n",
    "    \n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # plot grain size\n",
    "    # First plot the initial grain size\n",
    "    # Then the grain size after growth\n",
    "    if with_grain_size_evolution:\n",
    "        from hamageolib.core.GrainSize import GrainGrowthModel, GrainGrowthParams\n",
    "        year = 365 * 24 * 3600.0\n",
    "\n",
    "        initial_grain_size_grid = (6.0 * metastable_grid / grain_density_grid / np.pi)**(1.0/3.0)\n",
    "        grain_size_log_range = [-8.0, -1.0]\n",
    "        ax = fig.add_subplot(gs[3, 0])\n",
    "        levels = np.linspace(grain_size_log_range[0], grain_size_log_range[1], 50)\n",
    "        ticks=np.arange(grain_size_log_range[0], grain_size_log_range[1]+0.1, 1.0)\n",
    "        color_map = ax.contourf(x_grid/1e3, y_grid/1e3, np.log10(initial_grain_size_grid), cmap=\"viridis\", levels=levels, extend=\"both\") \n",
    "        cbar = fig.colorbar(color_map, ax=ax, label=\"log10(initial grain_size)\")  # Add colorbar\n",
    "        cbar.set_ticks(ticks)\n",
    "\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "        ax.set_xlim(x_lim)\n",
    "        ax.set_ylim(y_lim)\n",
    "\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "        \n",
    "        for spine in ax.spines.values():\n",
    "            # Adjust spine thickness for this plot\n",
    "            spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "        ax = fig.add_subplot(gs[3, 1])\n",
    "        color_map = ax.contourf(x_grid/1e3, y_grid/1e3, np.log10(grain_size_grid), cmap=\"viridis\", levels=levels, extend=\"both\")\n",
    "        cbar = fig.colorbar(color_map, ax=ax, label=\"log10(grain_size)\")  # Add colorbar\n",
    "        cbar.set_ticks(ticks)\n",
    "\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "        ax.set_xlim(x_lim)\n",
    "        ax.set_ylim(y_lim)\n",
    "\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "        \n",
    "        for spine in ax.spines.values():\n",
    "            # Adjust spine thickness for this plot\n",
    "            spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "        # Parameters for Wd grain growth\n",
    "        params = GrainGrowthParams(\n",
    "            grain_growth_rate_constant=3.02e-4,\n",
    "            m=3,\n",
    "            grain_growth_activation_energy=6.62e5,\n",
    "            grain_growth_activation_volume=0.0,\n",
    "        )\n",
    "\n",
    "        gModel = GrainGrowthModel(params=params)\n",
    "\n",
    "        time_scale = 1e6 * year\n",
    "        synthetic_grain_size_grid = np.full(initial_grain_size_grid.shape, np.nan)\n",
    "        mask = (initial_grain_size_grid > 0)\n",
    "        synthetic_grain_size_grid[mask] = gModel.grain_size_at_time(initial_grain_size_grid[mask], time_scale, P_grid[mask], T_grid[mask])\n",
    "\n",
    "        ax = fig.add_subplot(gs[4, 0])\n",
    "        color_map = ax.contourf(x_grid/1e3, y_grid/1e3, np.log10(synthetic_grain_size_grid), cmap=\"viridis\", levels=levels, extend=\"both\")\n",
    "        cbar = fig.colorbar(color_map, ax=ax, label=\"log10(grain_size)\")  # Add colorbar\n",
    "        cbar.set_ticks(ticks)\n",
    "\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "        ax.set_xlim(x_lim)\n",
    "        ax.set_ylim(y_lim)\n",
    "\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "        \n",
    "        for spine in ax.spines.values():\n",
    "            # Adjust spine thickness for this plot\n",
    "            spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "        # plot viscosity\n",
    "        ax = fig.add_subplot(gs[4, 1])\n",
    "\n",
    "        levels = np.linspace(10.0, 30.0, 50)\n",
    "        ticks=np.arange(10.0, 30.0+0.1, 1.0)\n",
    "        color_map = ax.contourf(x_grid/1e3, y_grid/1e3, np.log10(viscosity_grid), cmap=ccm.tokyo_r, levels=levels, extend=\"both\")\n",
    "        cbar = fig.colorbar(color_map, ax=ax, label=\"log10(viscosity)\")  # Add colorbar\n",
    "        cbar.set_ticks(ticks)\n",
    "\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "        ax.set_xlim(x_lim)\n",
    "        ax.set_ylim(y_lim)\n",
    "\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "        \n",
    "        for spine in ax.spines.values():\n",
    "            # Adjust spine thickness for this plot\n",
    "            spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # save figure\n",
    "    if reaction_metastable_trivial:\n",
    "        ofile_base = os.path.join(case_dir, \"metastable_diagram_trivial_nrep_%d_vstep_%05d_raw\" % (n_repetition, vtu_step))\n",
    "    else:\n",
    "        ofile_base = os.path.join(case_dir, \"metastable_diagram_nrep_%d_vstep_%05d_raw\" % (n_repetition, vtu_step))\n",
    "    ofile = ofile_base + \".png\"\n",
    "    fig.savefig(os.path.join(ofile))\n",
    "    print(\"Saved figure %s\" % ofile)\n",
    "    ofile = ofile_base + \".pdf\"\n",
    "    fig.savefig(os.path.join(ofile))\n",
    "    print(\"Saved figure %s\" % ofile)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the diagram at give step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_1ky:\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    from matplotlib import gridspec\n",
    "    from cmcrameri import cm as ccm\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "\n",
    "    T_lim = (400.0, 1800.0) # T (K)\n",
    "    T_level = 50  # number of levels in contourf plot\n",
    "    T_tick_interval = 200.0  # tick interval along v\n",
    "\n",
    "    T_lim1 = (0.0, 800.0) # T (C), smaller scale\n",
    "    T_tick_interval1 = 200.0  # tick interval along x\n",
    "\n",
    "    P_lim = (10.0, 30.0) # P (Gpa)\n",
    "    P_level = 50  # number of levels in contourf plot\n",
    "    P_tick_interval = 5.0  # tick interval along v\n",
    "\n",
    "    density_lim = (3000.0, 4000.0)\n",
    "    density_level = 50  # number of levels in contourf plot\n",
    "    density_tick_interval = 100.0  # tick interval along P\n",
    "\n",
    "    metastable_lim = (0.0, 1.0) # metastable contents\n",
    "    metastable_level = 100\n",
    "    metastable_interval = 0.2\n",
    "\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # Create a figure\n",
    "    fig = plt.figure(figsize=(10, 4.25), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "\n",
    "    # Plot the diagram of metastable composition\n",
    "    if with_metastable:\n",
    "        ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "        levels = np.linspace(metastable_lim[0], metastable_lim[1], metastable_level)\n",
    "        ticks=np.arange(metastable_lim[0], metastable_lim[1], metastable_interval)\n",
    "\n",
    "        color_map = ax.contourf(T_grid, P_grid/1e9, metastable_grid, levels=levels,\\\n",
    "                                vmin=metastable_lim[0], vmax=metastable_lim[1], cmap=\"viridis\")\n",
    "\n",
    "        contour_099 = ax.contour(\n",
    "            T_grid, P_grid / 1e9, metastable_grid,\n",
    "            levels=[0.5, 0.99],\n",
    "            colors=[\"tab:gray\", 'k'],  # or any other color you prefer\n",
    "            linewidths=1.5,\n",
    "            linestyles='-'\n",
    "        )\n",
    "\n",
    "        cbar = fig.colorbar(color_map, ax=ax, label=\"Metastable\")  # Add colorbar\n",
    "        cbar.set_ticks(ticks)\n",
    "\n",
    "        ax.set_xlim(T_lim)\n",
    "        ax.set_ylim(P_lim)\n",
    "\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(T_tick_interval))\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(T_tick_interval/(n_minor_ticks+1)))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(P_tick_interval))\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(P_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "        ax.grid()\n",
    "\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        ax.set_xlabel(\"T (K)\")\n",
    "        ax.set_ylabel(\"P (GPa)\")\n",
    "\n",
    "        for spine in ax.spines.values():\n",
    "            # Adjust spine thickness for this plot\n",
    "            spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Plot the diagram of density\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    levels = np.linspace(density_lim[0], density_lim[1], density_level)\n",
    "    ticks=np.arange(density_lim[0], density_lim[1], density_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(T_grid, P_grid/1e9, density_grid, levels=levels,\\\n",
    "                            vmin=density_lim[0], vmax=density_lim[1], cmap=ccm.batlow)\n",
    "\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"Density\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_xlim(T_lim)\n",
    "    ax.set_ylim(P_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(T_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(T_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(P_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(P_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_xlabel(\"T (K)\")\n",
    "    ax.set_ylabel(\"P (GPa)\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    if reaction_metastable_trivial:\n",
    "        ofile = os.path.join(case_dir, \"metastable_diagram_trivial_nrep_%d_vstep_%05d.pdf\" % (n_repetition, vtu_step))\n",
    "    else:\n",
    "        ofile = os.path.join(case_dir, \"metastable_diagram_nrep_%d_vstep_%05d.pdf\" % (n_repetition, vtu_step))\n",
    "\n",
    "    fig.savefig(ofile)\n",
    "    print(\"saved figure %s\" % ofile)\n",
    "    \n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot summary of run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case_summary.csv is deleted, so skip for now\n",
    "if is_run_aspect_tests_1ky and False:\n",
    "    \n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 3.0 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (0.0, 250.0)\n",
    "    x_tick_interval = 50.0   # tick interval along x\n",
    "    y_lim = (0.0, 300.0)\n",
    "    y_tick_interval = 50.0  # tick interval along y\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    summary_file = os.path.join(case_dir, \"summary.csv\")\n",
    "\n",
    "    assert(os.path.join(summary_file))\n",
    "\n",
    "    df = pd.read_csv(summary_file)\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Plot each group by 'description'\n",
    "    i = 0\n",
    "    for key, group in df.groupby('description'):\n",
    "        ax.plot(group['repitition'], group['runtime'], marker='o', linestyle=\"-\", label=key, color=default_colors[i])\n",
    "        ax.plot(group['repitition'], group['particle_update_properties_time'], marker='o', linestyle=\"--\", label=key, color=default_colors[i])\n",
    "        i += 1\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    # Axis labels and formatting\n",
    "    ax.set_xlabel(\"Repetition\")\n",
    "    ax.set_ylabel(\"Runtime (s)\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Adjust spine thickness for this plot\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    ofile = os.path.join(case_dir, \"runtime_summary.pdf\")\n",
    "    fig.savefig(ofile)\n",
    "\n",
    "    print(\"Saved figure: %s\" % ofile)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slab tests (TwoDSubduction_metastable_slab)\n",
    "\n",
    "This test makes use of\n",
    "\n",
    "    TwoDSubduction_metastable_slab.prm\n",
    "\n",
    "In this test, we create a synthetic slab using **ASPECT** + **WorldBuilder** and run the kinetics for the first few time steps.\n",
    "The outputs include the metastable field, grain size, and viscosity structure.\n",
    "\n",
    "### Set up\n",
    "\n",
    "Options:\n",
    "- Change the resolution (by adjusting the adaptive_refinement variable) — The test is compiled with a low resolution, whereas a high-resolution run is required here to generate results comparable to the Python-code results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "is_run_aspect_tests_slab = False\n",
    "is_run_aspect_tests_slab_solving = False\n",
    "\n",
    "if is_run_aspect_tests_slab:\n",
    "\n",
    "    from shutil import copy\n",
    "\n",
    "    no_iteration = False\n",
    "    adaptive_refinement = 4\n",
    "\n",
    "    aspect_dir = \"/home/lochy/Softwares/aspect\"\n",
    "    aspect_executable = os.path.join(aspect_dir, \"build_master_TwoD_rebase/aspect\")\n",
    "    prm_template_path = os.path.join(aspect_dir, \"tests\", \"TwoDSubduction_metastable_slab.prm\")\n",
    "    wb_template_path = os.path.join(aspect_dir, \"tests\", \"TwoDSubduction_metastable_slab.wb\")\n",
    "    case_dir = os.path.join(\"/mnt/lochy/ASPECT_DATA/MOW/mow_tests2\", \"TwoDSubduction_metastable_slab_1\")  # New directory to run the case\n",
    "\n",
    "    assert(os.path.isfile(aspect_executable))\n",
    "    assert(os.path.isfile(prm_template_path))\n",
    "    assert(os.path.isfile(wb_template_path))\n",
    "\n",
    "    # assign another directory to run the case\n",
    "    case_root_dir = os.path.join(root_path, \"dtemp\") \n",
    "\n",
    "    if not os.path.isdir(case_dir):\n",
    "        os.mkdir(case_dir)\n",
    "\n",
    "    copy(wb_template_path, case_dir)\n",
    "\n",
    "    if no_iteration:\n",
    "        output_dirname = \"output_ni_ar%02d\" % adaptive_refinement # output directory\n",
    "    else:\n",
    "        output_dirname = \"output_ar%02d\" % adaptive_refinement  # output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_slab:\n",
    "\n",
    "    from hamageolib.utils.dealii_param_parser import parse_parameters_to_dict, save_parameters_from_dict\n",
    "    from hamageolib.utils.world_builder_file_parser import find_feature_by_name, update_or_add_feature\n",
    "\n",
    "\n",
    "    # Modify the template\n",
    "    # Also read important parameters like the size of the model\n",
    "\n",
    "    with open(prm_template_path, 'r') as file:\n",
    "        params_dict = parse_parameters_to_dict(file)\n",
    "\n",
    "    params_dict[\"Output directory\"] = os.path.join(case_dir, output_dirname)\n",
    "\n",
    "    params_dict[\"Additional shared libraries\"] = \"$ASPECT_SOURCE_DIR/build_master_TwoD_rebase/prescribe_field/libprescribed_temperature.so, $ASPECT_SOURCE_DIR/build_master_TwoD_rebase/visco_plastic_TwoD/libvisco_plastic_TwoD.so, $ASPECT_SOURCE_DIR/build_master_TwoD_rebase/isosurfaces_TwoD1/libisosurfaces_TwoD1.so\"\n",
    "\n",
    "    if no_iteration:\n",
    "        params_dict[\"Nonlinear solver scheme\"] = \"no Advection, no Stokes\"\n",
    "\n",
    "    params_dict[\"Mesh refinement\"][\"Initial adaptive refinement\"] = str(adaptive_refinement)\n",
    "\n",
    "    # params_dict[\"Geometry model\"][\"Box\"][\"X repetitions\"] = str(n_repetition)\n",
    "    # params_dict[\"Geometry model\"][\"Box\"][\"Y repetitions\"] = str(n_repetition)\n",
    "\n",
    "    params_dict[\"Postprocess\"][\"Visualization\"][\"Output format\"] = \"vtu\"\n",
    "\n",
    "\n",
    "    # Write to a prm file in the new case directory\n",
    "    prm_path = os.path.join(case_dir, \"case.prm\")\n",
    "\n",
    "    with open(prm_path, 'w') as output_file:\n",
    "        save_parameters_from_dict(output_file, params_dict)\n",
    "\n",
    "    assert(os.path.isfile(prm_path))\n",
    "\n",
    "    print(\"Created case in %s\" % (case_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run\n",
    "\n",
    "Use \"subprocess.run\" to run the case.\n",
    "\n",
    "Capture the standard output and error streams\n",
    "\n",
    "Check\n",
    "  * if the expected line indicating wallclock time appears in the output.\n",
    "  * There is no stderr output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_slab and is_run_aspect_tests_slab_solving:\n",
    "\n",
    "    # Run theb ASPECT executable with the parameter file\n",
    "    # The function ensures that both the expected outputs are generated and no errors are produced\n",
    "    # 'capture_output=True' collects both stdout and stderr for further checks\n",
    "    completed_process = subprocess.run([aspect_executable, prm_path], capture_output=True, text=True)\n",
    "\n",
    "    # Capture the standard output and error streams\n",
    "    stdout = completed_process.stdout\n",
    "    stderr = completed_process.stderr\n",
    "\n",
    "    # Uncomment the following lines for debugging purposes to inspect the output\n",
    "    # print(stdout)  # Debugging: Prints the standard output\n",
    "    # print(stderr)  # Debugging: Prints the standard error\n",
    "\n",
    "    # Check if the expected line indicating wallclock time appears in the output\n",
    "    # The expected line format is something like:\n",
    "    # -- Total wallclock time elapsed including restarts: 1s\n",
    "    assert(re.match(\".*Total wallclock\", stdout.split('\\n')[-6]))\n",
    "\n",
    "    # Ensure that the error stream is empty, indicating no issues during the run\n",
    "    assert(stderr == \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_slab and is_run_aspect_tests_slab_solving:\n",
    "    print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the stdout output to a separate file\n",
    "if is_run_aspect_tests_slab and is_run_aspect_tests_slab_solving:\n",
    "\n",
    "    std_file = os.path.join(case_dir, \"stdout.txt\")\n",
    "\n",
    "    with open(std_file, \"w\") as fout:\n",
    "        fout.write(stdout)\n",
    "\n",
    "    print(\"Saved stdout outputs: %s\" % std_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_slab:\n",
    "\n",
    "    vtu_step = 5  # * 1ky\n",
    "\n",
    "    import vtk\n",
    "    from vtk.util.numpy_support import vtk_to_numpy\n",
    "    from hamageolib.utils.vtk_utilities import calculate_resolution\n",
    "    import time\n",
    "    from scipy.interpolate import LinearNDInterpolator\n",
    "\n",
    "    pvtu_file = os.path.join(case_dir, output_dirname, \"solution\", \"solution-%05d.pvtu\" % vtu_step)\n",
    "    assert(os.path.isfile(pvtu_file))\n",
    "\n",
    "    # Read the pvtu file\n",
    "    start = time.time()\n",
    "\n",
    "    reader = vtk.vtkXMLPUnstructuredGridReader()\n",
    "    reader.SetFileName(pvtu_file)\n",
    "    reader.Update()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Initiating reader takes %.2e s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Get the output data from the reader\n",
    "    grid = reader.GetOutput()  # Access the unstructured grid\n",
    "    data_set = reader.GetOutputAsDataSet()  # Access the dataset representation\n",
    "    points = grid.GetPoints()  # Extract the points (coordinates)\n",
    "    cells = grid.GetCells()  # Extract the cell connectivity information\n",
    "    point_data = data_set.GetPointData()  # Access point-wise data\n",
    "\n",
    "    n_points = grid.GetNumberOfPoints() # Number of points and cells\n",
    "    n_cells = grid.GetNumberOfCells()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Reading files takes %.2e s\" % (end - start))\n",
    "    print(f\"\\tNumber of points: {n_points}\")\n",
    "    print(f\"\\tNumber of cells: {n_cells}\")\n",
    "    print(\"\\tAvailable point data fields:\")\n",
    "    for i in range(point_data.GetNumberOfArrays()):\n",
    "        # Field names in point data\n",
    "        name = point_data.GetArrayName(i)\n",
    "        print(f\"\\t  - {name}\")\n",
    "    start = end\n",
    "\n",
    "    # Convert data to numpy array\n",
    "    # Get coordinates (points)\n",
    "    # Get field \"T\"\n",
    "    vtk_points = grid.GetPoints().GetData()\n",
    "    points_np = vtk_to_numpy(vtk_points)  # Shape: (n_points, 3)\n",
    "    points_2d = points_np[:, :2]  # Use only the first two columns for 2D coordinates\n",
    "\n",
    "    # Initialize dictionary for interpolators\n",
    "    interpolators = {}\n",
    "\n",
    "    # Loop over all arrays in point data\n",
    "    num_arrays = point_data.GetNumberOfArrays()\n",
    "    for i in range(num_arrays):\n",
    "        array_name = point_data.GetArrayName(i)\n",
    "        vtk_array = point_data.GetArray(i)\n",
    "        \n",
    "        if vtk_array is None:\n",
    "            print(f\"Warning: Array {array_name} is None, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Convert VTK array to NumPy\n",
    "        np_array = vtk_to_numpy(vtk_array)\n",
    "        \n",
    "        # Create interpolator and add to dict\n",
    "        interpolators[array_name] = LinearNDInterpolator(points_2d, np_array, fill_value=np.nan)\n",
    "\n",
    "    # Calculate resolution for each cell or point in the grid\n",
    "    resolution_np = calculate_resolution(grid)  # Custom function (not defined here)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Calculating resolution takes %.2e s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Create interpolators for temperature, pressure, and resolution\n",
    "    interpolators[\"resolution\"] = LinearNDInterpolator(points_2d, resolution_np)  # Interpolator for resolution\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Construct linear ND interpolator takes %.2e s\" % (end - start))\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_slab:\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    # Define the interval for the grid (in meters)\n",
    "    interval = 10e3\n",
    "\n",
    "    # Determine the bounding box of the 2D points\n",
    "    x_min, y_min = np.min(points_2d, axis=0)\n",
    "    x_max, y_max = np.max(points_2d, axis=0)\n",
    "\n",
    "    # Define a regular grid within the bounding box\n",
    "    # allow a little different in interval in x\n",
    "    # and y axis, thereform making the two dimensions\n",
    "    # unequal to make fewer mistakes ...\n",
    "    xs = np.arange(x_min, x_max, interval*0.99)\n",
    "    ys = np.arange(y_min, y_max, interval*1.01)\n",
    "    x_grid, y_grid = np.meshgrid(xs, ys, indexing=\"ij\")  # Create a grid of (x, y) points\n",
    "\n",
    "    # Flatten the grid for interpolation\n",
    "    grid_points_2d = np.vstack([x_grid.ravel(), y_grid.ravel()]).T\n",
    "\n",
    "    # Interpolate temperature (T) values onto the regular grid\n",
    "    T_grid = interpolators[\"T\"](grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    T_grid = T_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate temperature (P) values onto the regular grid\n",
    "    P_grid = interpolators[\"p\"](grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    P_grid = P_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate resolutions onto the regular grid\n",
    "    resolutions_grid = interpolators[\"resolution\"](grid_points_2d)\n",
    "    resolutions_grid = resolutions_grid.reshape(x_grid.shape)\n",
    "\n",
    "    # Interpolate density onto the regular grid\n",
    "    density_grid = interpolators[\"density\"](grid_points_2d)\n",
    "    density_grid = density_grid.reshape(x_grid.shape)\n",
    "\n",
    "    # Interpolate viscosity onto the regular grid\n",
    "    viscosity_grid = interpolators[\"viscosity\"](grid_points_2d)\n",
    "    viscosity_grid = viscosity_grid.reshape(x_grid.shape)\n",
    "\n",
    "    # Interpolate the grain size grid\n",
    "    grain_density_grid = interpolators[\"meta_x0\"](grid_points_2d)\n",
    "    grain_density_grid = grain_density_grid.reshape(x_grid.shape)\n",
    "\n",
    "    grain_size_grid = interpolators[\"meta_grain_size\"](grid_points_2d)\n",
    "    grain_size_grid = grain_size_grid.reshape(x_grid.shape)\n",
    "\n",
    "\n",
    "    # Interpolate latent heat onto the regular grid\n",
    "    # lheat_grid = interpolators[\"latent_heat\"](grid_points_2d)\n",
    "    # lheat_grid = lheat_grid.reshape(x_grid.shape)\n",
    "\n",
    "    # Interpolate metastable compositions onto the regular grid\n",
    "    metastable_grid = interpolators[\"metastable\"](grid_points_2d)\n",
    "    metastable_grid = metastable_grid.reshape(x_grid.shape)\n",
    "        \n",
    "    metarate_grid = interpolators[\"meta_rate\"](grid_points_2d)\n",
    "    metarate_grid = metarate_grid.reshape(x_grid.shape)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Interpolating to regular grid takes %.2e s\" % (end - start))\n",
    "    print(\"\\tgrid shape: (x axis, y axis): \", x_grid.shape)\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_slab:\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    from matplotlib import gridspec\n",
    "    from cmcrameri import cm as ccm\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (0.0, x_max/1e3) # km\n",
    "    x_tick_interval = 500   # tick interval along x\n",
    "    y_lim = (0.0, y_max/1e3) # km\n",
    "    y_tick_interval = 500  # tick interval along y\n",
    "\n",
    "    resolution_lim = (0.0, 100e3) # resolution\n",
    "    resolution_level = 50  # number of levels in contourf plot\n",
    "    resolution_tick_interval = 25e3  # tick interval along v\n",
    "\n",
    "    T_lim = (0.0, 2000.0) # T\n",
    "    T_level = 50  # number of levels in contourf plot\n",
    "    T_tick_interval = 250.0  # tick interval along v\n",
    "\n",
    "    P_lim = (np.min(P_grid), np.max(P_grid)) # P\n",
    "    P_level = 50  # number of levels in contourf plot\n",
    "    P_tick_interval = 1e9  # tick interval along P\n",
    "    \n",
    "    density_lim = (3000.0, 4000.0)\n",
    "    density_level = 50  # number of levels in contourf plot\n",
    "    density_tick_interval = 100.0  # tick interval along P\n",
    "\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # Create a figure with a 2x2 grid layout\n",
    "    fig = plt.figure(figsize=(12, 25), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(5, 2)\n",
    "\n",
    "    # Plot the mesh resolution\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    levels = np.linspace(resolution_lim[0], resolution_lim[1], resolution_level)\n",
    "    ticks=np.arange(resolution_lim[0], resolution_lim[1], resolution_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, resolutions_grid,  vmin=resolution_lim[0], vmax=resolution_lim[1], levels=levels, cmap=\"plasma_r\")  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"Resolution\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # Plot T\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    levels = np.linspace(T_lim[0], T_lim[1], T_level)\n",
    "    ticks=np.arange(T_lim[0], T_lim[1], T_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, T_grid,  vmin=T_lim[0], vmax=T_lim[1], levels=levels, cmap=ccm.lapaz)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"T\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # Plot P\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "    levels = np.linspace(P_lim[0], P_lim[1], P_level)\n",
    "    ticks=np.arange(P_lim[0], P_lim[1], P_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, P_grid,  vmin=P_lim[0], vmax=P_lim[1], levels=levels, cmap=ccm.tokyo_r)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"P\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Plot density\n",
    "    ax = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "    levels = np.linspace(density_lim[0], density_lim[1], density_level)\n",
    "    ticks=np.arange(density_lim[0], density_lim[1], density_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, density_grid,  vmin=density_lim[0], vmax=density_lim[1], levels=levels, cmap=ccm.batlow)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"density\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    \n",
    "    # Plot metastable grid\n",
    "    ax = fig.add_subplot(gs[2, 0])\n",
    "\n",
    "    levels = np.linspace(0.0, 1.0, 50)\n",
    "    ticks=np.arange(0.0, 1.01, 0.1) \n",
    "    \n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, metastable_grid, levels=levels)\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"metastable\", cmap=\"viridis\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "    \n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    \n",
    "    # Plot meta rate\n",
    "    ax = fig.add_subplot(gs[2, 1])\n",
    "\n",
    "    metarate_lim = (0, 1e-11)\n",
    "    # levels = np.linspace(metarate_lim[0], metarate_lim[1], 50)\n",
    "    # metarate_tick_interval = 2.5e-12\n",
    "    # ticks=np.arange(metarate_lim[0], metarate_lim[1], metarate_tick_interval)\n",
    "    # levels = np.linspace(0.0, np.max(metarate_grid), 50)\n",
    "    # ticks = np.linspace(0.0, np.max(metarate_grid), 10)\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, metarate_grid, cmap=ccm.buda) #, cmap=ccm.buda, vmin=0.0, vmax=1.0) #, level=levels) \n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"meta rate\")  # Add colorbar\n",
    "    # cbar.set_ticks(ticks)\n",
    "    \n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # plot grain size\n",
    "    # First plot the initial grain size\n",
    "    # Then the grain size after growth\n",
    "    from hamageolib.core.GrainSize import GrainGrowthModel, GrainGrowthParams\n",
    "    year = 365 * 24 * 3600.0\n",
    "\n",
    "    initial_grain_size_grid = (6.0 * metastable_grid / grain_density_grid / np.pi)**(1.0/3.0)\n",
    "    grain_size_log_range = [-8.0, -1.0]\n",
    "    ax = fig.add_subplot(gs[3, 0])\n",
    "    levels = np.linspace(grain_size_log_range[0], grain_size_log_range[1], 50)\n",
    "    ticks=np.arange(grain_size_log_range[0], grain_size_log_range[1]+0.1, 1.0)\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, np.log10(initial_grain_size_grid), cmap=\"viridis\", levels=levels, extend=\"both\") \n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"log10(initial grain_size)\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(gs[3, 1])\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, np.log10(grain_size_grid), cmap=\"viridis\", levels=levels, extend=\"both\")\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"log10(grain_size)\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Parameters for Wd grain growth\n",
    "    params = GrainGrowthParams(\n",
    "        grain_growth_rate_constant=3.02e-4,\n",
    "        m=3,\n",
    "        grain_growth_activation_energy=6.62e5,\n",
    "        grain_growth_activation_volume=0.0,\n",
    "    )\n",
    "\n",
    "    gModel = GrainGrowthModel(params=params)\n",
    "\n",
    "    time_scale = 1e6 * year\n",
    "    synthetic_grain_size_grid = np.full(initial_grain_size_grid.shape, np.nan)\n",
    "    mask = (initial_grain_size_grid > 0)\n",
    "    synthetic_grain_size_grid[mask] = gModel.grain_size_at_time(initial_grain_size_grid[mask], time_scale, P_grid[mask], T_grid[mask])\n",
    "\n",
    "    ax = fig.add_subplot(gs[4, 0])\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, np.log10(synthetic_grain_size_grid), cmap=\"viridis\", levels=levels, extend=\"both\")\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"log10(grain_size)\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # plot viscosity\n",
    "    ax = fig.add_subplot(gs[4, 1])\n",
    "\n",
    "    levels = np.linspace(18.0, 24.0, 50)\n",
    "    ticks=np.arange(18.0, 24.0+0.1, 1.0)\n",
    "    color_map = ax.contourf(x_grid/1e3, y_grid/1e3, np.log10(viscosity_grid), cmap=ccm.tokyo_r, levels=levels, extend=\"both\")\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"log10(viscosity)\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # save figure\n",
    "    ofile_base = os.path.join(case_dir, \"metastable_slab_%05d_raw\" % (vtu_step))\n",
    "    ofile = ofile_base + \".png\"\n",
    "    fig.savefig(os.path.join(ofile))\n",
    "    print(\"Saved figure %s\" % ofile)\n",
    "    ofile = ofile_base + \".pdf\"\n",
    "    fig.savefig(os.path.join(ofile))\n",
    "    print(\"Saved figure %s\" % ofile)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOW refinement test (TwoDSubduction_metastable_slab)\n",
    "\n",
    "This test makes use of\n",
    "\n",
    "    TwoDSubduction_metastable_slab.prm\n",
    "\n",
    "In this test, we create a synthetic slab using **ASPECT** + **WorldBuilder** and run the kinetics for the first time step to determine the mesh resolution.\n",
    "The specific strategy tested is to use the `sp_lower` or `sp_harz` field as a refinement indicator and to enforce the highest refinement level within a prescribed depth range in the MTZ.\n",
    "The outputs include the composition fields and the resulting meshes.\n",
    "\n",
    "### Set up\n",
    "\n",
    "Options:\n",
    "- None\n",
    "\n",
    "Process: Note that for this test, we don't visualize it in the notebook, instead, to check the mesh, copy file to local computer and open with Paraview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_run_aspect_tests_refinement = False\n",
    "is_run_aspect_tests_refinement_solving = True\n",
    "\n",
    "if is_run_aspect_tests_refinement:\n",
    "\n",
    "    from shutil import copy\n",
    "\n",
    "    no_iteration = False\n",
    "    adaptive_refinement = 4\n",
    "\n",
    "    aspect_dir = \"/home/lochy/Softwares/aspect\"\n",
    "    aspect_executable = os.path.join(aspect_dir, \"build_master_TwoD_rebase/aspect\")\n",
    "    prm_template_path = os.path.join(aspect_dir, \"tests\", \"TwoDSubduction_metastable_slab.prm\")\n",
    "    wb_template_path = os.path.join(aspect_dir, \"tests\", \"TwoDSubduction_metastable_slab.wb\")\n",
    "    case_dir = os.path.join(\"/mnt/lochy/ASPECT_DATA/MOW/mow_tests2\", \"TwoDSubduction_refinement\")  # New directory to run the case\n",
    "\n",
    "    assert(os.path.isfile(aspect_executable))\n",
    "    assert(os.path.isfile(prm_template_path))\n",
    "    assert(os.path.isfile(wb_template_path))\n",
    "\n",
    "    # assign another directory to run the case\n",
    "    case_root_dir = os.path.join(root_path, \"dtemp\") \n",
    "\n",
    "    if not os.path.isdir(case_dir):\n",
    "        os.mkdir(case_dir)\n",
    "\n",
    "    copy(wb_template_path, case_dir)\n",
    "\n",
    "    if no_iteration:\n",
    "        output_dirname = \"output_ni_ar%02d\" % adaptive_refinement # output directory\n",
    "    else:\n",
    "        output_dirname = \"output_ar%02d\" % adaptive_refinement  # output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_refinement:\n",
    "\n",
    "    from hamageolib.utils.dealii_param_parser import parse_parameters_to_dict, save_parameters_from_dict\n",
    "    from hamageolib.utils.world_builder_file_parser import find_feature_by_name, update_or_add_feature\n",
    "\n",
    "\n",
    "    # Modify the template\n",
    "    # Also read important parameters like the size of the model\n",
    "\n",
    "    with open(prm_template_path, 'r') as file:\n",
    "        params_dict = parse_parameters_to_dict(file)\n",
    "\n",
    "    params_dict[\"Output directory\"] = os.path.join(case_dir, output_dirname)\n",
    "\n",
    "    params_dict[\"Additional shared libraries\"] = \"$ASPECT_SOURCE_DIR/build_master_TwoD_rebase/prescribe_field/libprescribed_temperature.so, $ASPECT_SOURCE_DIR/build_master_TwoD_rebase/visco_plastic_TwoD/libvisco_plastic_TwoD.so, $ASPECT_SOURCE_DIR/build_master_TwoD_rebase/isosurfaces_TwoD1/libisosurfaces_TwoD1.so\"\n",
    "\n",
    "    if no_iteration:\n",
    "        params_dict[\"Nonlinear solver scheme\"] = \"no Advection, no Stokes\"\n",
    "\n",
    "    params_dict[\"Mesh refinement\"][\"Initial adaptive refinement\"] = str(adaptive_refinement)\n",
    "\n",
    "    params_dict[\"Postprocess\"][\"Visualization\"][\"Output format\"] = \"vtu\"\n",
    "\n",
    "    # todo_refine\n",
    "    # edit the specific options to refinement in MOW region\n",
    "    params_dict[\"Mesh refinement\"][\"Strategy\"] = \"isosurfaces, minimum refinement function, viscosity\"\n",
    "    params_dict[\"Mesh refinement\"][\"Isosurfaces\"] = params_dict[\"Mesh refinement\"].pop(\"IsosurfacesTwoD1\")\n",
    "    params_dict[\"Mesh refinement\"][\"Isosurfaces\"][\"Adjust metastable flag\"] = \"true\"\n",
    "\n",
    "    # Write to a prm file in the new case directory\n",
    "    prm_path = os.path.join(case_dir, \"case.prm\")\n",
    "\n",
    "    with open(prm_path, 'w') as output_file:\n",
    "        save_parameters_from_dict(output_file, params_dict)\n",
    "\n",
    "    assert(os.path.isfile(prm_path))\n",
    "\n",
    "    print(\"Created case in %s\" % (case_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run\n",
    "\n",
    "Use \"subprocess.run\" to run the case.\n",
    "\n",
    "Capture the standard output and error streams\n",
    "\n",
    "Check\n",
    "  * if the expected line indicating wallclock time appears in the output.\n",
    "  * There is no stderr output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_refinement and is_run_aspect_tests_refinement_solving:\n",
    "\n",
    "    # Run theb ASPECT executable with the parameter file\n",
    "    # The function ensures that both the expected outputs are generated and no errors are produced\n",
    "    # 'capture_output=True' collects both stdout and stderr for further checks\n",
    "    completed_process = subprocess.run([aspect_executable, prm_path], capture_output=True, text=True)\n",
    "\n",
    "    # Capture the standard output and error streams\n",
    "    stdout = completed_process.stdout\n",
    "    stderr = completed_process.stderr\n",
    "\n",
    "    # Uncomment the following lines for debugging purposes to inspect the output\n",
    "    # print(stdout)  # Debugging: Prints the standard output\n",
    "    # print(stderr)  # Debugging: Prints the standard error\n",
    "\n",
    "    # Check if the expected line indicating wallclock time appears in the output\n",
    "    # The expected line format is something like:\n",
    "    # -- Total wallclock time elapsed including restarts: 1s\n",
    "    assert(re.match(\".*Total wallclock\", stdout.split('\\n')[-6]))\n",
    "\n",
    "    # Ensure that the error stream is empty, indicating no issues during the run\n",
    "    assert(stderr == \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if is_run_aspect_tests_slab and is_run_aspect_tests_slab_solving:\n",
    "#     print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the stdout output to a separate file\n",
    "if is_run_aspect_tests_slab and is_run_aspect_tests_slab_solving:\n",
    "\n",
    "    std_file = os.path.join(case_dir, \"stdout.txt\")\n",
    "\n",
    "    with open(std_file, \"w\") as fout:\n",
    "        fout.write(stdout)\n",
    "\n",
    "    print(\"Saved stdout outputs: %s\" % std_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advection test\n",
    "\n",
    "List of options:\n",
    "\n",
    "- test_backward_advection:\n",
    "  advection is backward: bottom-up. This serves to check that the metastable\n",
    "  value is reset below equilibrium "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_run_aspect_tests_advection = False\n",
    "is_run_aspect_tests_advection_solving = True\n",
    "\n",
    "if is_run_aspect_tests_advection:\n",
    "\n",
    "    with_metastable = True\n",
    "    reaction_metastable_trivial = False\n",
    "    with_latent_heat = True\n",
    "    test_backward_advection = True\n",
    "\n",
    "    adiabatic_surface_temperature = 1073.15 # K\n",
    "    advection_rate = 0.10 # m/r\n",
    "\n",
    "    end_time = 1e4  # yr\n",
    "    maximum_time_step = 1e3 # yr\n",
    "\n",
    "    x_extent = 2e3\n",
    "    y_extent = 1000e3\n",
    "    n_repetition = 4  # original - no repetition (x); documentation - 4\n",
    "\n",
    "    aspect_dir = \"/home/lochy/Softwares/aspect\"\n",
    "    aspect_executable = os.path.join(aspect_dir, \"build_master_TwoD_rebase/aspect\")\n",
    "    if test_backward_advection:\n",
    "        prm_template_path = os.path.join(aspect_dir, \"tests\", \"TwoDSubduction_metastable_backward_advection.prm\")\n",
    "    else:\n",
    "        prm_template_path = os.path.join(aspect_dir, \"tests\", \"TwoDSubduction_metastable_advection.prm\")\n",
    "\n",
    "    assert(os.path.isfile(aspect_executable))\n",
    "    assert(os.path.isfile(prm_template_path))\n",
    "\n",
    "    # assign another directory to run the case\n",
    "    case_root_dir = os.path.join(\"/mnt/lochz/ASPECT_DATA/TwoDSubduction/test_cases\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_advection:\n",
    "\n",
    "    from hamageolib.utils.dealii_param_parser import parse_parameters_to_dict, save_parameters_from_dict\n",
    "    from hamageolib.utils.world_builder_file_parser import find_feature_by_name, update_or_add_feature\n",
    "\n",
    "    if test_backward_advection:\n",
    "        case_dir = os.path.join(\"/mnt/lochz/ASPECT_DATA/TwoDSubduction/test_cases\", \"TwoDSubduction_metastable_backward_advection\")  # New directory to run the case\n",
    "    else:\n",
    "        case_dir = os.path.join(\"/mnt/lochz/ASPECT_DATA/TwoDSubduction/test_cases\", \"TwoDSubduction_metastable_advection\")  # New directory to run the case\n",
    "    if not os.path.isdir(case_dir):\n",
    "        os.mkdir(case_dir)\n",
    "\n",
    "    # Modify the template\n",
    "    # Also read important parameters like the size of the model\n",
    "\n",
    "    with open(prm_template_path, 'r') as file:\n",
    "        params_dict = parse_parameters_to_dict(file)\n",
    "\n",
    "    if with_metastable:\n",
    "        if reaction_metastable_trivial:\n",
    "            output_dirname = \"output_reaction_trivial_nrep_%d\" % n_repetition  # output directory\n",
    "        else:\n",
    "            output_dirname = \"output_nrep_%d\" % n_repetition  # output directory\n",
    "    else:\n",
    "        output_dirname = \"output_trivial_nrep_%d\" % n_repetition  # output directory\n",
    "\n",
    "    output_dirname += \"_end_%.2e_maxstep_%.2e_lt_%d\" % (end_time, maximum_time_step, with_latent_heat)\n",
    "\n",
    "    params_dict[\"Output directory\"] = os.path.join(case_dir, output_dirname)\n",
    "    params_dict[\"End time\"] = \"%.2e\" % end_time\n",
    "    params_dict[\"Maximum time step\"] = \"%.2e\" % maximum_time_step\n",
    "\n",
    "    params_dict[\"Additional shared libraries\"] = \"$ASPECT_SOURCE_DIR/build_master_TwoD_rebase/subduction_temperature2d/libsubduction_temperature2d.so, $ASPECT_SOURCE_DIR/build_master_TwoD_rebase/prescribe_field/libprescribed_temperature.so, $ASPECT_SOURCE_DIR/build_master_TwoD_rebase/visco_plastic_TwoD/libvisco_plastic_TwoD.so\"\n",
    "\n",
    "    params_dict[\"Adiabatic surface temperature\"] = str(adiabatic_surface_temperature)\n",
    "\n",
    "    params_dict[\"Geometry model\"][\"Box\"][\"X extent\"] = str(x_extent)\n",
    "    params_dict[\"Geometry model\"][\"Box\"][\"Y extent\"] = str(y_extent)\n",
    "    params_dict[\"Geometry model\"][\"Box\"][\"X repetitions\"] = str(n_repetition)\n",
    "    params_dict[\"Geometry model\"][\"Box\"][\"Y repetitions\"] = str(int(np.ceil(n_repetition*y_extent/x_extent)))\n",
    "\n",
    "    if test_backward_advection:\n",
    "        params_dict[\"Prescribed Stokes solution\"][\"Velocity function\"][\"Function expression\"] = \"0; %.2e\" % (advection_rate)\n",
    "    else:\n",
    "        params_dict[\"Prescribed Stokes solution\"][\"Velocity function\"][\"Function expression\"] = \"0; %.2e\" % (-advection_rate)\n",
    "\n",
    "    if not with_metastable:\n",
    "        params_dict.pop(\"Compositional fields\")\n",
    "\n",
    "        params_dict[\"Initial temperature model\"].pop(\"Adiabatic\")\n",
    "\n",
    "        params_dict.pop(\"Initial composition model\")\n",
    "        \n",
    "        params_dict[\"Material model\"][\"Visco Plastic TwoD\"][\"Reaction metastable\"] = \"false\"\n",
    "        params_dict[\"Material model\"][\"Visco Plastic TwoD\"][\"Densities\"] = \"background: 3300.0|3394.4|3442.1|3453.2|3617.6|3691.5|3774.7|3929.1\"\n",
    "\n",
    "        params_dict[\"Material model\"][\"Visco Plastic TwoD\"].pop(\"Metastable transition\")\n",
    "\n",
    "        params_dict.pop(\"Particles\")\n",
    "\n",
    "        params_dict[\"Postprocess\"].pop(\"Particles\")\n",
    "        \n",
    "    if reaction_metastable_trivial:\n",
    "        params_dict[\"Material model\"][\"Visco Plastic TwoD\"][\"Reaction metastable trivial\"] = \"true\"\n",
    "\n",
    "    if with_latent_heat:\n",
    "        params_dict[\"Heating model\"][\"List of model names\"] = \"adiabatic heating, latent heat\"\n",
    "    else:\n",
    "        params_dict[\"Heating model\"][\"List of model names\"] = \"adiabatic heating\"\n",
    "\n",
    "    params_dict[\"Postprocess\"][\"Visualization\"][\"Output format\"] = \"vtu\"\n",
    "    params_dict[\"Postprocess\"][\"Visualization\"][\"Time between graphical output\"] = \"%.1e\" % maximum_time_step\n",
    "    if with_metastable:\n",
    "        params_dict[\"Postprocess\"][\"Particles\"][\"Data output format\"] = \"vtu\"\n",
    "        params_dict[\"Postprocess\"][\"Particles\"][\"Time between data output\"] = \"%.1e\" % maximum_time_step\n",
    "\n",
    "    # Write to a prm file in the new case directory\n",
    "    prm_path = os.path.join(case_dir, \"case.prm\")\n",
    "\n",
    "    with open(prm_path, 'w') as output_file:\n",
    "        save_parameters_from_dict(output_file, params_dict)\n",
    "\n",
    "    assert(os.path.isfile(prm_path))\n",
    "\n",
    "    print(\"Created case in %s\" % (case_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run\n",
    "\n",
    "Use \"subprocess.run\" to run the case.\n",
    "\n",
    "Capture the standard output and error streams\n",
    "\n",
    "Check\n",
    "  * if the expected line indicating wallclock time appears in the output.\n",
    "  * There is no stderr output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_advection and is_run_aspect_tests_advection_solving:\n",
    "\n",
    "    # Run theb ASPECT executable with the parameter file\n",
    "    # The function ensures that both the expected outputs are generated and no errors are produced\n",
    "    # 'capture_output=True' collects both stdout and stderr for further checks\n",
    "    completed_process = subprocess.run([aspect_executable, prm_path], capture_output=True, text=True)\n",
    "\n",
    "    # Capture the standard output and error streams\n",
    "    stdout = completed_process.stdout\n",
    "    stderr = completed_process.stderr\n",
    "\n",
    "    # Uncomment the following lines for debugging purposes to inspect the output\n",
    "    # print(stdout)  # Debugging: Prints the standard output\n",
    "    # print(stderr)  # Debugging: Prints the standard error\n",
    "\n",
    "    # Check if the expected line indicating wallclock time appears in the output\n",
    "    # The expected line format is something like:\n",
    "    # -- Total wallclock time elapsed including restarts: 1s\n",
    "    assert(re.match(\".*Total wallclock\", stdout.split('\\n')[-6]))\n",
    "\n",
    "    # Ensure that the error stream is empty, indicating no issues during the run\n",
    "    assert(stderr == \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the stdout to separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_advection and is_run_aspect_tests_advection_solving:\n",
    "\n",
    "    std_file = os.path.join(case_dir, \"stdout.txt\")\n",
    "\n",
    "    with open(std_file, \"w\") as fout:\n",
    "        fout.write(stdout)\n",
    "\n",
    "    print(\"Saved stdout outputs: %s\" % std_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_advection:\n",
    "\n",
    "    vtu_step = 0\n",
    "\n",
    "    import vtk\n",
    "    from vtk.util.numpy_support import vtk_to_numpy\n",
    "    from hamageolib.utils.vtk_utilities import calculate_resolution\n",
    "    import time\n",
    "    from scipy.interpolate import LinearNDInterpolator\n",
    "\n",
    "    pvtu_file = os.path.join(case_dir, output_dirname, \"solution\", \"solution-%05d.pvtu\" % vtu_step)\n",
    "    assert(os.path.isfile(pvtu_file))\n",
    "\n",
    "    # Read the pvtu file\n",
    "    start = time.time()\n",
    "\n",
    "    reader = vtk.vtkXMLPUnstructuredGridReader()\n",
    "    reader.SetFileName(pvtu_file)\n",
    "    reader.Update()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Initiating reader takes %.2e s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Get the output data from the reader\n",
    "    grid = reader.GetOutput()  # Access the unstructured grid\n",
    "    data_set = reader.GetOutputAsDataSet()  # Access the dataset representation\n",
    "    points = grid.GetPoints()  # Extract the points (coordinates)\n",
    "    cells = grid.GetCells()  # Extract the cell connectivity information\n",
    "    point_data = data_set.GetPointData()  # Access point-wise data\n",
    "\n",
    "    n_points = grid.GetNumberOfPoints() # Number of points and cells\n",
    "    n_cells = grid.GetNumberOfCells()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Reading files takes %.2e s\" % (end - start))\n",
    "    print(f\"\\tNumber of points: {n_points}\")\n",
    "    print(f\"\\tNumber of cells: {n_cells}\")\n",
    "    print(\"\\tAvailable point data fields:\")\n",
    "    for i in range(point_data.GetNumberOfArrays()):\n",
    "        # Field names in point data\n",
    "        name = point_data.GetArrayName(i)\n",
    "        print(f\"\\t  - {name}\")\n",
    "    start = end\n",
    "\n",
    "    # Convert data to numpy array\n",
    "    # Get coordinates (points)\n",
    "    # Get field \"T\"\n",
    "    vtk_points = grid.GetPoints().GetData()\n",
    "    points_np = vtk_to_numpy(vtk_points)  # Shape: (n_points, 3)\n",
    "    points_2d = points_np[:, :2]  # Use only the first two columns for 2D coordinates\n",
    "\n",
    "    vtk_T = point_data.GetArray(\"T\")\n",
    "    vtk_p = point_data.GetArray(\"p\")\n",
    "    metastable = point_data.GetArray(\"metastable\")\n",
    "    metarate = point_data.GetArray(\"meta_rate\")\n",
    "    vtk_velocity = point_data.GetArray(\"velocity\")\n",
    "    vtk_density = point_data.GetArray(\"density\")\n",
    "    vtk_aheat = point_data.GetArray(\"adiabatic_heating\")\n",
    "    vtk_lheat = point_data.GetArray(\"latent_heat\")\n",
    "    assert(vtk_T is not None and vtk_p is not None)\n",
    "    T_np = vtk_to_numpy(vtk_T)  # Shape: (n_points,)\n",
    "    p_np = vtk_to_numpy(vtk_p)  # Shape: (n_points,)\n",
    "    v_np = vtk_to_numpy(vtk_velocity)\n",
    "    aheat_np = vtk_to_numpy(vtk_aheat)\n",
    "    if with_latent_heat:\n",
    "        lheat_np = vtk_to_numpy(vtk_lheat)\n",
    "    density_np = vtk_to_numpy(vtk_density)\n",
    "\n",
    "    if with_metastable:\n",
    "        assert(metastable is not None)\n",
    "        metastable_np = vtk_to_numpy(metastable)\n",
    "        metarate_np = vtk_to_numpy(metarate)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Converting data takes %.2e s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Calculate resolution for each cell or point in the grid\n",
    "    resolution_np = calculate_resolution(grid)  # Custom function (not defined here)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Calculating resolution takes %.2e s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "\n",
    "    # Create interpolators for temperature, pressure, and resolution\n",
    "    interpolator = LinearNDInterpolator(points_2d, T_np)  # Interpolator for temperature\n",
    "    interpolator_P = LinearNDInterpolator(points_2d, p_np)  # Interpolator for pressure\n",
    "    interpolator_r = LinearNDInterpolator(points_2d, resolution_np)  # Interpolator for resolution\n",
    "    interpolator_v = LinearNDInterpolator(points_2d, v_np)  # Interpolator for velocity\n",
    "    interpolator_density = LinearNDInterpolator(points_2d, density_np)  # Interpolator for density\n",
    "    interpolator_aheat = LinearNDInterpolator(points_2d, aheat_np)\n",
    "    if with_latent_heat:\n",
    "        interpolator_lheat = LinearNDInterpolator(points_2d, lheat_np)\n",
    "    if with_metastable:\n",
    "        interpolator_meta = LinearNDInterpolator(points_2d, metastable_np)  # Interpolator for metastable\n",
    "        interpolator_metarate = LinearNDInterpolator(points_2d, metarate_np)  # Interpolator for metastable\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Construct linear ND interpolator takes %.2e s\" % (end - start))\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_advection:\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    # Define the interval for the grid (in meters)\n",
    "    n_x = 5\n",
    "    n_y = int(np.ceil(n_x*y_extent/x_extent))\n",
    "\n",
    "    # Determine the bounding box of the 2D points\n",
    "    x_min, y_min = 0.0, 0.0\n",
    "    x_max, y_max = x_extent, y_extent\n",
    "\n",
    "    # Define a regular grid within the bounding box\n",
    "    # allow a little different in interval in x\n",
    "    # and y axis, thereform making the two dimensions\n",
    "    # unequal to make fewer mistakes ...\n",
    "    xs = np.linspace(x_min, x_max, n_x)\n",
    "    ys = np.linspace(y_min, y_max, n_y)\n",
    "    x_grid, y_grid = np.meshgrid(xs, ys, indexing=\"ij\")  # Create a grid of (x, y) points\n",
    "\n",
    "    # Flatten the grid for interpolation\n",
    "    grid_points_2d = np.vstack([x_grid.ravel(), y_grid.ravel()]).T\n",
    "\n",
    "    # Interpolate temperature (T) values onto the regular grid\n",
    "    T_grid = interpolator(grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    T_grid = T_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate temperature (P) values onto the regular grid\n",
    "    P_grid = interpolator_P(grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    P_grid = P_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate resolutions onto the regular grid\n",
    "    resolutions_grid = interpolator_r(grid_points_2d)\n",
    "    resolutions_grid = resolutions_grid.reshape(x_grid.shape)\n",
    "\n",
    "    # Interpolate velocity (v) values onto the regular grid\n",
    "    v_interp_flat = interpolator_v(grid_points_2d)\n",
    "    vx_grid = v_interp_flat[:, 0].reshape(x_grid.shape)\n",
    "    vy_grid = v_interp_flat[:, 1].reshape(x_grid.shape)\n",
    "    # v_grid = interpolator_v((x_grid.shape[0], x_grid.shape[1], 3))\n",
    "    \n",
    "    # Interpolate density values onto the regular grid\n",
    "    density_grid = interpolator_density(grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    density_grid = density_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate adiabatic heating values onto the regular grid\n",
    "    aheat_grid = interpolator_aheat(grid_points_2d)\n",
    "    aheat_grid = aheat_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "    \n",
    "    # Interpolate adiabatic heating values onto the regular grid\n",
    "    if with_latent_heat:\n",
    "        lheat_grid = interpolator_lheat(grid_points_2d)\n",
    "        lheat_grid = lheat_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate metastable compositions onto the regular grid\n",
    "    if with_metastable:\n",
    "        metastable_grid = interpolator_meta(grid_points_2d)\n",
    "        metastable_grid = metastable_grid.reshape(x_grid.shape)\n",
    "        metarate_grid = interpolator_metarate(grid_points_2d)\n",
    "        metarate_grid = metarate_grid.reshape(x_grid.shape)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Interpolating to regular grid takes %.2e s\" % (end - start))\n",
    "    print(\"\\tgrid shape: (x axis, y axis): \", x_grid.shape)\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_run_aspect_tests_advection:\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    from matplotlib import gridspec\n",
    "    from cmcrameri import cm as ccm\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (x_min/1e3, x_max/1e3) # km\n",
    "    x_tick_interval = 0.5   # tick interval along x\n",
    "    y_lim = (y_min/1e3, y_max/1e3) # km\n",
    "    y_tick_interval = 100.0  # tick interval along y\n",
    "\n",
    "    resolution_lim = (0.0, 1e3) # resolution\n",
    "    resolution_level = 50  # number of levels in contourf plot\n",
    "    resolution_tick_interval = 0.25e3  # tick interval along v\n",
    "\n",
    "    T_lim = (0.0, 2000.0) # T\n",
    "    T_level = 50  # number of levels in contourf plot\n",
    "    T_tick_interval = 250.0  # tick interval along v\n",
    "\n",
    "    P_lim = (0.0, 40e9) # P\n",
    "    P_level = 50  # number of levels in contourf plot\n",
    "    P_tick_interval = 5e9  # tick interval along P\n",
    "\n",
    "    v_lim = (-0.15, 0.15)\n",
    "    v_level = 50\n",
    "    v_tick_interval = 0.05\n",
    "\n",
    "    density_lim = (3000.0, 4000.0)\n",
    "    density_level = 50\n",
    "    density_tick_interval = 100.0\n",
    "    \n",
    "    metastable_lim = (0.0, 1.0)\n",
    "    metastable_level = 50\n",
    "    metastable_tick_interval = 0.25\n",
    "    \n",
    "    metarate_lim = (0.0, 1.0)\n",
    "    metarate_level = 50\n",
    "    metarate_tick_interval = 0.25\n",
    "    \n",
    "    heating_lim = (-1e-4, 1e-4)\n",
    "    heating_level = 50\n",
    "    heating_tick_interval = 2.5e-5\n",
    "\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # Create a figure with a 2x2 grid layout\n",
    "    fig = plt.figure(figsize=(12, 25), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(5, 2)\n",
    "\n",
    "    # Plot the mesh resolution\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    levels = np.linspace(resolution_lim[0], resolution_lim[1], resolution_level)\n",
    "    ticks=np.arange(resolution_lim[0], resolution_lim[1], resolution_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, (y_extent-y_grid)/1e3, resolutions_grid,  vmin=resolution_lim[0], vmax=resolution_lim[1], levels=levels, cmap=\"plasma_r\")  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"Resolution\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X (km)\")\n",
    "    ax.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # Plot T\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    levels = np.linspace(T_lim[0], T_lim[1], T_level)\n",
    "    ticks=np.arange(T_lim[0], T_lim[1], T_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, (y_extent-y_grid)/1e3, T_grid,  vmin=T_lim[0], vmax=T_lim[1], levels=levels, cmap=ccm.lapaz)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"T\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    # ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X (km)\")\n",
    "    ax.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "\n",
    "    # Plot P\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "    levels = np.linspace(P_lim[0], P_lim[1], P_level)\n",
    "    ticks=np.arange(P_lim[0], P_lim[1], P_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, (y_extent-y_grid)/1e3, P_grid,  vmin=P_lim[0], vmax=P_lim[1], levels=levels, cmap=ccm.tokyo_r)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"P\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    # ax.set_aspect(\"equal\", adjustable=\"box\")  # Equal aspect ratio\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X (km)\")\n",
    "    ax.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Plot vx\n",
    "    ax = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "    levels = np.linspace(v_lim[0], v_lim[1], v_level)\n",
    "    ticks=np.arange(v_lim[0], v_lim[1], v_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, (y_extent-y_grid)/1e3, vx_grid,  vmin=v_lim[0], vmax=v_lim[1], levels=levels, cmap=ccm.hawaii)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"vx\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X (km)\")\n",
    "    ax.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Plot vy\n",
    "    ax = fig.add_subplot(gs[2, 0])\n",
    "\n",
    "    levels = np.linspace(v_lim[0], v_lim[1], v_level)\n",
    "    ticks=np.arange(v_lim[0], v_lim[1], v_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, (y_extent-y_grid)/1e3, vy_grid,  vmin=v_lim[0], vmax=v_lim[1], levels=levels, cmap=ccm.hawaii)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"vy\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X (km)\")\n",
    "    ax.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # plot density\n",
    "    ax = fig.add_subplot(gs[2, 1])\n",
    "\n",
    "    levels = np.linspace(density_lim[0], density_lim[1], density_level)\n",
    "    ticks=np.arange(density_lim[0], density_lim[1], density_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, (y_extent-y_grid)/1e3, density_grid,  vmin=density_lim[0], vmax=density_lim[1], levels=levels, cmap=ccm.batlow)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"density\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X (km)\")\n",
    "    ax.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # plot metastable\n",
    "    if with_metastable:\n",
    "        ax = fig.add_subplot(gs[3, 0])\n",
    "\n",
    "        levels = np.linspace(metastable_lim[0], metastable_lim[1], metastable_level)\n",
    "        ticks=np.arange(metastable_lim[0], metastable_lim[1], metastable_tick_interval)\n",
    "\n",
    "        color_map = ax.contourf(x_grid/1e3, (y_extent-y_grid)/1e3, metastable_grid,  vmin=metastable_lim[0], vmax=metastable_lim[1], levels=levels, cmap=\"viridis\")  # Metastable color map\n",
    "        cbar = fig.colorbar(color_map, ax=ax, label=\"metastable\")  # Add colorbar\n",
    "        cbar.set_ticks(ticks)\n",
    "\n",
    "        ax.set_xlim(x_lim)\n",
    "        ax.set_ylim(y_lim)\n",
    "\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "        ax.set_xlabel(\"X (km)\")\n",
    "        ax.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        for spine in ax.spines.values():\n",
    "            # Adjust spine thickness for this plot\n",
    "            spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    \n",
    "    # plot adiabatic heating\n",
    "    ax = fig.add_subplot(gs[3, 1])\n",
    "\n",
    "    levels = np.linspace(heating_lim[0], heating_lim[1], heating_level)\n",
    "    ticks=np.arange(heating_lim[0], heating_lim[1], heating_tick_interval)\n",
    "\n",
    "    color_map = ax.contourf(x_grid/1e3, (y_extent-y_grid)/1e3, aheat_grid, cmap=ccm.glasgow, vmin=heating_lim[0], vmax=heating_lim[1], levels=levels)  # Resolution colormap\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"adiabatic heating\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.set_xlabel(\"X (km)\")\n",
    "    ax.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # plot letent heating\n",
    "    if with_latent_heat:\n",
    "        ax = fig.add_subplot(gs[4, 0])\n",
    "\n",
    "        levels = np.linspace(heating_lim[0], heating_lim[1], heating_level)\n",
    "        ticks=np.arange(heating_lim[0], heating_lim[1], heating_tick_interval)\n",
    "        color_map = ax.contourf(x_grid/1e3, (y_extent-y_grid)/1e3, lheat_grid,\\\n",
    "                                cmap=ccm.glasgow, vmin=heating_lim[0], vmax=heating_lim[1], levels=levels)\n",
    "        \n",
    "        # levels = np.linspace(np.min(lheat_grid), np.max(lheat_grid), heating_level)\n",
    "        # ticks = np.linspace(np.min(lheat_grid), np.max(lheat_grid), 10)\n",
    "        # color_map = ax.contourf(x_grid/1e3, (y_extent-y_grid)/1e3, lheat_grid,\\\n",
    "        #                         cmap=ccm.glasgow, vmin=np.min(lheat_grid), vmax=np.max(lheat_grid), levels=levels,\\\n",
    "        #                             extend=\"both\")\n",
    "\n",
    "        cbar = fig.colorbar(color_map, ax=ax, label=\"latent heat\")  # Add colorbar\n",
    "        cbar.set_ticks(ticks)\n",
    "\n",
    "        ax.set_xlim(x_lim)\n",
    "        ax.set_ylim(y_lim)\n",
    "\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "        ax.set_xlabel(\"X (km)\")\n",
    "        ax.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        for spine in ax.spines.values():\n",
    "            # Adjust spine thickness for this plot\n",
    "            spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "        # plot metastable\n",
    "    if with_metastable:\n",
    "        ax = fig.add_subplot(gs[4, 1])\n",
    "\n",
    "        # levels = np.linspace(metarate_lim[0], metarate_lim[1], metarate_level)\n",
    "        # ticks=np.arange(metarate_lim[0], metarate_lim[1], metarate_tick_interval)\n",
    "        levels = np.linspace(0.0, np.max(metarate_grid), 50)\n",
    "        ticks = np.linspace(0.0, np.max(metarate_grid), 10)\n",
    "        color_map = ax.contourf(x_grid/1e3, (y_extent-y_grid)/1e3, metarate_grid, cmap=ccm.buda, vmin=0.0, vmax=np.max(metarate_grid), level=levels) \n",
    "        cbar = fig.colorbar(color_map, ax=ax, label=\"meta rate\")  # Add colorbar\n",
    "        cbar.set_ticks(ticks)\n",
    "\n",
    "        ax.set_xlim(x_lim)\n",
    "        ax.set_ylim(y_lim)\n",
    "\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(x_tick_interval))\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(x_tick_interval/(n_minor_ticks+1)))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(y_tick_interval))\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(y_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "        ax.set_xlabel(\"X (km)\")\n",
    "        ax.set_ylabel(\"Depth (km)\")\n",
    "\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        for spine in ax.spines.values():\n",
    "            # Adjust spine thickness for this plot\n",
    "            spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    if with_metastable:\n",
    "        if reaction_metastable_trivial:\n",
    "            ofile_name = os.path.join(case_dir, \"metastable_advection_trivial_adT_%.1f_adv_%.3f_end_%.2e_maxstep_%.2e_vstep_%d_lt_%d\" % (adiabatic_surface_temperature, advection_rate, end_time, maximum_time_step, vtu_step, with_latent_heat))\n",
    "        else:\n",
    "            ofile_name = os.path.join(case_dir, \"metastable_advection_adT_%.1f_adv_%.3f_end_%.2e_maxstep_%.2e_vstep_%d_lt_%d\" % (adiabatic_surface_temperature, advection_rate, end_time, maximum_time_step, vtu_step, with_latent_heat))\n",
    "    else:\n",
    "        ofile_name = os.path.join(case_dir, \"trivial_advection_adT_%.1f_adv_%.3f_end_%.2e_maxstep_%.2e_vstep_%d_lt_%d\" % (adiabatic_surface_temperature, advection_rate, end_time, maximum_time_step, vtu_step, with_latent_heat))\n",
    "\n",
    "    fig.savefig(ofile_name + \".png\")\n",
    "    print(\"Saved figure %s\" % (ofile_name + \".png\"))\n",
    "    fig.savefig(ofile_name + \".pdf\")\n",
    "    print(\"Saved figure %s\" % (ofile_name + \".pdf\"))\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASPECT Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viscosity profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo_visc\n",
    "test_viscosity_profile = False\n",
    "\n",
    "if test_viscosity_profile:\n",
    "\n",
    "    viscosity_jump_type = \"660\" # 660 or 1100\n",
    "\n",
    "    from hamageolib.research.haoyuan_2d_subduction.legacy_tools import RHEOLOGY_PRM, RHEOLOGY_OPR, RefitRheology\n",
    "\n",
    "    # constant variables\n",
    "    rheology_name = \"WarrenHansen23\"\n",
    "    mantle_coh = 300.0\n",
    "    strain_rate = 1e-15\n",
    "\n",
    "    if viscosity_jump_type == \"660\":\n",
    "        jump_lower_mantle = 60.0\n",
    "        Vdiff_lm = 3e-6\n",
    "        depth_lm_middle = -1.0\n",
    "    elif viscosity_jump_type == \"1100\":\n",
    "        jump_lower_mantle = 0.5\n",
    "        Vdiff_lm = 9e-6\n",
    "        depth_lm_middle = 1100e3\n",
    "    elif viscosity_jump_type == \"1100i\":\n",
    "        jump_lower_mantle = 5\n",
    "        Vdiff_lm = 6e-6\n",
    "        depth_lm_middle = 1100e3\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    rheology_prm_dict = RHEOLOGY_PRM()\n",
    "    Operator = RHEOLOGY_OPR()\n",
    "\n",
    "    # import a depth average profile\n",
    "    LEGACY_FILE_DIR = os.path.join(root_path, \"hamageolib/research/haoyuan_2d_subduction/legacy_files\")\n",
    "    da_file = os.path.join(LEGACY_FILE_DIR, 'reference_ThD', \"depth_average_1573.txt\")\n",
    "    Operator.ReadProfile(da_file)\n",
    "    depths, pressures, temperatures = Operator.depths, Operator.pressures, Operator.temperatures\n",
    "\n",
    "    T660, P660 = np.interp(660e3, depths, temperatures), np.interp(660e3, depths, pressures)\n",
    "    T1500, P1500 = np.interp(1500e3, depths, temperatures), np.interp(1500e3, depths, pressures)\n",
    "\n",
    "    # initial rheologic parameters\n",
    "    diffusion_creep_ori = getattr(rheology_prm_dict, rheology_name + \"_diff\")\n",
    "    dislocation_creep_ori = getattr(rheology_prm_dict, rheology_name + \"_disl\")\n",
    "    rheology_dict = {'diffusion': diffusion_creep_ori, 'dislocation': dislocation_creep_ori}\n",
    "    # prescribe the correction\n",
    "    diff_correction = {'A': 1.0, 'p': 0.0, 'r': 0.0, 'n': 0.0, 'E': 0.0, 'V': -2.1e-6}\n",
    "    disl_correction = {'A': 1.0, 'p': 0.0, 'r': 0.0, 'n': 0.0, 'E': 0.0, 'V': 3e-6}\n",
    "    # prescribe the reference state\n",
    "    ref_state = {}\n",
    "    ref_state[\"Coh\"] = mantle_coh # H / 10^6 Si\n",
    "    ref_state[\"stress\"] = 50.0 # MPa\n",
    "    ref_state[\"P\"] = 100.0e6 # Pa\n",
    "    ref_state[\"T\"] = 1250.0 + 273.15 # K\n",
    "    ref_state[\"d\"] = 15.0 # mu m\n",
    "    # refit rheology\n",
    "    rheology_dict_refit = RefitRheology(rheology_dict, diff_correction, disl_correction, ref_state)\n",
    "    # derive mantle rheology\n",
    "    rheology, viscosity_profile = Operator.MantleRheology(assign_rheology=True, diffusion_creep=rheology_dict_refit['diffusion'],\\\n",
    "                                                dislocation_creep=rheology_dict_refit['dislocation'], save_profile=0,\\\n",
    "                                                use_effective_strain_rate=True, save_json=1, Coh=mantle_coh,\\\n",
    "                                                jump_lower_mantle=jump_lower_mantle, Vdiff_lm=Vdiff_lm, depth_lm_middle=depth_lm_middle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_viscosity_profile:\n",
    "\n",
    "    from hamageolib.research.haoyuan_2d_subduction.legacy_tools import CreepRheologyInAspectViscoPlastic\n",
    "\n",
    "    diff_um = rheology[\"diffusion_creep\"]\n",
    "    disl_um = rheology[\"dislocation_creep\"]\n",
    "\n",
    "    visc_660_diff_um = CreepRheologyInAspectViscoPlastic(diff_um, strain_rate, P660, T660)\n",
    "    visc_660_disl_um = CreepRheologyInAspectViscoPlastic(disl_um, strain_rate, P660, T660)\n",
    "    visc_660_um = 1.0 / (1.0/visc_660_diff_um + 1.0/visc_660_disl_um)\n",
    "\n",
    "    diff_lm = rheology[\"diffusion_lm\"]\n",
    "\n",
    "    visc_660_lm = CreepRheologyInAspectViscoPlastic(diff_lm, strain_rate, P660, T660)\n",
    "\n",
    "\n",
    "    print(\"visc_660_diff_um: \", visc_660_diff_um)\n",
    "    print(\"visc_660_disl_um: \", visc_660_disl_um)\n",
    "    print(\"visc_660_um: \", visc_660_um)\n",
    "\n",
    "    print(\"visc_660_lm: \", visc_660_lm)\n",
    "\n",
    "    print(rheology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_viscosity_profile:\n",
    "\n",
    "    from matplotlib import rcdefaults\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 1.0\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    x_lim = (0.0, 10.0)\n",
    "    x_tick_interval = 2.0   # tick interval along x\n",
    "    y_lim = (0.0, 100.0)\n",
    "    y_tick_interval = 20.0  # tick interval along y\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "\n",
    "    ymax = 2890.0 # km\n",
    "\n",
    "    ylim=[ymax, 0.0]\n",
    "    masky = (depths/1e3 < ymax)\n",
    "\n",
    "    # get diffusion and dislocation profile\n",
    "    eta_diff = viscosity_profile[\"diffusion\"]\n",
    "    eta_disl = viscosity_profile[\"dislocation\"]\n",
    "    eta = viscosity_profile[\"composite\"]\n",
    "    eta13 = viscosity_profile[\"composite_13\"]\n",
    "    eta_disl13 = viscosity_profile[\"dislocation_13\"]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5), tight_layout=True)\n",
    "\n",
    "    # pressure\n",
    "    color = 'tab:blue'\n",
    "    axs[0].plot(pressures/1e9, depths/1e3, color=color, label='pressure')\n",
    "    axs[0].set_ylabel('Depth [km]') \n",
    "    axs[0].set_xlabel('Pressure [GPa]', color=color)\n",
    "    Pmax = np.ceil(np.max(pressures[masky]/1e9) / 10.0) *10.0\n",
    "    axs[0].set_xlim([0.0, Pmax])\n",
    "    # axs[0].invert_yaxis()\n",
    "    axs[0].set_ylim(ylim)\n",
    "\n",
    "    # ax2: temperature\n",
    "    color = 'tab:red'\n",
    "    ax2 = axs[0].twiny()\n",
    "    ax2.set_ylim(ylim)\n",
    "    ax2.plot(temperatures, depths/1e3, color=color, label='temperature')\n",
    "    Tmax = np.ceil(np.max(temperatures[masky]) / 100.0) *100.0\n",
    "    ax2.set_xlim([0.0, Tmax])\n",
    "    ax2.set_xlabel('Temperature [K]', color=color) \n",
    "\n",
    "    # second: viscosity\n",
    "    #   upper mantle\n",
    "    axs[1].semilogx(eta_diff, depths/1e3, 'c', label='diffusion creep')\n",
    "    axs[1].semilogx(eta_disl, depths/1e3, 'g', label='dislocation creep(%.2e)' % strain_rate)\n",
    "    axs[1].semilogx(eta, depths/1e3, 'r--', label='Composite')\n",
    "    axs[1].set_xlim([1e19,1e24])\n",
    "    axs[1].set_ylim(ylim)\n",
    "    axs[1].grid()\n",
    "    axs[1].set_ylabel('Depth [km]')\n",
    "    axs[1].legend()\n",
    "\n",
    "    # third: viscosity at 1e13\n",
    "    axs[2].semilogx(eta_diff, depths/1e3, 'c', label='diffusion creep')\n",
    "    axs[2].semilogx(eta_disl13, depths/1e3, 'g', label='dislocation creep(%.2e)' % 1e-13)\n",
    "    axs[2].semilogx(eta13, depths/1e3, 'r--', label='Composite')\n",
    "    axs[2].set_xlim([1e19,1e24])\n",
    "    axs[2].set_ylim(ylim)\n",
    "    axs[2].grid()\n",
    "    axs[2].set_ylabel('Depth [km]')\n",
    "    axs[2].legend()\n",
    "\n",
    "    fig_path=os.path.join(results_dir, \"viscosity_profile_combined_%s.pdf\" % viscosity_jump_type)\n",
    "    fig.savefig(fig_path)\n",
    "    print(\"Saved figure %s\" % fig_path)\n",
    "\n",
    "\n",
    "    # Adjust spine thickness for this plot\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (This is the new method of using the json/dict inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_group_2d_by_dict = False\n",
    "\n",
    "if create_group_2d_by_dict:\n",
    "\n",
    "    from hamageolib.research.haoyuan_2d_subduction.legacy_tools import CreateGroup, CASE_TWOD, CASE_OPT_TWOD\n",
    "\n",
    "    local_MOW_dir = \"/mnt/lochy/ASPECT_DATA/MOW\"\n",
    "    \n",
    "    base_json_path = os.path.join(root_path, \"hamageolib/research/haoyuan_2d_subduction/legacy_files/reference_TwoD/240221/case_3d_consistent.json\")\n",
    "    base_dir = os.path.join(root_path, \"hamageolib/research/haoyuan_2d_subduction/legacy_files/reference_TwoD/240221\")\n",
    "    slurm_file_path = os.path.join(root_path, \"scripts/slurm/250816/job_hive_high.sh\")\n",
    "    output_dir = os.path.join(local_MOW_dir, \"mow02_2\")\n",
    "\n",
    "    group_json_2d = \\\n",
    "    {\n",
    "        \"base name\": \"C_mow\", \n",
    "        \"base json\": base_json_path,\n",
    "        \"base directory\": base_dir,\n",
    "        \"output directory\": output_dir,\n",
    "        \"slurm base file\": slurm_file_path,\n",
    "        \"combine case run\": 1,\n",
    "        \"base features\":[\n",
    "            {\n",
    "                \"name\": \"branch to use\",\n",
    "                \"key\": [\"branch\"],\n",
    "                \"unit\": \"\",\n",
    "                \"values\": [\"master_TwoD_rebase_dealii-9.5\"],\n",
    "                \"abbreviating strings\": [\"\"]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"depth average file\",\n",
    "                \"key\": [\"depth average file\"],\n",
    "                \"unit\": \"\",\n",
    "                \"values\": [os.path.join(root_path, \"hamageolib/research/haoyuan_2d_subduction/legacy_files/reference_TwoD/depth_average.txt\")],\n",
    "                \"abbreviating strings\": [\"\"]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"version\",\n",
    "                \"key\": [\"version\"],\n",
    "                \"unit\": \"\",\n",
    "                \"values\": [3.0],\n",
    "                \"abbreviating strings\": [\"\"]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"composition method scheme\",\n",
    "                \"key\": [\"composition method\", \"scheme\"],\n",
    "                \"unit\": \"\",\n",
    "                \"values\": [\"particle\"],\n",
    "                \"abbreviating strings\": [\"\"]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"composition method duplicate op\",\n",
    "                \"key\": [\"composition method\", \"duplicate op composition\"],\n",
    "                \"unit\": \"\",\n",
    "                \"values\": [1],\n",
    "                \"abbreviating strings\": [\"\"]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"adaptive refinemen\",\n",
    "                \"key\": [\"refinement\", \"adaptive refinement\"],\n",
    "                \"unit\": \"\",\n",
    "                \"values\": [4],\n",
    "                \"abbreviating strings\": [\"\"]\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"name\": \"peierls creep fix V\",\n",
    "                \"key\": [\"peierls creep\", \"fix peierls V as\"],\n",
    "                \"unit\": \"\",\n",
    "                \"values\": [\"dislocation\"],\n",
    "                \"abbreviating strings\": [\"\"]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Width of the box\",\n",
    "                \"key\": [\"world builder\", \"box width before adjusting\"],\n",
    "                \"unit\": \"km\",\n",
    "                \"values\": [8.896e6],\n",
    "                \"abbreviating strings\": [\"\"]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Viscosity in the slab core\",\n",
    "                \"key\": [\"shear zone\", \"slab core viscosity\"],\n",
    "                \"unit\": \"pa s\",\n",
    "                \"values\": [1e22],\n",
    "                \"abbreviating strings\": [\"\"]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Include peierls creep\",\n",
    "                \"key\": [\"include peierls creep\"],\n",
    "                \"unit\": \"\",\n",
    "                \"values\": [1],\n",
    "                \"abbreviating strings\": [\"\"]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Geometry\",\n",
    "                \"key\": [\"geometry\"],\n",
    "                \"unit\": \"\",\n",
    "                \"values\": [\"box\"],\n",
    "                \"abbreviating strings\": [\"\"]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Height of the box\",\n",
    "                \"key\": [\"world builder\", \"box height\"],\n",
    "                \"unit\": \"km\",\n",
    "                \"values\": [2890e3],\n",
    "                \"abbreviating strings\": [\"\"]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Thickness of the shear zone / crust\",\n",
    "                \"key\": [\"shear zone\", \"thickness\"],\n",
    "                \"unit\": \"m\",\n",
    "                \"values\": [15e3],\n",
    "                \"abbreviating strings\": [\"\"]\n",
    "            }\n",
    "\t    ],\n",
    "        \"features\":[\n",
    "            {\n",
    "                \"name\": \"Age of the subducting plate\",\n",
    "                \"key\": [\"world builder\", \"subducting plate\", \"age trench\"],\n",
    "                \"unit\": \"yr\",\n",
    "                \"values\": [40e6, 50e6, 80e6, 120e6],\n",
    "                \"abbreviation by value\": 1,\n",
    "                \"abbreviating value options\": [\"SA\", 1e-6]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Age of the overiding plate\",\n",
    "                \"key\": [\"world builder\", \"overiding plate\", \"age\"],\n",
    "                \"unit\": \"yr\",\n",
    "                \"values\": [20e6, 40e6],\n",
    "                \"abbreviation by value\": 1,\n",
    "                \"abbreviating value options\": [\"OA\", 1e-6]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Slab strength\",\n",
    "                \"key\": [\"slab\", \"strength\"],\n",
    "                \"unit\": \"pa\",\n",
    "                \"values\": [100e6, 300e6, 500e6, 1e12],\n",
    "                \"abbreviation by value\": 1,\n",
    "                \"abbreviating value options\": [\"ss\", 1e-6]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Constant viscosity\",\n",
    "                \"key\": [\"shear zone\", 'constant viscosity'],\n",
    "                \"unit\": \"pa s\",\n",
    "                \"values\": [3e19, 1e20, 3e20, 1e21],\n",
    "                \"abbreviating strings\": [\"SZV3e19\",\"SZV1e20\",\"SZV3e20\", \"SZV1e21\"],\n",
    "                \"if abbreviating\": [1, 1, 1, 1]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Include metastable\",\n",
    "                \"key\": [\"metastable\", \"include metastable\"],\n",
    "                \"unit\": \"\",\n",
    "                \"values\": [0, 1],\n",
    "                \"abbreviating strings\": [\"\",\"M\"],\n",
    "                \"if abbreviating\": [0, 1]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Include metastable\",\n",
    "                \"key\": [\"metastable\", \"include grain size\"],\n",
    "                \"unit\": \"\",\n",
    "                \"values\": [0, 1],\n",
    "                \"abbreviating strings\": [\"\",\"gz\"],\n",
    "                \"if abbreviating\": [0, 1]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Width of the subducting plate\",\n",
    "                \"key\": [\"mantle rheology\", \"jump scheme\"],\n",
    "                \"unit\": \"1\",\n",
    "                \"values\": [\"default\", \"1100i\"],\n",
    "                \"abbreviating strings\": [\"\", \"jp1100i\"],\n",
    "                \"if abbreviating\": [0, 1]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Value of Coh to use in the rheology\",\n",
    "                \"key\": [\"mantle rheology\", \"Coh\"],\n",
    "                \"unit\": \"\",\n",
    "                \"values\": [300.0, 100.0],\n",
    "                \"abbreviating strings\": [\"\", \"Coh100\"],\n",
    "                \"if abbreviating\": [0, 1]\n",
    "            },\n",
    "        ],\n",
    "        \"bindings\": [[3, 1, 3, 1, 0, 0, 0, 0], [3, 1, 1, 1, 0, 0, 0, 0], [3, 1, 3, 1, 1, 1, 0, 0], \n",
    "                     [3, 1, 1, 1, 1, 1, 0, 0], [3, 1, 3, 1, 0, 0, 1, 0], [3, 1, 3, 1, 1, 1, 1, 0],\n",
    "                     [3, 1, 3, 1, 0, 0, 0, 1], [3, 1, 3, 1, 1, 1, 0, 1], \n",
    "                     [3, 1, 3, 2, 0, 0, 0, 1], [3, 1, 3, 2, 1, 1, 0, 1], [3, 1, 3, 3, 1, 1, 0, 1]\n",
    "                     ],\n",
    "        \"slurm\": [\n",
    "          {\n",
    "            \"slurm file\": slurm_file_path,\n",
    "            \"build directory\": \"master_TwoD_rebase_dealii-9.5\",\n",
    "            \"tasks per node\": 8,\n",
    "            \"cpus\": 8\n",
    "          }\n",
    "      ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_group_2d_by_dict:\n",
    "    CreateGroup(group_json_2d, CASE_TWOD, CASE_OPT_TWOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Options\n",
    "\n",
    "- option 0: case is adapted from F100sa80oa40Rwedge in the twod case\n",
    "- option 1: case is adapted from C2d_SA80_OA40_l8896_h1000_s300 in the 3d-consistent 2d case\n",
    "\n",
    "#### (This is the old method to prescribe options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mow_case_name(case_name_base, geometry, box_height, include_metastable,\\\n",
    "                  global_refine_level ,adaptive_refine_level, viscosity_jump_type,\\\n",
    "                    shear_zone_thickness, shear_zone_visc, include_metastable_grain_size):\n",
    "    \n",
    "    import math\n",
    "\n",
    "    # fix case_name\n",
    "    if geometry == \"box\":\n",
    "        case_name = \"C_%s_h%.1f\" % (case_name_base, box_height/1e3)\n",
    "    else:\n",
    "        case_name = \"Sp_%s_h%.1f\" % (case_name_base, box_height/1e3)\n",
    "    if include_metastable:\n",
    "        case_name = \"%s_M\" % case_name\n",
    "    else:\n",
    "        case_name = case_name\n",
    "    case_name = \"%s_gr%d_ar%d\" % (case_name, global_refine_level, adaptive_refine_level)\n",
    "\n",
    "    # viscosity change\n",
    "    if viscosity_jump_type != \"660\":\n",
    "        case_name = \"%s_jp%s\" % (case_name, viscosity_jump_type)\n",
    "\n",
    "    # shear zone\n",
    "    if not math.isclose(shear_zone_thickness, 15e3, rel_tol=1e-9):\n",
    "        case_name = \"%s_szT%.2f\" % (case_name, shear_zone_thickness/1e3)\n",
    "    \n",
    "    if not math.isclose(np.log10(shear_zone_visc), 20.0, rel_tol=1e-9):\n",
    "        case_name = \"%s_szV%.2e\" % (case_name, shear_zone_visc)\n",
    "\n",
    "    if include_metastable_grain_size:\n",
    "        case_name += \"_gz\"\n",
    "\n",
    "    return case_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_aspect_2d_test = False\n",
    "run_aspect_2d_test_first_step = False\n",
    "\n",
    "if run_aspect_2d_test:\n",
    "\n",
    "    # paths \n",
    "    aspect_dir = \"/home/lochy/Softwares/aspect\" # aspect directory (local, optional if not ran locally)\n",
    "    aspect_executable = os.path.join(aspect_dir, \"build_master_TwoD_rebase/aspect\") # build direcotory (local, optional if not ran locally)\n",
    "    slurm_base_path = os.path.join(root_path, \"scripts/slurm/250816/job_hive_high.sh\")\n",
    "\n",
    "    # options\n",
    "    case_option_id = 1 # 0 - same to the shear zone model, 1 - same to the 3-d model\n",
    "    include_metastable = 1  # 1 - include metastable\n",
    "    include_metastable_grain_size =  1 # 1 - include grain size\n",
    "    case_root_dir = \"/mnt/lochy/ASPECT_DATA/MOW/mow_01_test\"  # parent directory\n",
    "    case_name_base = \"mow\" # case directory\n",
    "    geometry = \"box\"; box_height = 2890e3 # geometry setup\n",
    "    global_refine_level = 3\n",
    "    adaptive_refine_level = 4\n",
    "\n",
    "    # viscosity profile\n",
    "    viscosity_jump_type = \"660\" # 660 or 1100 or 1100i\n",
    "\n",
    "    # shear zone\n",
    "    shear_zone_thickness = 15e3\n",
    "    shear_zone_visc = 1e20\n",
    "    case_name = mow_case_name(case_name_base, geometry, box_height, include_metastable,\\\n",
    "                              global_refine_level ,adaptive_refine_level, viscosity_jump_type,\\\n",
    "                                shear_zone_thickness, shear_zone_visc, include_metastable_grain_size)\n",
    "\n",
    "    if viscosity_jump_type == \"660\":\n",
    "        mantle_rheology_dict = {\n",
    "            \"scheme\": \"HK03_WarrenHansen23\",\n",
    "            \"flow law\": \"composite\",\n",
    "            \"adjust detail\": 1,\n",
    "            \"jump lower mantle\": 60.0,\n",
    "            \"Coh\": 300.0,\n",
    "            \"use 3d da file\": 1\n",
    "          }\n",
    "    elif viscosity_jump_type == \"1100\" :\n",
    "        mantle_rheology_dict = {\n",
    "            \"scheme\": \"HK03_WarrenHansen23\",\n",
    "            \"flow law\": \"composite\",\n",
    "            \"adjust detail\": 1,\n",
    "            \"jump lower mantle\": 0.5,\n",
    "            \"Coh\": 300.0,\n",
    "            \"use 3d da file\": 1,\n",
    "            \"use 3d da file whole mantle\": 1,\n",
    "            \"depth lm middle\": 1100e3,\n",
    "            \"V lm\": 9e-6,\n",
    "            \"V lm middle\": 3e-6\n",
    "          }\n",
    "    elif viscosity_jump_type == \"1100i\" :\n",
    "        mantle_rheology_dict = {\n",
    "            \"scheme\": \"HK03_WarrenHansen23\",\n",
    "            \"flow law\": \"composite\",\n",
    "            \"adjust detail\": 1,\n",
    "            \"jump lower mantle\": 5.0,\n",
    "            \"Coh\": 300.0,\n",
    "            \"use 3d da file\": 1,\n",
    "            \"use 3d da file whole mantle\": 1,\n",
    "            \"depth lm middle\": 1100e3,\n",
    "            \"V lm\": 6e-6,\n",
    "            \"V lm middle\": 3e-6\n",
    "        }\n",
    "    else:\n",
    "        raise NotImplementedError()  \n",
    "\n",
    "    case_options0 = {\n",
    "      \"base directory\": os.path.join(root_path, \"hamageolib/research/haoyuan_2d_subduction/legacy_files/reference_TwoD/240106\"), \n",
    "      \"branch\": \"master_TwoD_rebase_dealii-9.5\",\n",
    "      \"output directory\": case_root_dir,\n",
    "      \"name\": case_name,\n",
    "      \"depth average file\": os.path.join(root_path, \"hamageolib/research/haoyuan_2d_subduction/legacy_files/reference_TwoD/depth_average.txt\"),\n",
    "      \"include fast first step\": 1,\n",
    "      \"version\": 3.0,\n",
    "      \"test initial steps\": {\n",
    "        \"number of outputs\": 3,\n",
    "        \"interval of outputs\": 10000.0\n",
    "      },\n",
    "      \"geometry\": \"box\",\n",
    "      \"potential temperature\": 1573.0,\n",
    "      \"boundary condition\": {\n",
    "        \"model\": \"all free slip\"\n",
    "      },\n",
    "      \"use world builder\": 1,\n",
    "      \"world builder\": {\n",
    "        \"use new ridge implementation\": 1,\n",
    "        \"plate age method\": \"adjust box width\",\n",
    "        \"box width before adjusting\": 15570000.0,\n",
    "        \"adjust mesh with box width\": 1,\n",
    "        \"subducting plate\": {\n",
    "          \"age trench\": 80000000.0,\n",
    "          \"sp rate\": 0.05\n",
    "        },\n",
    "        \"overiding plate\": {\n",
    "          \"age\": 40000000.0,\n",
    "          \"transit\": {\n",
    "            \"age\": 20000000.0,\n",
    "            \"length\": 700000.0\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"use new rheology module\": 1,\n",
    "      \"coupling the eclogite phase to shear zone viscosity\": 0,\n",
    "      \"slurm\": [\n",
    "        {\n",
    "          \"slurm file\": slurm_base_path,\n",
    "          \"build directory\": \"master_TwoD_rebase_dealii-9.5\",\n",
    "          \"tasks per node\": 8,\n",
    "          \"cpus\": 8\n",
    "        }\n",
    "      ],\n",
    "      \"mantle rheology\": {\n",
    "        \"scheme\": \"HK03_WarrenHansen23\",\n",
    "        \"Coh\": 500.0,\n",
    "        \"delta Edisl\": 0.0\n",
    "      },\n",
    "      \"include peierls creep\": 1,\n",
    "      \"peierls creep\": {\n",
    "        \"scheme\": \"MK10\",\n",
    "        \"maximum peierls iterations\": 100,\n",
    "        \"fix peierls V as\": \"dislocation\"\n",
    "      },\n",
    "      \"refinement level\": global_refine_level + adaptive_refine_level,\n",
    "      \"shear zone\": {\n",
    "        \"thickness\": shear_zone_thickness,\n",
    "        \"constant viscosity\": shear_zone_visc,\n",
    "        \"cutoff depth\": 100000.0,\n",
    "        \"thickness\": 7500.0\n",
    "      },\n",
    "      \"phase transition model CDPT type\": \"HeFESTo_consistent\",\n",
    "      \"prescribe temperature method\": \"plate model 1\",\n",
    "      \"prescribe temperature width\": 400000.0,\n",
    "      \"outputs\": {\n",
    "        \"heat flux\": 1\n",
    "      },\n",
    "      \"refinement\": {\n",
    "        \"refine wedge\": 1\n",
    "      },\n",
    "      \"composition method\": {\n",
    "        \"scheme\": \"particle\",\n",
    "        \"duplicate op composition\": 1,\n",
    "      },\n",
    "      'metastable': {\n",
    "        \"include metastable\": include_metastable,\n",
    "        \"include grain size\": include_metastable_grain_size\n",
    "      }\n",
    "    }\n",
    "\n",
    "    case_options1 = {\n",
    "      \"base directory\": os.path.join(root_path, \"hamageolib/research/haoyuan_2d_subduction/legacy_files/reference_TwoD/240106\"), \n",
    "      \"branch\": \"master_TwoD_rebase_dealii-9.5\",\n",
    "      \"output directory\": case_root_dir,\n",
    "      \"name\": case_name,\n",
    "      \"depth average file\": os.path.join(root_path, \"hamageolib/research/haoyuan_2d_subduction/legacy_files/reference_ThD/depth_average_1573.txt\"),\n",
    "      \"include fast first step\": 1,\n",
    "      \"version\": 3.0,\n",
    "      \"test initial steps\": {\n",
    "        \"number of outputs\": 3,\n",
    "        \"interval of outputs\": 10000.0\n",
    "      },\n",
    "      \"geometry\": geometry,\n",
    "      \"potential temperature\": 1573.0,\n",
    "      \"boundary condition\": {\n",
    "        \"model\": \"all free slip\"\n",
    "      },\n",
    "      \"use world builder\": 1,\n",
    "      \"world builder\": {\n",
    "        \"use new ridge implementation\": 1,\n",
    "        \"plate age method\": \"adjust box width only assigning age\",\n",
    "        \"box width before adjusting\": 8896000.0,\n",
    "        \"adjust mesh with box width\": 1,\n",
    "        \"subducting plate\": {\n",
    "          \"age trench\": 80000000.0,\n",
    "          \"sp rate\": 0.05,\n",
    "          \"trailing length\": 600000.0\n",
    "        },\n",
    "        \"overiding plate\": {\n",
    "          \"age\": 40000000.0,\n",
    "          \"transit\": {\n",
    "            \"age\": 20000000.0,\n",
    "            \"length\": 700000.0\n",
    "          },\n",
    "          \"trailing length\": 600000.0\n",
    "        },\n",
    "        \"maximum repetition slice\": 1000000.0,\n",
    "        \"fix boudnary temperature auto\": 1,\n",
    "        \"box height\": box_height\n",
    "      },\n",
    "      \"coupling the eclogite phase to shear zone viscosity\": 0,\n",
    "      \"slurm\": [\n",
    "        {\n",
    "          \"slurm file\": slurm_base_path,\n",
    "          \"build directory\": \"master_TwoD_rebase_dealii-9.5\",\n",
    "          \"tasks per node\": 8,\n",
    "          \"cpus\": 8\n",
    "        }\n",
    "      ],\n",
    "      \"use new rheology module\": 1,\n",
    "      \"mantle rheology\": mantle_rheology_dict,\n",
    "      \"include peierls creep\": 1,\n",
    "      \"peierls creep\": {\n",
    "        \"scheme\": \"MK10\",\n",
    "        \"maximum peierls iterations\": 100,\n",
    "        \"fix peierls V as\": \"dislocation\"\n",
    "      },\n",
    "      \"refinement level\": global_refine_level + adaptive_refine_level,\n",
    "      \"minimum viscosity\": 1e+19,\n",
    "      \"refinement scheme\": \"3d consistent\",\n",
    "      \"reset density\": 1,\n",
    "      \"refinement\": {\n",
    "        \"global refinement\": global_refine_level,\n",
    "        \"adaptive refinement\": adaptive_refine_level\n",
    "      },\n",
    "      \"phase transition model CDPT type\": \"HeFESTo_consistent\",\n",
    "      \"shear zone\": {\n",
    "        \"thickness\": shear_zone_thickness,\n",
    "        \"constant viscosity\": shear_zone_visc,\n",
    "        \"slab core viscosity\": 1e+22\n",
    "      },\n",
    "      \"prescribe temperature method\": \"plate model 1\",\n",
    "      \"prescribe temperature width\": 900000.0,\n",
    "      \"prescribe temperature with trailing edge\": 1,\n",
    "      \"slab\": {\n",
    "        \"strength\": 300000000.0\n",
    "      },\n",
    "      \"composition method\": {\n",
    "        \"scheme\": \"particle\",\n",
    "        \"duplicate op composition\": 1,\n",
    "      },\n",
    "      'metastable': {\n",
    "        \"include metastable\": include_metastable,\n",
    "        \"include grain size\": include_metastable_grain_size\n",
    "      }\n",
    "    }\n",
    "\n",
    "    if case_option_id == 0:\n",
    "        case_options = case_options0\n",
    "    elif case_option_id == 1:\n",
    "        case_options = case_options1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_aspect_2d_test:\n",
    "    import json\n",
    "    from hamageolib.research.haoyuan_2d_subduction.legacy_tools import create_case_with_json, CASE_TWOD, CASE_OPT_TWOD\n",
    "\n",
    "    if not os.path.isdir(case_root_dir):\n",
    "        os.mkdir(case_root_dir)\n",
    "\n",
    "    # create the case\n",
    "    create_case_with_json(case_options, CASE_TWOD, CASE_OPT_TWOD)\n",
    "\n",
    "    # save the json path\n",
    "    json_path = os.path.join(case_root_dir, case_name, \"case.json\")\n",
    "    with open(json_path, \"w\") as fout:\n",
    "        json.dump(case_options, fout, indent=4)\n",
    "    print(\"Save file %s\" % json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the First step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_aspect_2d_test and run_aspect_2d_test_first_step:\n",
    "\n",
    "    case_dir = os.path.join(case_root_dir, \"test_foo1\")\n",
    "    prm_path = os.path.join(case_dir, \"case_ini.prm\")\n",
    "\n",
    "    # Run the ASPECT executable with the parameter file\n",
    "    # The function ensures that both the expected outputs are generated and no errors are produced\n",
    "    # 'capture_output=True' collects both stdout and stderr for further checks\n",
    "    # 'cwd' set the run from case_dir\n",
    "    completed_process = subprocess.run([aspect_executable, prm_path], capture_output=True, text=True, cwd=case_dir)\n",
    "\n",
    "    # Capture the standard output and error streams\n",
    "    stdout = completed_process.stdout\n",
    "    stderr = completed_process.stderr\n",
    "\n",
    "    # Uncomment the following lines for debugging purposes to inspect the output\n",
    "    # print(stdout)  # Debugging: Prints the standard output\n",
    "    # print(stderr)  # Debugging: Prints the standard error\n",
    "\n",
    "    # Check if the expected line indicating wallclock time appears in the output\n",
    "    # The expected line format is something like:\n",
    "    # -- Total wallclock time elapsed including restarts: 1s\n",
    "    assert(re.match(\".*Total wallclock\", stdout.split('\\n')[-6]))\n",
    "\n",
    "    # Ensure that the error stream is empty, indicating no issues during the run\n",
    "    assert(stderr == \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results\n",
    "\n",
    "make use of the jupyter_notebooks/TwoDSubduction/PlotCase.ipynb notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_aspect_3d = False\n",
    "\n",
    "if create_aspect_3d:\n",
    "\n",
    "    from hamageolib.research.haoyuan_2d_subduction.legacy_tools import CreateGroup, CASE_THD, CASE_OPT_THD\n",
    "\n",
    "    base_json_path = os.path.join(root_path, \"hamageolib/research/haoyuan_2d_subduction/legacy_files/reference_ThD/12272025/case_2d_consistent.json\")\n",
    "    base_dir = os.path.join(root_path, \"hamageolib/research/haoyuan_2d_subduction/legacy_files/reference_ThD/12272025\")\n",
    "    slurm_file_path = os.path.join(root_path, \"scripts/slurm/250816/job_frontera-normal.sh\")\n",
    "    output_dir = \"/mnt/lochy/ASPECT_DATA/MOW/mow3_01\"\n",
    "    branch = \"master_TwoD_rebase_dealii-9.5\"\n",
    "\n",
    "\n",
    "    if create_aspect_3d:\n",
    "        group_json = \\\n",
    "        {\n",
    "          \"base name\": \"eba3d\",\n",
    "          \"type\": \"2d_consistent\", \n",
    "          \"base json\": base_json_path,\n",
    "          \"base directory\": base_dir,\n",
    "          \"output directory\": output_dir,\n",
    "          \"branch\": branch,\n",
    "          \"base features\": [\n",
    "          {\n",
    "            \"name\": \"Version\",\n",
    "            \"key\": [\"version\"],\n",
    "            \"unit\": \"\",\n",
    "            \"values\": [3.0],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Composition method\",\n",
    "            \"key\": [\"composition method\", \"scheme\"],\n",
    "            \"unit\": \"\",\n",
    "            \"values\": [\"particle\"],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Geometry\",\n",
    "            \"key\": [\"geometry\"],\n",
    "            \"unit\": \"\",\n",
    "            \"values\": [\"box\"],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Viscosity in the slab core\",\n",
    "            \"key\": [\"shear zone\", \"slab core viscosity\"],\n",
    "            \"unit\": \"Pa s\",\n",
    "            \"values\": [1e22],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Adjust detail of mantle rheology\",\n",
    "            \"key\": [\"mantle rheology\", \"adjust detail\"],\n",
    "            \"unit\":\"1\",\n",
    "            \"values\": [1],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "\t        },\n",
    "\n",
    "          {\n",
    "            \"name\": \"Value of Coh to use in the rheology\",\n",
    "            \"key\": [\"mantle rheology\", \"Coh\"],\n",
    "            \"unit\": \"Coh/ 10^6 Si\",\n",
    "            \"values\": [300.0],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "\t        },\n",
    "          {\n",
    "            \"name\": \"Output non-adiabatic pressure\",\n",
    "            \"key\": [\"post-process\", \"nonadiabatic pressure\"],\n",
    "            \"unit\": \"\",\n",
    "            \"values\": [1],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "          },\n",
    "\n",
    "          {\n",
    "            \"name\": \"Age of the subducting plate at trench\",\n",
    "            \"key\": [\"plate setup\", \"sp age\"],\n",
    "            \"unit\": \"yr\",\n",
    "            \"values\": [80000000.0],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Age of the overiding plate\",\n",
    "            \"key\": [\"plate setup\", \"ov age\"],\n",
    "            \"unit\": \"yr\",\n",
    "            \"values\": [40000000.0],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Length of the Box before adjusting for the age of the trench.\",\n",
    "            \"key\": [\"geometry setup\", \"box length before adjusting\"],\n",
    "            \"unit\": \"m\",\n",
    "            \"values\": [8896000.0],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Width of the box\",\n",
    "            \"key\": [\"geometry setup\", \"box width\"],\n",
    "            \"unit\": \"m\",\n",
    "            \"values\": [4000000.0],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Width of the subducting plate\",\n",
    "            \"key\": [\"plate setup\", \"sp width\"],\n",
    "            \"unit\": \"m\",\n",
    "            \"values\": [1000000.0],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Height of the box\",\n",
    "            \"key\": [\"geometry setup\", \"box height\"],\n",
    "            \"unit\": \"m\",\n",
    "            \"values\": [2890e3],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "\t        },\n",
    "          {\n",
    "            \"name\": \"Lower the number of particles\",\n",
    "            \"key\": [\"composition method\", \"lower particle numbers\"],\n",
    "            \"unit\": \"1\",\n",
    "            \"values\": [1],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "\t        },\n",
    "          {\n",
    "            \"name\": \"Use loose solver scheme\",\n",
    "            \"key\": [\"stokes solver\", \"use loose solver scheme\"],\n",
    "            \"unit\": \"1\",\n",
    "            \"values\": [1],\n",
    "            \"abbreviating strings\": [\"\"]\n",
    "\t        }\n",
    "        ],\n",
    "        \"features\": [\n",
    "          {\n",
    "            \"name\": \"Include metastable\",\n",
    "            \"key\": [\"metastable\", \"include metastable\"],\n",
    "            \"unit\": \"1\",\n",
    "            \"values\": [0, 1],\n",
    "            \"abbreviating strings\": [\"\", \"M\"],\n",
    "            \"if abbreviating\": [0, 1]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Include metastable grain size\",\n",
    "            \"key\": [\"metastable\", \"include grain size\"],\n",
    "            \"unit\": \"1\",\n",
    "            \"values\": [0, 1],\n",
    "            \"abbreviating strings\": [\"\", \"gz\"],\n",
    "            \"if abbreviating\": [0, 1]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Width of the subducting plate\",\n",
    "            \"key\": [\"mantle rheology\", \"jump scheme\"],\n",
    "            \"unit\": \"1\",\n",
    "            \"values\": [\"default\", \"1100i\"],\n",
    "            \"abbreviating strings\": [\"\", \"jp1100i\"],\n",
    "            \"if abbreviating\": [0, 1]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Value of lower/upper mantle ratio to use in the rheology\",\n",
    "            \"key\": [\"mantle rheology\", \"jump lower mantle\"],\n",
    "            \"unit\":\"1\",\n",
    "            \"values\": [60.0, 6.0],\n",
    "            \"abbreviating strings\": [\"\", \"j10\"],\n",
    "            \"if abbreviating\": [0, 1]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Slab strengh\",\n",
    "            \"key\": [\"plate setup\", \"strength\"],\n",
    "            \"unit\": \"Pa\",\n",
    "            \"values\": [300e6, 1e12],\n",
    "            \"abbreviating strings\": [\"\", \"nY\"],\n",
    "            \"if abbreviating\": [0, 1]\n",
    "          },\n",
    "          {\n",
    "              \"name\": \"Update metastable transition refinement scheme\",\n",
    "              \"key\": ['metastable', \"update refinement\"],\n",
    "              \"unit\": \"1\",\n",
    "              \"values\": [0, 1],\n",
    "              \"abbreviating strings\": [\"\", \"rf\"],\n",
    "            \"if abbreviating\": [0, 1]\n",
    "          }\n",
    "        ],\n",
    "        \"bindings\": [\n",
    "          [0, 0, 1, 1, 1, 0], [1, 0, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]\n",
    "        ],\n",
    "          \"slurm\":[\n",
    "          {\n",
    "            \"slurm file\": slurm_file_path,\n",
    "            \"build directory\": branch,\n",
    "            \"tasks per node\": 56,\n",
    "            \"cpus\": 5600\n",
    "          }\n",
    "          ]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_aspect_3d:\n",
    "    CreateGroup(group_json, CASE_THD, CASE_OPT_THD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Process\n",
    "\n",
    "In this section, I handle the post-processing of metatsable cases.\n",
    "\n",
    "* Visualization: I use a combined workflow of python (mainly pyvista) + paraview + Adobe Illustrator to generate plots\n",
    "\n",
    "Note:\n",
    "- do_post_process: control the running the the whole section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_post_process = True\n",
    "\n",
    "if do_post_process:\n",
    "\n",
    "    import shutil, math\n",
    "    from shutil import rmtree, copy\n",
    "    from matplotlib import gridspec, cm\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    from scipy.interpolate import interp1d, UnivariateSpline\n",
    "    import datetime\n",
    "\n",
    "    # Working directories\n",
    "    local_MOW_dir = \"/mnt/lochy/ASPECT_DATA/MOW\"\n",
    "    local_MOW_dir1 = \"/mnt/lochy2/ASPECT_DATA/MOW\"\n",
    "    assert(os.path.isdir(local_MOW_dir))\n",
    "\n",
    "    local_ThD_dir = \"/mnt/lochy/ASPECT_DATA/ThDSubduction\"\n",
    "    assert(os.path.isdir(local_ThD_dir))\n",
    "    use_3d_case = False # use cases in the old project\n",
    "\n",
    "    # py_temp file and temperature results directory\n",
    "    py_temp_dir = os.path.join(root_path, \"py_temp_files\")\n",
    "    RESULT_DIR = os.path.join(root_path, 'results')\n",
    "    os.makedirs(py_temp_dir, exist_ok=True) # Ensure the directory exists\n",
    "\n",
    "    today_date = datetime.datetime.today().strftime(\"%Y-%m-%d\") # Get today's date in YYYY-MM-DD format\n",
    "    py_temp_file = os.path.join(py_temp_dir, f\"py_temp_{today_date}.sh\")\n",
    "\n",
    "    if not os.path.exists(py_temp_file):\n",
    "        bash_header = \"\"\"#!/bin/bash\n",
    "    # =====================================================\n",
    "    # Script: py_temp.sh\n",
    "    # Generated on: {date}\n",
    "    # Description: Temporary Bash script created by Python\n",
    "    # =====================================================\n",
    "\n",
    "    \"\"\".format(date=today_date)\n",
    "        with open(py_temp_file, \"w\") as f:\n",
    "            f.write(bash_header)\n",
    "\n",
    "    print(f\"File ensured at: {py_temp_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_post_process:\n",
    "    # case_name_2d = \"mow_tests/eba2d_width80_h1000_bw4000_sw1000_yd300_M_fix_1\"\n",
    "    # case_name = None; case_name_2d = \"mow00/C_mow_h2890.0_M_gr4_ar5\"\n",
    "\n",
    "    ####################\n",
    "    # 1000 km\n",
    "    ####################\n",
    "    # without metastable\n",
    "    # case_name = \"mow3_00/C_mow_h1000.0_gr3_ar4\"; case_name_2d = \"mow_tests/eba2d_width80_h1000_bw4000_sw1000_yd300\"\n",
    "    # with metastable\n",
    "    # case_name = \"mow3_00/C_mow_h1000.0_M_gr3_ar4\"; casa_name_2d = None\n",
    "    # case_name = None; case_name_2d = \"mow00/C_mow_h2890.0_M_gr4_ar5\"\n",
    "    # case_name_2d = \"mow00/C_mow_h2890.0_gr4_ar5\"\n",
    "    \n",
    "    ####################\n",
    "    # Cases with full domain \n",
    "    ####################\n",
    "    # LABEL: R3d, paper: R2d\n",
    "    case_name = \"EBA_2d_consistent_8_6/eba3d_width80_c22_AR4_yd300\"; use_3d_case = True; case_name_2d = \"mow01/C_mow_h2890.0_gr3_ar4\" # meta, low r\n",
    "    # LABEL: M3d, paper: M2d\n",
    "    # case_name =  \"mow3_00/C_mow_h2890.0_M_gr3_ar4_rf\"; case_name_2d = \"mow01/C_mow_h2890.0_M_gr3_ar4\" # set PTs for overring plate compositions\n",
    "    # case_name = \"mow3_00/C_mow_h2890.0_M_gr3_ar4_rf\"; case_name_2d = \"mow01/C_mow_h2890.0_M_gr3_ar4_rf\" # test refinement and particle number\n",
    "    # case_name = None; case_name_2d = \"mow01/C_mow_h2890.0_M_gr3_ar4_rf_1\" # test particle number\n",
    "    # LABEL: M3d_gz, paper: M2d_gz\n",
    "    # case_name = \"mow3_00/C_mow_h2890.0_M_gr3_ar4_rf_gz\"; case_name_2d = \"mow01/C_mow_h2890.0_M_gr3_ar4_gz_2\"\n",
    "    # case_name = None; case_name_2d = \"mow00/C_mow_h2890.0_gr3_ar4\" # non-meta\n",
    "    # LABEL: C_mow_M_gr3_ar4_mv_compare\n",
    "    # case_name = None; case_name_2d = \"mow01/C_mow_h2890.0_gr3_ar4_gz_test_mv\"\n",
    "    \n",
    "    ####################\n",
    "    # Cases with full domain and a different slab age\n",
    "    ####################\n",
    "    # C_mow_SA120_gr3_ar4_nY\n",
    "    # case_name = None; case_name_2d = \"mow02_2/C_mow_SA120.0_OA40.0_ss1000000.0_SZV1e20\"\n",
    "    # C_mow_SA120_gr3_ar4_nY_M_gz\n",
    "    # case_name = None; case_name_2d = \"mow02_2/C_mow_SA120.0_OA40.0_ss1000000.0_SZV1e20_M_gz\"\n",
    "    # C_mow_SA120_gr3_ar4\n",
    "    # case_name = None; case_name_2d = \"mow02_2/C_mow_SA120.0_OA40.0_ss300.0_SZV1e20\"\n",
    "    # C_mow_SA120_gr3_ar4_nY_jp1100i\n",
    "    # case_name = None; case_name_2d = \"mow02_2/C_mow_SA120.0_OA40.0_ss1000000.0_SZV1e20_jp1100i\"\n",
    "    # C_mow_SA120_gr3_ar4_nY_jp1100i_M_gz\n",
    "    # case_name = None; case_name_2d = \"mow02_2/C_mow_SA120.0_OA40.0_ss1000000.0_SZV1e20_M_gz_jp1100i\"\n",
    "    # C_mow_SA120_gr3_ar4_nY_coh100_M_gz\n",
    "    # case_name = None; case_name_2d = \"mow02_2/C_mow_SA120.0_OA40.0_ss1000000.0_SZV1e20_M_gz_Coh100\"\n",
    "    # C_mow_SA120_gr3_ar4_nY_coh100_szv3e20_M_gz\n",
    "    # case_name = None; case_name_2d = \"mow02_2/C_mow_SA120.0_OA40.0_ss1000000.0_SZV3e20_M_gz_Coh100\"\n",
    "    # C_mow_SA120_gr3_ar4_nY_coh100_szv1e21_M_gz\n",
    "    # case_name = None; case_name_2d = \"mow02_2/C_mow_SA120.0_OA40.0_ss1000000.0_SZV1e21_M_gz_Coh100\"\n",
    "\n",
    "    ####################\n",
    "    # Cases with full domain and different rheology in the lower mantle\n",
    "    ####################\n",
    "    # LABEL: C_mow_gr3_ar4_j1100\n",
    "    # case_name = None; case_name_2d = \"mow01/C_mow_h2890.0_gr3_ar4_jp1100\"\n",
    "    # LABEL: C_mow_M_gr3_ar4_j1100\n",
    "    # case_name = None; case_name_2d = \"mow01/C_mow_h2890.0_M_gr3_ar4_jp1100\"\n",
    "    # LABEL: C_mow_gr3_ar4_j1100i\n",
    "    # case_name = None; case_name_2d = \"mow01/C_mow_h2890.0_gr3_ar4_jp1100i\"\n",
    "    # LABEL: C_mow_M_gr3_ar4_j1100i\n",
    "    # case_name = None; case_name_2d = \"mow01/C_mow_h2890.0_M_gr3_ar4_jp1100i\"\n",
    "    # LABEL: C_mow_M_gr3_ar4_j1100i_szT7.5\n",
    "    # case_name = None; case_name_2d = \"mow01/C_mow_h2890.0_M_gr3_ar5_jp1100i_szT7.50_szV5.00e+19\"\n",
    "    # LABEL: C_mow_gr3_ar4_j1100i_szT7.5\n",
    "    # case_name = None; case_name_2d = \"no_mow_sz_jump/C_mow_h2890.0_gr3_ar5_jp1100i_szT7.50_szV5.00e+19\"\n",
    "    # LABEL: C_mow_M_gr3_ar4_j1100i_szT7.5_noMyd\n",
    "    # case_name = None; case_name_2d = \"mow01/C_mow_h2890.0_M_gr3_ar5_jp1100i_szT7.50_szV5.00e+19_no_myd\"\n",
    "    # LABEL: C_mow_gr3_ar4_j1100i_szT7.5_noMyd\n",
    "    # case_name = None; case_name_2d = \"no_mow_sz_jump/C_mow_h2890.0_gr3_ar5_jp1100i_szT7.50_szV5.00e+19_no_myd\"\n",
    "\n",
    "    ####################\n",
    "    # Cases with full domain and different shear zone viscosity\n",
    "    ####################\n",
    "    # LABEL: C_mow_gr3_ar4_szT7.5_szv1e20\n",
    "    # case_name = None; case_name_2d = \"mow02_1/C_mow_SA80.0_OA40.0_ss300.0_SZW7.5_SZV1e20\"\n",
    "    # LABEL: C_mow_gr3_ar4_szT7.5_szv1e21\n",
    "    # case_name = None; case_name_2d = \"mow02_1/C_mow_SA80.0_OA40.0_ss300.0_SZW7.5_SZV1e21\"\n",
    "\n",
    "\n",
    "\n",
    "    ####################\n",
    "    # Cases with chunk geometry (not intended)\n",
    "    ####################\n",
    "    # LABEL: C_mow_gr3_ar4_j1100i_szT7.5_sz1e20\n",
    "    # case_name = None; case_name_2d = \"mow02/C_mow_SA80.0_OA40.0_ss300.0_SZW7.5_SZV1e20\"\n",
    "    # LABEL: C_mow_gr3_ar4_j1100i_szT7.5_sz1e21\n",
    "    # case_name = None; case_name_2d = \"mow02/C_mow_SA80.0_OA40.0_ss300.0_SZW7.5_SZV1e21\"\n",
    "\n",
    "    local_dir_2d = None; local_dir = None\n",
    "    if case_name_2d is not None:\n",
    "        local_dir_2d = os.path.join(local_MOW_dir, case_name_2d)\n",
    "        assert(os.path.isdir(local_dir_2d))\n",
    "        print(\"local_dir_2d:\\n\\t\", local_dir_2d)\n",
    "        img_dir = os.path.join(local_dir_2d, \"img\")\n",
    "        if not os.path.isdir(img_dir):\n",
    "            os.mkdir(img_dir)\n",
    "        pv_img_dir = os.path.join(img_dir, \"pv_outputs\")\n",
    "        if not os.path.isdir(pv_img_dir):\n",
    "            os.mkdir(pv_img_dir)\n",
    "    if case_name is not None:\n",
    "        if use_3d_case:\n",
    "            local_dir = os.path.join(local_ThD_dir, case_name)\n",
    "        else:\n",
    "            local_dir = os.path.join(local_MOW_dir, case_name)\n",
    "        assert(os.path.isdir(local_dir))\n",
    "        print(\"local_dir:\\n\\t\", local_dir)\n",
    "        img_dir = os.path.join(local_dir, \"img\")\n",
    "        if not os.path.isdir(img_dir):\n",
    "            os.mkdir(img_dir)\n",
    "        pv_img_dir = os.path.join(img_dir, \"pv_outputs\")\n",
    "        if not os.path.isdir(pv_img_dir):\n",
    "            os.mkdir(pv_img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-d case\n",
    "\n",
    "For the 2-d case, I use a combined pyvista + paraview workflow.\n",
    "\n",
    "- Analysis: this is handled in pyvista (e.g. trench position, slab depth, etc.)\n",
    "- Generating script: using python to generate script for paraview\n",
    "- Visualization: running script in paraview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_prepare_for_plot_2d = True # flag for processing 2-d case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate case options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_post_process and is_prepare_for_plot_2d:\n",
    "    from hamageolib.research.mow_subduction.case_options import CASE_OPTIONS_TWOD\n",
    "    assert(local_dir_2d is not None)\n",
    "\n",
    "    # case options \n",
    "    Case_Options_2d = CASE_OPTIONS_TWOD(local_dir_2d)\n",
    "    Case_Options_2d.Interpret()\n",
    "    Case_Options_2d.SummaryCaseVtuStep(os.path.join(local_dir_2d, \"summary.csv\"))\n",
    "    Case_Options_2d.SummaryCaseVtuStepExport(os.path.join(local_dir_2d, \"summary.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate runtime plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_post_process and is_prepare_for_plot_2d:\n",
    "    output_dir = os.path.join(local_dir_2d, \"img\", \"runtime_plots\")\n",
    "    \n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    plot_helper.generate_runtime_plots(Case_Options_2d.time_df, output_dir=output_dir, assemble=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate plotting scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 2d case: prepare data and paraview script\n",
    "\n",
    "is_process_pyvista_for_plot_2d = True\n",
    "\n",
    "if do_post_process and is_prepare_for_plot_2d:\n",
    "    from hamageolib.research.haoyuan_3d_subduction.post_process import ProcessVtuFileTwoDStep \n",
    "\n",
    "\n",
    "    # parameters\n",
    "    graphical_steps = [22] # specify steps\n",
    "    rotation_plus = 0.47 # rotation of the frame along the lon when making plot\n",
    "    max_depth = \"1000\"  # maximum plot depth, 1000, 1300, or 1500\n",
    "\n",
    "    assert(max_depth in [\"1000\", \"1300\", \"1500\"])\n",
    "\n",
    "\n",
    "\n",
    "    # Processing pyvista\n",
    "    if is_process_pyvista_for_plot_2d:\n",
    "        # print(Case_Options_2d.summary_df)\n",
    "        # print(Case_Options_2d.summary_df.loc[idx, \"Time\"].values[0])\n",
    "        for step in graphical_steps:\n",
    "            pvtu_step = step + int(Case_Options_2d.options['INITIAL_ADAPTIVE_REFINEMENT'])\n",
    "            output_dict = ProcessVtuFileTwoDStep(local_dir_2d, pvtu_step, Case_Options_2d)\n",
    "            Case_Options_2d.SummaryCaseVtuStepUpdateValue(\"Slab depth\", step, output_dict[\"slab_depth\"])\n",
    "            Case_Options_2d.SummaryCaseVtuStepUpdateValue(\"Trench\", step, output_dict[\"trench_center\"])\n",
    "\n",
    "            # print(\"metastable_area: %.2e km^2\" % (output_dict[\"metastable_area\"]/1e6))\n",
    "    \n",
    "    # Generate paraview script\n",
    "    for step in graphical_steps:\n",
    "        my_assert(len(graphical_steps)==1, ValueError, \"Feeding the trench position only works when there is only one step\")\n",
    "\n",
    "        # Get time \n",
    "        idx = Case_Options_2d.summary_df[\"Vtu step\"] == step\n",
    "        _time = Case_Options_2d.summary_df.loc[idx, \"Time\"].values[0]\n",
    "        pvtu_step = step + int(Case_Options_2d.options['INITIAL_ADAPTIVE_REFINEMENT']) \n",
    "        pyvista_outdir = os.path.join(local_dir_2d, \"pyvista_outputs\", \"%05d\" % pvtu_step)\n",
    "\n",
    "        # Get trench center\n",
    "        # trench_initial = Case_Options_2d.summary_df.loc[0, \"Trench\"] # there is issue with this\n",
    "        trench_center = Case_Options_2d.summary_df.loc[idx, \"Trench\"].values[0]\n",
    "\n",
    "        # Apply steps\n",
    "        Case_Options_2d.Interpret(steps=[step])\n",
    "    \n",
    "        # Add additional outputs\n",
    "        additional_options = {\"TRENCH_CENTER\": trench_center, \"TRENCH_INI_DERIVED\": 0.0} # 0.0: initial trench center issue\n",
    "        for key, value in additional_options.items():\n",
    "            Case_Options_2d.options[key] = value\n",
    "\n",
    "        # Add additonal plot options\n",
    "        Case_Options_2d.options[\"FOO00\"] = 1 # this turns on the contour of eq_trans\n",
    "        Case_Options_2d.options[\"FOO01\"] = 1 # this turns on the contour of 725 C\n",
    "        Case_Options_2d.options[\"FOO03\"] = 1 # this turns on the metasstable region\n",
    "        Case_Options_2d.options[\"DA_RANGE\"] = [-1e8, 1e8] # this turns on the contour of 725 C\n",
    "        if max_depth == \"1500\":\n",
    "            Case_Options_2d.options[\"MAX_PLOT_DEPTH_IN_SLICE\"] = 1500e3 # turn this on to plot max depth of 1500\n",
    "        # Case_Options_2d.options[\"FOO02\"] = 1 # this turns on the metastable area\n",
    "        # Case_Options_2d.options[\"FOO03\"] = 1 # this turns on the metastable area in the slab\n",
    "\n",
    "        # Export paraview script\n",
    "        odir = os.path.join(local_dir_2d, 'paraview_scripts')\n",
    "        if not os.path.isdir(odir):\n",
    "            os.mkdir(odir)\n",
    "        print(\"Generating paraview scripts\")\n",
    "        py_script = 'slab1.py'\n",
    "        ofile = os.path.join(odir, py_script)\n",
    "        paraview_script = os.path.join(SCRIPT_DIR, 'paraview_scripts', 'ThDSubduction', py_script)\n",
    "        paraview_script_base = os.path.join(SCRIPT_DIR, 'paraview_scripts', 'base.py')\n",
    "        Case_Options_2d.read_contents(paraview_script_base, paraview_script)  # combine these two scripts\n",
    "        Case_Options_2d.substitute()\n",
    "\n",
    "        ofile_path = Case_Options_2d.save(ofile, relative=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automazed workflow to finalize visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalize_visual_2d = False\n",
    "\n",
    "if do_post_process and finalize_visual_2d:\n",
    "\n",
    "    from hamageolib.research.haoyuan_2d_subduction.workflow_scripts import finalize_visualization_2d_12172024\n",
    "    from hamageolib.research.haoyuan_3d_subduction.post_process import finalize_visualization_2d_07222025_box\n",
    "\n",
    "    _time = 1.0000e+07\n",
    "    \n",
    "    # file types\n",
    "    file_name = \"slice_center_viscosity\"\n",
    "\n",
    "\n",
    "    if file_name in [\"slice_center_viscosity\", \"T\", \"slice_center_density\", \"slice_center_mow\", \"slice_center_meta_grain_size\"]:\n",
    "        if Case_Options_2d.options[\"GEOMETRY\"] == \"chunk\":\n",
    "            if max_depth == \"1000\":\n",
    "                frame_png_file_with_ticks = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/upper_mantle_frame_12172024_trans_modified-01.png\"\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "            output_image_file = finalize_visualization_2d_12172024(local_dir_2d, file_name, _time, frame_png_file_with_ticks, add_time=False)\n",
    "        else:\n",
    "            if max_depth == \"1000\":\n",
    "                frame_png_file_with_ticks = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/upper_mantle_frame_07222025_trans_modified_box-01.png\"\n",
    "                output_image_file = finalize_visualization_2d_07222025_box(local_dir_2d, file_name, _time, frame_png_file_with_ticks, add_time=False)\n",
    "            elif max_depth == \"1300\":\n",
    "                frame_png_file_with_ticks = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/upper_mantle_frame_07222025_trans_modified_box_1300-01.png\"\n",
    "                output_image_file = finalize_visualization_2d_07222025_box(local_dir_2d, file_name, _time, frame_png_file_with_ticks, add_time=False, canvas_size=(996, 700))\n",
    "            elif max_depth == \"1500\":\n",
    "                # pos_v_diff=90, test whether this is needed, needed in the 3-d slice\n",
    "                frame_png_file_with_ticks = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/upper_mantle_frame_07222025_trans_modified_box_1500.png\"\n",
    "                output_image_file = finalize_visualization_2d_07222025_box(local_dir_2d, file_name, _time, frame_png_file_with_ticks, add_time=False, canvas_size=(996, 800), pos_v_diff=90)\n",
    "            else:\n",
    "                raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-d case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate case options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_3d_case = True\n",
    "\n",
    "if do_post_process and process_3d_case:\n",
    "    from hamageolib.research.haoyuan_3d_subduction.case_options import CASE_OPTIONS\n",
    "\n",
    "    assert(local_dir is not None)\n",
    "    \n",
    "    # case options \n",
    "    Case_Options = CASE_OPTIONS(local_dir)\n",
    "    Case_Options.Interpret()\n",
    "    Case_Options.SummaryCaseVtuStep(os.path.join(local_dir, \"summary.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate runtime plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_post_process and process_3d_case:\n",
    "    output_dir = os.path.join(img_dir, \"runtime_plots\")\n",
    "    \n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    \n",
    "    plot_helper.generate_runtime_plots(Case_Options.time_df, output_dir=output_dir, assemble=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate statistic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_post_process and process_3d_case:\n",
    "\n",
    "    file_path = os.path.join(local_dir, \"output/statistics\")\n",
    "\n",
    "    output_dir = os.path.join(img_dir, \"statistic_plots\")\n",
    "\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    plot_helper.generate_statistic_plots(file_path, output_dir=output_dir, annotate_column=\"Time step number\", assemble=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate plotting scripts\n",
    "\n",
    "Notes\n",
    "\n",
    "* A purpose to turn on is_process_pyvista_for_plot and run the processing of pyvista file is to apply clip to the domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_prepare_for_plot = True\n",
    "is_process_pyvista_for_plot = False\n",
    "\n",
    "if do_post_process and process_3d_case and is_prepare_for_plot:\n",
    "\n",
    "    from hamageolib.research.haoyuan_3d_subduction.post_process import get_trench_position_from_file, get_slab_depth_from_file,\\\n",
    "          PLOT_CASE_RUN_THD, ProcessVtuFileThDStep\n",
    "    from hamageolib.research.mow_subduction.case_options import CASE_OPTIONS\n",
    "\n",
    "    # options \n",
    "    graphical_step = 142\n",
    "    n_pieces = None # None - process the whole dataset together\n",
    "                    # 16 - process piecewise\n",
    "\n",
    "    # parameters\n",
    "    ofile_list = [\"slab1.py\"]; require_base=True\n",
    "    time_range = None\n",
    "    time_interval = None\n",
    "    # turn on plot_axis if I want to save a complete result\n",
    "    # turn off if I want to prepare for figures in a paper\n",
    "    plot_axis = False\n",
    "    slices=None # specify steps\n",
    "    # step = \"auto\"; slices=3  # auto-figure out the steps, take the numebr of slices\n",
    "    max_velocity = -1.0  # rescale the color for velocity\n",
    "    rotation_plus = 0.47 # rotation of the frame along the lon when making plot\n",
    "    da_range = [-1e8, 1e8] # range of dynamic pressures\n",
    "    do_clip = True # turn this off to plot the whole mantle (needs to generate new pyvista outputs)\n",
    "\n",
    "    # Initiate plotting class\n",
    "    # PlotCaseRunThD = PLOT_CASE_RUN_THD(local_dir, time_range=time_range, run_visual=False,\\\n",
    "            # time_interval=time_interval, visualization=\"paraview\", step=graphical_step, plot_axis=plot_axis, max_velocity=max_velocity,\\\n",
    "                    # rotation_plus=rotation_plus, ofile_list=ofile_list, require_base=require_base)\n",
    "    Case_Options = CASE_OPTIONS(local_dir)\n",
    "    Case_Options.Interpret(time_range=time_range, run_visual=False,\\\n",
    "                            time_interval=time_interval, visualization=\"paraview\", step=graphical_step, plot_axis=plot_axis, max_velocity=max_velocity,\\\n",
    "                    rotation_plus=rotation_plus, ofile_list=ofile_list, require_base=require_base)\n",
    "    Case_Options.SummaryCaseVtuStep(os.path.join(local_dir, \"summary.csv\"))\n",
    "\n",
    "\n",
    "    # Processing pyvista\n",
    "    extract_trench_at_additional_depths = [50e3]\n",
    "    # extract_trench_at_additional_depths = [10e3]\n",
    "    # extract_trench_at_additional_depths = [0.0]\n",
    "    # pyvista_outdir = os.path.join(local_dir, \"pyvista_outputs\", \"%05d\" % vtu_step)\n",
    "    if is_process_pyvista_for_plot:\n",
    "        pvtu_step = graphical_step + int(Case_Options.options['INITIAL_ADAPTIVE_REFINEMENT'])\n",
    "        ProcessVtuFileThDStep(local_dir, pvtu_step, Case_Options, do_clip=do_clip, extract_trench_at_additional_depths=extract_trench_at_additional_depths,\\\n",
    "                              n_pieces=n_pieces)\n",
    "\n",
    "    # get initial trench position    \n",
    "    pyvista_outdir0 = os.path.join(local_dir, \"pyvista_outputs\", \"%05d\" % int(Case_Options.options['INITIAL_ADAPTIVE_REFINEMENT']))\n",
    "    try:\n",
    "        trench_center_ini = get_trench_position_from_file(pyvista_outdir0, int(Case_Options.options['INITIAL_ADAPTIVE_REFINEMENT']), Case_Options.options['GEOMETRY'])\n",
    "    except FileNotFoundError:\n",
    "        trench_center_ini = -1.0\n",
    "\n",
    "    # Generate paraview script\n",
    "    # Get time \n",
    "    idx = Case_Options.summary_df[\"Vtu step\"] == graphical_step\n",
    "    _time = Case_Options.summary_df.loc[idx, \"Time\"].values[0]\n",
    "    # get trench center\n",
    "    pvtu_step = graphical_step + int(Case_Options.options['INITIAL_ADAPTIVE_REFINEMENT']) \n",
    "    pyvista_outdir = os.path.join(local_dir, \"pyvista_outputs\", \"%05d\" % pvtu_step)\n",
    "    trench_center = get_trench_position_from_file(pyvista_outdir, pvtu_step, Case_Options.options['GEOMETRY'], trench_depth=50e3)\n",
    "    slab_depth = get_slab_depth_from_file(pyvista_outdir, pvtu_step, Case_Options.options['GEOMETRY'], float(Case_Options.options['OUTER_RADIUS']), \"sp_lower\")\n",
    "    # generate paraview script\n",
    "    Case_Options.options[\"FOO00\"] = 1 # this turns on the contour of eq_trans\n",
    "    Case_Options.options[\"FOO01\"] = 1 # this turns on the contour of 725 C\n",
    "    additional_options = {\"TRENCH_CENTER\": trench_center, \"TRENCH_INI_DERIVED\": trench_center_ini, \"PLOT_TIME\": _time, \"DA_RANGE\": str(da_range),\\\n",
    "                         \"FOO00\": 1, \"FOO01\":1, \"PLOT_TYPES\": [\"slab_3d\"]}\n",
    "    \n",
    "    # PlotCaseRunThD.GenerateParaviewScript(ofile_list, addtional_options)\n",
    "    # animation = kwargs.get(\"animation\", False)\n",
    "    # require_base = self.kwargs.get('require_base', True)\n",
    "    for ofile_base in ofile_list:\n",
    "        # Different file name if make animation\n",
    "        ofile = os.path.join(local_dir, 'paraview_scripts', ofile_base)\n",
    "        # Read base file\n",
    "        paraview_script = os.path.join(SCRIPT_DIR, 'paraview_scripts',\"ThDSubduction\", ofile_base)\n",
    "        paraview_base_script = os.path.join(SCRIPT_DIR, 'paraview_scripts', 'base.py')  # base.py : base file\n",
    "        Case_Options.read_contents(paraview_base_script, paraview_script)  # this part combines two scripts\n",
    "        # Update additional options\n",
    "        Case_Options.options.update(additional_options)\n",
    "        # Generate scripts\n",
    "        Case_Options.substitute()  # substitute keys in these combined file with values determined by Interpret() function\n",
    "        ofile_path = Case_Options.save(ofile, relative=False)  # save the altered script\n",
    "        print(\"\\t File generated: %s\" % ofile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automazed workflow to finalize visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalize_visual = True\n",
    "\n",
    "if do_post_process and process_3d_case and finalize_visual:\n",
    "\n",
    "    from hamageolib.research.haoyuan_2d_subduction.workflow_scripts import finalize_visualization_2d_12172024\n",
    "    from hamageolib.research.haoyuan_3d_subduction.post_process import finalize_visualization_2d_07222025_box\n",
    "\n",
    "    _time = 1.4255e+07\n",
    "    \n",
    "    # file types\n",
    "    file_name = \"slice_center_viscosity\"\n",
    "\n",
    "    max_depth = \"1000\"  # 1000, 1300, or 1500\n",
    "\n",
    "    if file_name in [\"slice_center_viscosity\", \"T\", \"slice_center_density\", \"slice_center_mow\", \"slice_center_meta_grain_size\"]:\n",
    "        if Case_Options.options[\"GEOMETRY\"] == \"chunk\":\n",
    "            if max_depth == \"1000\":\n",
    "                frame_png_file_with_ticks = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/upper_mantle_frame_12172024_trans_modified-01.png\"\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "            output_image_file = finalize_visualization_2d_12172024(local_dir, file_name, _time, frame_png_file_with_ticks, add_time=False)\n",
    "        else:\n",
    "            if max_depth == \"1000\":\n",
    "                frame_png_file_with_ticks = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/upper_mantle_frame_07222025_trans_modified_box-01.png\"\n",
    "                output_image_file = finalize_visualization_2d_07222025_box(local_dir, file_name, _time, frame_png_file_with_ticks, add_time=False)\n",
    "            elif max_depth == \"1300\":\n",
    "                frame_png_file_with_ticks = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/upper_mantle_frame_07222025_trans_modified_box_1300-01.png\"\n",
    "                output_image_file = finalize_visualization_2d_07222025_box(local_dir, file_name, _time, frame_png_file_with_ticks, add_time=False, canvas_size=(996, 700))\n",
    "            elif max_depth == \"1500\":\n",
    "                frame_png_file_with_ticks = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/upper_mantle_frame_07222025_trans_modified_box_1500.png\"\n",
    "                output_image_file = finalize_visualization_2d_07222025_box(local_dir, file_name, _time, frame_png_file_with_ticks, add_time=False, canvas_size=(996, 800))\n",
    "            else:\n",
    "                raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_plots = True\n",
    "\n",
    "if do_post_process and combine_plots:\n",
    "    # past options\n",
    "    # compare cases with/without MOW (reference cases)\n",
    "    dirs_2d = [\n",
    "        # os.path.join(local_MOW_dir, \"mow01/C_mow_h2890.0_gr3_ar4\")\n",
    "        # os.path.join(local_MOW_dir, \"mow01/C_mow_h2890.0_M_gr3_ar4\"),\n",
    "        # os.path.join(local_MOW_dir, \"mow01/C_mow_h2890.0_M_gr3_ar4_gz_2\")\n",
    "        ]\n",
    "    dirs = [\n",
    "            #  \"/mnt/lochy/ASPECT_DATA/ThDSubduction/EBA_2d_consistent_8_6/eba3d_width80_c22_AR4_yd300\"\n",
    "    #     os.path.join(local_MOW_dir, \"mow3_00/C_mow_h2890.0_M_gr3_ar4\"),\n",
    "        os.path.join(local_MOW_dir, \"mow3_00/C_mow_h2890.0_M_gr3_ar4_gz\"), # case with low resolution in MOW\n",
    "        os.path.join(local_MOW_dir, \"mow3_00/C_mow_h2890.0_M_gr3_ar4_rf_gz\") # case with higher resolution in MOW\n",
    "    ]\n",
    "    # compare cases with different particle densities\n",
    "    # dirs_2d = [\n",
    "    #     os.path.join(local_MOW_dir, \"mow01/C_mow_h2890.0_M_gr3_ar4\"),\n",
    "    #     os.path.join(local_MOW_dir, \"mow01/C_mow_h2890.0_M_gr3_ar4_rf\"),\n",
    "    #     os.path.join(local_MOW_dir, \"mow01/C_mow_h2890.0_M_gr3_ar4_rf_1\")\n",
    "    # ]\n",
    "    # dirs = []\n",
    "\n",
    "    # Compare cases with jump at 660 and jump at 1100i\n",
    "    # Demonstrate the research idea with 7.5 km shear zozne and 1e20 Pas as\n",
    "    # Reference and vary shear zone width accordinglly. \n",
    "    # dirs_2d = [\n",
    "    #          os.path.join(local_MOW_dir, \"no_mow_sz_jump/C_mow_h2890.0_gr3_ar5_jp1100_szT7.50\"),\n",
    "    #          os.path.join(local_MOW_dir, \"no_mow_sz_jump/C_mow_h2890.0_gr3_ar5_jp1100_szV2.00e+20\"),\n",
    "    #         os.path.join(local_MOW_dir, \"no_mow_sz_jump/C_mow_h2890.0_gr3_ar5_szT7.50\"),\n",
    "    #         os.path.join(local_MOW_dir, \"no_mow_sz_jump/C_mow_h2890.0_gr3_ar5_szV2.00e+20\")\n",
    "    # ]\n",
    "    # dirs = []\n",
    "\n",
    "    # Compare cases with viscosity discontinuity at 1100i\n",
    "    # With MOW and no MOW\n",
    "    # dirs_2d = [\n",
    "    #     os.path.join(local_MOW_dir, \"no_mow_sz_jump/C_mow_h2890.0_gr3_ar5_jp1100i_szT7.50_szV5.00e+19\"),\n",
    "    #     os.path.join(local_MOW_dir, \"mow01/C_mow_h2890.0_M_gr3_ar5_jp1100i_szT7.50_szV5.00e+19\")\n",
    "    # ]\n",
    "    # dirs = []\n",
    "\n",
    "    # compare cases with 1000 jump, with metastable and no-metastable state\n",
    "    # dirs_2d = [\n",
    "    #     os.path.join(local_MOW_dir, \"no_mow_sz_jump/C_mow_h2890.0_gr3_ar5_jp1100i_szT7.50_szV5.00e+19_no_myd\"),\n",
    "    #     os.path.join(local_MOW_dir, \"mow01/C_mow_h2890.0_M_gr3_ar5_jp1100i_szT7.50_szV5.00e+19_no_myd\")\n",
    "    # ]\n",
    "    # dirs = []\n",
    "\n",
    "    print(\"dirs: \")\n",
    "    print(dirs)\n",
    "    print(\"dirs_2d: \")\n",
    "    print(dirs_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rates and MOW area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_plot_slab_morphology = True\n",
    "\n",
    "if do_post_process and combine_plots and is_plot_slab_morphology:\n",
    "\n",
    "    from hamageolib.research.mow_subduction.case_options import CASE_OPTIONS_TWOD, CASE_OPTIONS\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import gridspec\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    from matplotlib import rcdefaults\n",
    "\n",
    "    import hamageolib.utils.plot_helper as plot_helper\n",
    "\n",
    "    max_slab_depth = 2500e3 # m, only plot to the timestep slab dip reaches this depth\n",
    "    time_marker = None\n",
    "    factor_2d = 10\n",
    "    factor = 10\n",
    "    odir = os.path.join(local_dir_2d, \"img\")\n",
    "\n",
    "    if not os.path.isdir(odir):\n",
    "        os.mkdir(odir)\n",
    "\n",
    "    n_2d = len(dirs_2d)\n",
    "    n_3d = len(dirs)\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0\n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5  # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.8\n",
    "    line_width_scaling_multiplier = 2.0  # extra scaling multiplier for lines\n",
    "    t_lim = (0.0, 30.0)  # limit on t\n",
    "    t_tick_interval = 10.0   # tick interval along x\n",
    "    y_lim = (-5.0, 5.0)\n",
    "    y_tick_interval = 100.0  # tick interval along y\n",
    "    v_lim = (-1.5, 1.5)\n",
    "    v_level = 50  # number of levels in contourf plot\n",
    "    v_tick_interval = 0.5  # tick interval along v\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(\n",
    "        scaling_factor,\n",
    "        font_scaling_multiplier=font_scaling_multiplier,\n",
    "        legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "        line_width_scaling_multiplier=line_width_scaling_multiplier\n",
    "    )\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # Initiate figure\n",
    "    # ax - slab dip position and trench position\n",
    "    # ax_twin - slab depth\n",
    "    # ax1 - kinetics\n",
    "    # ax1_twinx - dip angle\n",
    "    # ax2 - plate and sinking velocity\n",
    "    # ax2_twinx - MOW area\n",
    "    # ax3 - 3d model\n",
    "    # ax3_twinx - MOW volume\n",
    "    fig = plt.figure(figsize=(10*scaling_factor, 10.5*scaling_factor), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(3, 2)\n",
    "    \n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    ax_twin = ax.twinx()\n",
    "    ax1 = fig.add_subplot(gs[0, 1])\n",
    "    ax1_twinx = ax1.twinx()\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    ax2_twinx = ax2.twinx()\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    ax3_twinx = ax3.twinx()\n",
    "    ax4 = fig.add_subplot(gs[2, 0])\n",
    "    ax4_twinx = ax4.twinx()\n",
    "\n",
    "    # Initiate case options\n",
    "    # Loop for 2d cases\n",
    "    for i, _dir_2d in enumerate(dirs_2d):\n",
    "        print(_dir_2d) # debug\n",
    "        Case_Options_2d = CASE_OPTIONS_TWOD(_dir_2d)\n",
    "        Case_Options_2d.Interpret()\n",
    "        geometry = Case_Options_2d.options[\"GEOMETRY\"]\n",
    "        Ro = Case_Options_2d.options[\"OUTER_RADIUS\"]\n",
    "        Case_Options_2d.SummaryCaseVtuStep(os.path.join(_dir_2d, \"summary.csv\"))\n",
    "\n",
    "        # Get plot values\n",
    "        time_2d_raw = Case_Options_2d.summary_df[\"Time\"].to_numpy()\n",
    "        trench_center_2d_raw = Case_Options_2d.summary_df[\"Trench\"].to_numpy()\n",
    "        slab_depth_2d_raw = Case_Options_2d.summary_df[\"Slab depth\"].to_numpy()\n",
    "        dip_angle_2d_raw = Case_Options_2d.summary_df[\"Dip 100\"].to_numpy()\n",
    "        mow_area_2d_raw = Case_Options_2d.summary_df[\"Mow area\"].to_numpy()\n",
    "        mow_area_slab_2d_raw = Case_Options_2d.summary_df[\"Mow area cold\"].to_numpy()\n",
    "        sp_velocity_2d_raw = Case_Options_2d.summary_df[\"Sp velocity\"].to_numpy()\n",
    "        # todo_depth\n",
    "        mow_area_slab_2d_depth_raw = Case_Options_2d.summary_df[\"Mow area cold depth\"].to_numpy()\n",
    "        T_923_depth_raw = Case_Options_2d.summary_df[\"T depth 923.15\"].to_numpy()\n",
    "        T_973_depth_raw = Case_Options_2d.summary_df[\"T depth 973.15\"].to_numpy()\n",
    "        T_1023_depth_raw = Case_Options_2d.summary_df[\"T depth 1023.15\"].to_numpy()\n",
    "\n",
    "        # mask on slab depth \n",
    "        mask0 = (slab_depth_2d_raw < max_slab_depth)\n",
    "        time_2d = time_2d_raw[mask0]\n",
    "        trench_center_2d = trench_center_2d_raw[mask0]\n",
    "        slab_depth_2d = slab_depth_2d_raw[mask0]\n",
    "        dip_angle_2d = dip_angle_2d_raw[mask0]\n",
    "        mow_area_2d = mow_area_2d_raw[mask0]\n",
    "        mow_area_slab_2d = mow_area_slab_2d_raw[mask0]\n",
    "        mow_area_slab_2d_depth = mow_area_slab_2d_depth_raw[mask0]\n",
    "        T_923_depth = T_923_depth_raw[mask0]\n",
    "        T_973_depth = T_973_depth_raw[mask0]\n",
    "        T_1023_depth = T_1023_depth_raw[mask0]\n",
    "        sp_velocity_2d = sp_velocity_2d_raw[mask0]\n",
    "\n",
    "        if geometry == \"chunk\":\n",
    "            trench_center_2d *= Ro\n",
    "\n",
    "        \n",
    "        # time range for mow depth > selected depth\n",
    "        # todo_range\n",
    "        pick_depth = 550e3\n",
    "        pick_depth_time_range = (0, 30e6)\n",
    "\n",
    "        mask_t = (time_2d > pick_depth_time_range[0]) & (time_2d < pick_depth_time_range[1])\n",
    "        time_2d_1 = time_2d[mask_t]\n",
    "        mask = (mow_area_slab_2d_depth > pick_depth) & mask_t\n",
    "        dt = np.diff(time_2d)\n",
    "        t_deeper_than_pick_depth = np.sum(dt[mask[:-1]]) # Count time intervals where depth is deeper during the interval\n",
    "        print(\"\\ttime deeper than pick depth = %.2f Ma (in between %.2f Ma to %.2f Ma)\"\\\n",
    "              % (t_deeper_than_pick_depth/1e6, time_2d_1[0]/1e6, time_2d_1[-1]/1e6))\n",
    "\n",
    "        # plot slab dip angle and trench position\n",
    "\n",
    "        Xs_2d = time_2d / 1e6\n",
    "        Ys_2d = (trench_center_2d - trench_center_2d[0]) / 1e3\n",
    "        Ys_2d_1 = slab_depth_2d / 1e3\n",
    "        dx_dy_2d = np.gradient(Ys_2d[::factor_2d], Xs_2d[::factor_2d]) / 1e3 * 1e2\n",
    "        dx_dy_2d_1 = np.gradient(Ys_2d_1[::factor_2d], Xs_2d[::factor_2d]) / 1e3 * 1e2\n",
    "        ax.plot(Xs_2d[::factor_2d], Ys_2d[::factor_2d], label=\"Trench 2d\", color=default_colors[i])\n",
    "        if i==0 and time_marker is not None:\n",
    "            ax.vlines(time_marker/1e6, linestyle=\"--\", color=\"k\", ymin=-150.0, ymax=100.0, linewidth=1)\n",
    "        ax_twin.plot(Xs_2d[::factor_2d], Ys_2d_1[::factor_2d], linestyle=\"-.\", label=\"Slab Depth 2d\", color=default_colors[i])\n",
    "\n",
    "        if i == 0:\n",
    "            lines, labels = ax.get_legend_handles_labels()\n",
    "            lines2, labels2 = ax_twin.get_legend_handles_labels()\n",
    "            ax.legend(lines + lines2, labels + labels2, loc=\"upper right\")\n",
    "\n",
    "        # plot velocity and dip angle\n",
    "\n",
    "        ax1.plot(Xs_2d[::factor_2d], dx_dy_2d, label=\"Trench Velocity 2d\", color=default_colors[i])\n",
    "        # ax1.plot(Xs_2d[::factor_2d], sp_velocity_2d[::factor_2d]*100.0, label=\"Sp Velocity 2d\", color=default_colors[i], linewidth=3)\n",
    "        ax1.plot(Xs_2d[::factor_2d], dx_dy_2d_1, linestyle=\"-.\", label=\"Sinking Velocity 2d\", color=default_colors[i])\n",
    "        \n",
    "        ax1_twinx.plot(Xs_2d[::factor_2d], dip_angle_2d[::factor_2d]*180.0/np.pi, label=\"Dip 100 2d\", linestyle=\"--\", color=default_colors[i])\n",
    "\n",
    "        if i == 0:\n",
    "            lines, labels = ax1.get_legend_handles_labels()\n",
    "            lines2, labels2 = ax1_twinx.get_legend_handles_labels()\n",
    "            ax1.legend(lines + lines2, labels + labels2, loc=\"upper right\")\n",
    "        \n",
    "        # plot velocity and mow area\n",
    "        # ax2.plot(Xs_2d[::factor_2d], dx_dy_2d_1, linestyle=\"-.\", label=\"Sinking Velocity 2d\", color=default_colors[i])\n",
    "        ax2.plot(Xs_2d[::factor_2d], sp_velocity_2d[::factor_2d]*100.0, label=\"Sp Velocity 2d\", color=default_colors[i], linewidth=1)\n",
    "        \n",
    "        # ax2_twinx.plot(Xs_2d[::factor_2d], mow_area_2d[::factor_2d]/1e6, label=\"MOW Area, 2d\", linestyle=\"-\", color=default_colors[i], linewidth=3)\n",
    "        ax2_twinx.plot(Xs_2d[::factor_2d], mow_area_slab_2d[::factor_2d]/1e6, label=\"MOW Area in slab, 2d\", linestyle=\"-\", color=default_colors[i], linewidth=2)\n",
    "\n",
    "        # todo_depth \n",
    "        ax4.plot(Xs_2d[::factor_2d], sp_velocity_2d[::factor_2d]*100.0, label=\"Sp Velocity 2d\", color=default_colors[i], linewidth=1)\n",
    "        ax4_twinx.plot(Xs_2d[::factor_2d], mow_area_slab_2d_depth[::factor_2d]/1e3, label=\"MOW Depth in slab, 2d\", linestyle=\"-\", color=default_colors[i], linewidth=2)\n",
    "        ax4_twinx.plot(Xs_2d[::factor_2d], T_923_depth[::factor_2d]/1e3, label=\"T 923 Depth in slab, 2d\", linestyle=\"--\", color=default_colors[i], linewidth=1)\n",
    "        ax4_twinx.plot(Xs_2d[::factor_2d], T_973_depth[::factor_2d]/1e3, label=\"T 973 Depth in slab, 2d\", linestyle=\"--\", color=default_colors[i], linewidth=1)\n",
    "        ax4_twinx.plot(Xs_2d[::factor_2d], T_1023_depth[::factor_2d]/1e3, label=\"T 1023 Depth in slab, 2d\", linestyle=\"--\", color=default_colors[i], linewidth=1)\n",
    "\n",
    "        if i == 0:\n",
    "            lines, labels = ax2.get_legend_handles_labels()\n",
    "            lines2, labels2 = ax2_twinx.get_legend_handles_labels()\n",
    "            ax2.legend(lines + lines2, labels + labels2, loc=\"upper right\")\n",
    "\n",
    "\n",
    "    # Loop for 3d cases\n",
    "    for i, _dir in enumerate(dirs):\n",
    "        Case_Options = CASE_OPTIONS(_dir)\n",
    "        Case_Options.Interpret()\n",
    "        geometry = Case_Options.options[\"GEOMETRY\"]\n",
    "        Ro = Case_Options.options[\"OUTER_RADIUS\"]\n",
    "        Case_Options.SummaryCaseVtuStep(os.path.join(_dir, \"summary.csv\"))\n",
    "\n",
    "        # Get plot values\n",
    "        # todo_3d\n",
    "        time_raw = Case_Options.summary_df[\"Time\"].to_numpy()\n",
    "        trench_center_raw = Case_Options.summary_df[\"Trench (center)\"].to_numpy()\n",
    "        slab_depth_raw = Case_Options.summary_df[\"Slab depth\"].to_numpy()\n",
    "        dip_angle_raw = Case_Options.summary_df[\"Dip 100 (center)\"].to_numpy()\n",
    "        mow_volume_raw = Case_Options.summary_df[\"MOW volume\"].to_numpy()\n",
    "        mow_volume_slab_raw = Case_Options.summary_df[\"MOW volume cold\"].to_numpy()\n",
    "        mow_area_raw = Case_Options.summary_df[\"Mow area center\"].to_numpy()\n",
    "        mow_area_slab_raw = Case_Options.summary_df[\"Mow area cold center\"].to_numpy()\n",
    "        sp_velocity_raw = Case_Options.summary_df[\"Sp velocity\"].to_numpy()\n",
    "\n",
    "        # mask on slab depth \n",
    "        mask0 = (slab_depth_raw < max_slab_depth)\n",
    "        _time = time_raw[mask0]\n",
    "        trench_center = trench_center_raw[mask0]\n",
    "        slab_depth = slab_depth_raw[mask0]\n",
    "        dip_angle = dip_angle_raw[mask0]\n",
    "        mow_area = mow_area_raw[mask0]\n",
    "        mow_area_slab = mow_area_slab_raw[mask0]\n",
    "        mow_volume = mow_volume_raw[mask0]\n",
    "        mow_volume_slab = mow_volume_slab_raw[mask0]\n",
    "        sp_velocity = sp_velocity_raw[mask0]\n",
    "\n",
    "        if geometry == \"chunk\":\n",
    "            trench_center *= Ro\n",
    "\n",
    "        # plot slab dip angle and trench position\n",
    "        Xs = _time / 1e6\n",
    "        Ys = (trench_center - trench_center[0]) / 1e3\n",
    "        Ys_1 = slab_depth / 1e3\n",
    "        dx_dy = np.gradient(Ys[::factor], Xs[::factor]) / 1e3 * 1e2\n",
    "        dx_dy_1 = np.gradient(Ys_1[::factor], Xs[::factor]) / 1e3 * 1e2\n",
    "        ax.plot(Xs[::factor], Ys[::factor], label=\"Trench (%d)\" % i, color=default_colors[i+n_2d])\n",
    "        if i==0 and time_marker is not None:\n",
    "            ax.vlines(time_marker/1e6, linestyle=\"--\", color=\"k\", ymin=-150.0, ymax=100.0, linewidth=1)\n",
    "        ax_twin.plot(Xs[::factor], Ys_1[::factor], linestyle=\"-.\", label=\"Slab Depth\", color=default_colors[i+n_2d])\n",
    "\n",
    "        if i == 0:\n",
    "            lines, labels = ax.get_legend_handles_labels()\n",
    "            lines2, labels2 = ax_twin.get_legend_handles_labels()\n",
    "            ax.legend(lines + lines2, labels + labels2, loc=\"upper right\")\n",
    "\n",
    "        # plot velocity and dip angle\n",
    "\n",
    "        ax1.plot(Xs[::factor], dx_dy, label=\"Trench Velocity\", color=default_colors[i+n_2d])\n",
    "        # ax1.plot(Xs[::factor], sp_velocity[::factor]*100.0, label=\"Sp Velocity\", color=default_colors[i+n_2d], linewidth=3)\n",
    "        ax1.plot(Xs[::factor], dx_dy_1, linestyle=\"-.\", label=\"Sinking Velocity\", color=default_colors[i+n_2d])\n",
    "        \n",
    "        # ax1_twinx.plot(Xs[::factor], dip_angle[::factor]*180.0/np.pi, label=\"Dip 100\", linestyle=\"--\", color=default_colors[i+n_2d])\n",
    "\n",
    "        # plot velocity and mow area\n",
    "\n",
    "        # ax2.plot(Xs[::factor], dx_dy_1, linestyle=\"-.\", label=\"Sinking Velocity\", color=default_colors[i+n_2d])\n",
    "        ax2.plot(Xs[::factor], sp_velocity[::factor]*100.0, label=\"Sp Velocity\", linestyle=\"-\", color=default_colors[i+n_2d], linewidth=1)\n",
    "        \n",
    "        ax2_twinx.plot(Xs[::factor], mow_area_slab[::factor]/1e6, label=\"MOW Area in slab\", linestyle=\"-\", color=default_colors[i+n_2d], linewidth=2)\n",
    "\n",
    "        # plot velocity and mow volume \n",
    "        ax3.plot(Xs[::factor], dx_dy_1, linestyle=\"-.\", label=\"Sinking Velocity\", color=default_colors[i+n_2d])\n",
    "        ax3.plot(Xs[::factor], sp_velocity[::factor]*100.0, label=\"Sp Velocity\", color=default_colors[i+n_2d], linewidth=3)\n",
    "        \n",
    "        ax3_twinx.plot(Xs[::factor], mow_volume_slab[::factor]/1e9, label=\"MOW Volume in slab\", linestyle=\"-\", color=default_colors[i+n_2d], linewidth=2)\n",
    "\n",
    "\n",
    "    # configuration of figures\n",
    "    ax.set_xlim(t_lim)\n",
    "    ax.set_ylim([-800.0, 200.0])\n",
    "    ax_twin.set_ylim([0, 2500.0])\n",
    "    ax.set_xlabel(\"Time (Ma)\")\n",
    "    ax.set_ylabel(\"Trench (km)\")\n",
    "    ax.grid()\n",
    "\n",
    "    # show the legend of the first axis\n",
    "    ax.legend()\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    for spine in ax_twin.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(t_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(t_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(200.0))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(200.0/(n_minor_ticks+1)))\n",
    "    ax_twin.yaxis.set_major_locator(MultipleLocator(500.0))\n",
    "    ax_twin.yaxis.set_minor_locator(MultipleLocator(500.0/(n_minor_ticks+1)))\n",
    "\n",
    "    ax1.set_xlim(t_lim)\n",
    "    ax1.set_ylim([-5.0, 20.0])\n",
    "    ax1.set_xlabel(\"Time (Ma)\")\n",
    "    ax1.set_ylabel(\"Velocity (cm/yr)\")\n",
    "    ax1.grid()\n",
    "\n",
    "    ax1.xaxis.set_major_locator(MultipleLocator(t_tick_interval))\n",
    "    ax1.xaxis.set_minor_locator(MultipleLocator(t_tick_interval/(n_minor_ticks+1)))\n",
    "    ax1.yaxis.set_major_locator(MultipleLocator(5.0))\n",
    "    ax1.yaxis.set_minor_locator(MultipleLocator(5.0/(n_minor_ticks+1)))\n",
    "\n",
    "    ax1_twinx.set_ylim([20.0, 70.0])\n",
    "    ax1_twinx.yaxis.set_major_locator(MultipleLocator(10.0))\n",
    "    ax1_twinx.yaxis.set_minor_locator(MultipleLocator(10.0/(n_minor_ticks+1)))\n",
    "    \n",
    "    for spine in ax1.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    for spine in ax1_twinx.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    ax2.set_xlim(t_lim)\n",
    "    ax2.set_ylim([0.0, 20.0])\n",
    "    ax2.set_xlabel(\"Time (Ma)\")\n",
    "    ax2.set_ylabel(\"Velocity (cm/yr)\")\n",
    "    ax2.grid()\n",
    "    \n",
    "    ax2.xaxis.set_major_locator(MultipleLocator(t_tick_interval))\n",
    "    ax2.xaxis.set_minor_locator(MultipleLocator(t_tick_interval/(n_minor_ticks+1)))\n",
    "    ax2.yaxis.set_major_locator(MultipleLocator(5.0))\n",
    "    ax2.yaxis.set_minor_locator(MultipleLocator(5.0/(n_minor_ticks+1)))\n",
    "\n",
    "    ax2_twinx.set_ylabel(\"MOW Area (km^2)\")\n",
    "    ax2_twinx.set_ylim([0.0, 10000.0])\n",
    "    ax2_twinx.yaxis.set_major_locator(MultipleLocator(2500.0))\n",
    "    ax2_twinx.yaxis.set_minor_locator(MultipleLocator(2500.0/(n_minor_ticks+1)))\n",
    "    \n",
    "    for spine in ax2.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    for spine in ax2_twinx.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    ax3.set_xlim(t_lim)\n",
    "    ax3.set_ylim([0.0, 20.0])\n",
    "    ax3.set_xlabel(\"Time (Ma)\")\n",
    "    ax3.set_ylabel(\"Velocity (cm/yr)\")\n",
    "    ax3.grid()\n",
    "    \n",
    "    ax3.xaxis.set_major_locator(MultipleLocator(t_tick_interval))\n",
    "    ax3.xaxis.set_minor_locator(MultipleLocator(t_tick_interval/(n_minor_ticks+1)))\n",
    "    ax3.yaxis.set_major_locator(MultipleLocator(5.0))\n",
    "    ax3.yaxis.set_minor_locator(MultipleLocator(5.0/(n_minor_ticks+1)))\n",
    "\n",
    "    ax3_twinx.set_ylabel(\"MOW Volume (km^3)\")\n",
    "    ax3_twinx.set_ylim([0.0, 8e6])\n",
    "    ax3_twinx.yaxis.set_major_locator(MultipleLocator(2e6))\n",
    "    ax3_twinx.yaxis.set_minor_locator(MultipleLocator(2e6/(n_minor_ticks+1)))\n",
    "    \n",
    "    for spine in ax3.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    for spine in ax3_twinx.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # todo_depth\n",
    "    ax4.set_xlim(t_lim)\n",
    "    ax4.set_ylim([0.0, 25.0])\n",
    "    ax4.set_xlabel(\"Time (Ma)\")\n",
    "    ax4.set_ylabel(\"Velocity (cm/yr)\")\n",
    "    ax4.grid()\n",
    "    \n",
    "    ax4.xaxis.set_major_locator(MultipleLocator(t_tick_interval))\n",
    "    ax4.xaxis.set_minor_locator(MultipleLocator(t_tick_interval/(n_minor_ticks+1)))\n",
    "    ax4.yaxis.set_major_locator(MultipleLocator(5.0))\n",
    "    ax4.yaxis.set_minor_locator(MultipleLocator(5.0/(n_minor_ticks+1)))\n",
    "\n",
    "    ax4_twinx.set_ylabel(\"MOW Depth (km)\")\n",
    "    ax4_twinx.set_ylim([300.0, 800.0])\n",
    "    ax4_twinx.yaxis.set_major_locator(MultipleLocator(100.0))\n",
    "    ax4_twinx.yaxis.set_minor_locator(MultipleLocator(100.0/(n_minor_ticks+1)))\n",
    "    \n",
    "    for spine in ax4.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "    for spine in ax4_twinx.spines.values():\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # save figure\n",
    "    filepath = os.path.join(odir, \"slab_morphology.pdf\")\n",
    "    fig.savefig(filepath)\n",
    "    print(\"Saved figure: \", filepath)\n",
    "    filepath_png = os.path.join(odir, \"slab_morphology.png\")\n",
    "    fig.savefig(filepath_png)\n",
    "    print(\"Saved figure: \", filepath_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-d Case\n",
    "\n",
    "#### Read data\n",
    "In this block:\n",
    "  * Use vtk package to read from vtu files (need to set the snapshot, e.g. 49)\n",
    "  * Convert data (coordinates and fields) to numpy array\n",
    "  * initiate interpolators (Here we give the example of T, P and resolution, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_diagram_2d = False\n",
    "\n",
    "if do_post_process and check_diagram_2d:\n",
    "\n",
    "    # Options:\n",
    "    # step - the step to plot (step where visualization is generated)\n",
    "    step = 100\n",
    "\n",
    "    # Import module\n",
    "    import vtk\n",
    "    from vtk.util.numpy_support import vtk_to_numpy\n",
    "    from hamageolib.utils.vtk_utilities import calculate_resolution\n",
    "    import time\n",
    "    from scipy.interpolate import LinearNDInterpolator\n",
    "    from hamageolib.research.mow_subduction.case_options import CASE_OPTIONS_TWOD\n",
    "\n",
    "    # Case options\n",
    "    Case_Options_2d = CASE_OPTIONS_TWOD(local_dir_2d)\n",
    "    Case_Options_2d.Interpret()\n",
    "    Case_Options_2d.SummaryCaseVtuStep(os.path.join(local_dir_2d, \"summary.csv\"))\n",
    "\n",
    "    # Find vtu file\n",
    "    pvtu_step = step + int(Case_Options_2d.options['INITIAL_ADAPTIVE_REFINEMENT'])\n",
    "    pvtu_file = os.path.join(local_dir_2d, \"output\", \"solution\", \"solution-%05d.pvtu\" % pvtu_step)\n",
    "    assert(os.path.isfile(pvtu_file))\n",
    "\n",
    "    # Read the pvtu file\n",
    "    start = time.time()\n",
    "\n",
    "    reader = vtk.vtkXMLPUnstructuredGridReader()\n",
    "    reader.SetFileName(pvtu_file)\n",
    "    reader.Update()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Initiating reader takes %.2e s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Get the output data from the reader\n",
    "    grid = reader.GetOutput()  # Access the unstructured grid\n",
    "    data_set = reader.GetOutputAsDataSet()  # Access the dataset representation\n",
    "    points = grid.GetPoints()  # Extract the points (coordinates)\n",
    "    cells = grid.GetCells()  # Extract the cell connectivity information\n",
    "    point_data = data_set.GetPointData()  # Access point-wise data\n",
    "\n",
    "    n_points = grid.GetNumberOfPoints() # Number of points and cells\n",
    "    n_cells = grid.GetNumberOfCells()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Reading files takes %.2e s\" % (end - start))\n",
    "    print(f\"\\tNumber of points: {n_points}\")\n",
    "    print(f\"\\tNumber of cells: {n_cells}\")\n",
    "    print(\"\\tAvailable point data fields:\")\n",
    "    for i in range(point_data.GetNumberOfArrays()):\n",
    "        # Field names in point data\n",
    "        name = point_data.GetArrayName(i)\n",
    "        print(f\"\\t  - {name}\")\n",
    "    start = end\n",
    "\n",
    "    # Convert data to numpy array\n",
    "    # Get coordinates (points)\n",
    "    # Get field \"T\"\n",
    "\n",
    "    vtk_points = grid.GetPoints().GetData()\n",
    "    points_np = vtk_to_numpy(vtk_points)  # Shape: (n_points, 3)\n",
    "    points_2d = points_np[:, :2]  # Use only the first two columns for 2D coordinates\n",
    "\n",
    "    # Initialize dictionary for interpolators\n",
    "    interpolators = {}\n",
    "\n",
    "    # Loop over all arrays in point data\n",
    "    num_arrays = point_data.GetNumberOfArrays()\n",
    "    for i in range(num_arrays):\n",
    "        array_name = point_data.GetArrayName(i)\n",
    "        vtk_array = point_data.GetArray(i)\n",
    "        \n",
    "        if vtk_array is None:\n",
    "            print(f\"Warning: Array {array_name} is None, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Convert VTK array to NumPy\n",
    "        np_array = vtk_to_numpy(vtk_array)\n",
    "        \n",
    "        # Create interpolator and add to dict\n",
    "        interpolators[array_name] = LinearNDInterpolator(points_2d, np_array, fill_value=np.nan)\n",
    "\n",
    "    # Calculate resolution for each cell or point in the grid\n",
    "    resolution_np = calculate_resolution(grid)  # Custom function (not defined here)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Calculating resolution takes %.2e s\" % (end - start))\n",
    "    start = end\n",
    "\n",
    "    # Create interpolators for temperature, pressure, and resolution\n",
    "    interpolators[\"resolution\"] = LinearNDInterpolator(points_2d, resolution_np)  # Interpolator for resolution\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Construct linear ND interpolator takes %.2e s\" % (end - start))\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate grid\n",
    "\n",
    "Next use the interpolator we have to generate a grid to plot\n",
    "\n",
    "- Note the interval is defined by meter\n",
    "- xs and ys are generate with slightly different interval, therefore we always get different number of nodes along x and y, making it easier to debug (It's generally easier when a 2-d array have different sizes along the 2 dimensions, that you can easier tell which is which.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_post_process and check_diagram_2d:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Define the interval for the grid (in meters)\n",
    "    interval = 10e3\n",
    "\n",
    "    # Determine the bounding box of the 2D points\n",
    "    x_min, y_min = np.min(points_2d, axis=0)\n",
    "    x_max, y_max = np.max(points_2d, axis=0)\n",
    "\n",
    "    # Define a regular grid within the bounding box\n",
    "    # allow a little different in interval in x\n",
    "    # and y axis, thereform making the two dimensions\n",
    "    # unequal to make fewer mistakes ...\n",
    "    xs = np.arange(x_min, x_max, interval*0.99)\n",
    "    ys = np.arange(y_min, y_max, interval*1.01)\n",
    "    x_grid, y_grid = np.meshgrid(xs, ys, indexing=\"ij\")  # Create a grid of (x, y) points\n",
    "\n",
    "    # Flatten the grid for interpolation\n",
    "    grid_points_2d = np.vstack([x_grid.ravel(), y_grid.ravel()]).T\n",
    "\n",
    "    # Interpolate temperature (T) values onto the regular grid\n",
    "    T_grid = interpolators[\"T\"](grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    T_grid = T_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate temperature (P) values onto the regular grid\n",
    "    P_grid = interpolators[\"p\"](grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    P_grid = P_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "    \n",
    "    # Interpolate density (density) values onto the regular grid\n",
    "    density_grid = interpolators[\"density\"](grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    density_grid = density_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "    \n",
    "    # Interpolate metastable (metastable) values onto the regular grid\n",
    "    metastable_grid = interpolators[\"metastable\"](grid_points_2d)  # Use the NearestNDInterpolator\n",
    "    metastable_grid = metastable_grid.reshape(x_grid.shape)  # Reshape back to the grid\n",
    "\n",
    "    # Interpolate resolutions onto the regular grid\n",
    "    resolutions_grid = interpolators[\"resolution\"](grid_points_2d)\n",
    "    resolutions_grid = resolutions_grid.reshape(x_grid.shape)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Interpolating to regular grid takes %.2e s\" % (end - start))\n",
    "    print(\"\\tgrid shape: (x axis, y axis): \", x_grid.shape)\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interp the results into a regular grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_post_process and check_diagram_2d:\n",
    "\n",
    "    # Load modules\n",
    "    from scipy.spatial import cKDTree\n",
    "\n",
    "    # Option\n",
    "    max_distance = 0.1  \n",
    "\n",
    "    # Get the P, T limits\n",
    "    T_min = np.min(T_grid)\n",
    "    T_max = np.max(T_grid)\n",
    "    P_min = np.min(P_grid)\n",
    "    P_max = np.max(P_grid)\n",
    "\n",
    "    # 1. Flatten input data\n",
    "    data_points = np.column_stack((T_grid.ravel()/T_max, P_grid.ravel()/P_max))\n",
    "    tree = cKDTree(data_points)\n",
    "    metastable_values = metastable_grid.ravel()\n",
    "\n",
    "    # 2. Create a regular grid\n",
    "    T_lin = np.linspace(T_min/T_max, 1.0, 300)\n",
    "    P_lin = np.linspace(P_min/P_max, 1.0, 300)\n",
    "    T_reg, P_reg = np.meshgrid(T_lin, P_lin)\n",
    "    grid_points = np.column_stack((T_reg.ravel(), P_reg.ravel()))\n",
    "\n",
    "    # 3. Interpolate the data\n",
    "    # Nearest neighbor interpolation\n",
    "    distances, indices = tree.query(grid_points, k=1)\n",
    "    mask = distances <= max_distance\n",
    "    metastable_interp_flat = np.full(grid_points.shape[0], np.nan)\n",
    "    metastable_interp_flat[mask] = metastable_values[indices[mask]]\n",
    "    metastable_interp = metastable_interp_flat.reshape(T_reg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the P, T diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_post_process and check_diagram_2d:\n",
    "\n",
    "    # Load modules\n",
    "    from cmcrameri import cm as ccm\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # Example usage\n",
    "    # Rule of thumbs:\n",
    "    # 1. Set the limit to something like 5.0, 10.0 or 50.0, 100.0 \n",
    "    # 2. Set five major ticks for each axis\n",
    "    scaling_factor = 1.0  # scale factor of plot\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "\n",
    "    T_lim = (400.0, 1800.0) # T (K)\n",
    "    T_level = 50  # number of levels in contourf plot\n",
    "    T_tick_interval = 200.0  # tick interval along v\n",
    "\n",
    "    T_lim1 = (0.0, 800.0) # T (C), smaller scale\n",
    "    T_tick_interval1 = 200.0  # tick interval along x\n",
    "\n",
    "    P_lim = (10.0, 30.0) # P (Gpa)\n",
    "    P_level = 50  # number of levels in contourf plot\n",
    "    P_tick_interval = 5.0  # tick interval along v\n",
    "\n",
    "    density_lim = (3000.0, 4000.0)\n",
    "    density_level = 50  # number of levels in contourf plot\n",
    "    density_tick_interval = 100.0  # tick interval along P\n",
    "\n",
    "    metastable_lim = (0.0, 1.0) # metastable contents\n",
    "    metastable_level = 100\n",
    "    metastable_interval = 0.2\n",
    "\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    # Create a figure\n",
    "    fig = plt.figure(figsize=(10, 8), tight_layout=True)\n",
    "    gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "    # Plot the diagram of metastable composition\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    ticks=np.arange(metastable_lim[0], metastable_lim[1], metastable_interval)\n",
    "\n",
    "    color_map = ax.pcolormesh(T_grid, P_grid/1e9, metastable_grid,\\\n",
    "                             vmin=metastable_lim[0], vmax=metastable_lim[1], cmap=\"viridis\")\n",
    "\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"Metastable\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_xlim(T_lim)\n",
    "    ax.set_ylim(P_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(T_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(T_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(P_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(P_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_xlabel(\"T (K)\")\n",
    "    ax.set_ylabel(\"P (GPa)\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Plot the diagram of density\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    ticks=np.arange(density_lim[0], density_lim[1], density_tick_interval)\n",
    "\n",
    "    color_map = ax.pcolormesh(T_grid, P_grid/1e9, density_grid,\\\n",
    "                            vmin=density_lim[0], vmax=density_lim[1], cmap=ccm.batlow)\n",
    "\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"Density\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_xlim(T_lim)\n",
    "    ax.set_ylim(P_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(T_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(T_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(P_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(P_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_xlabel(\"T (K)\")\n",
    "    ax.set_ylabel(\"P (GPa)\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # Plot the diagram of interpolated metastable composition\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "    ticks=np.arange(metastable_lim[0], metastable_lim[1], metastable_interval)\n",
    "\n",
    "    color_map = ax.pcolormesh(T_reg*T_max, P_reg*P_max/1e9, metastable_interp,\\\n",
    "                             vmin=metastable_lim[0], vmax=metastable_lim[1], cmap=\"viridis\")\n",
    "\n",
    "    cbar = fig.colorbar(color_map, ax=ax, label=\"Metastable\")  # Add colorbar\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    ax.set_xlim(T_lim)\n",
    "    ax.set_ylim(P_lim)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(T_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(T_tick_interval/(n_minor_ticks+1)))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(P_tick_interval))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(P_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_xlabel(\"T (K)\")\n",
    "    ax.set_ylabel(\"P (GPa)\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        # Adjust spine thickness for this plot\n",
    "        spine.set_linewidth(0.5 * scaling_factor * line_width_scaling_multiplier)\n",
    "\n",
    "    # ofile = os.path.join(case_dir, \"metastable_diagram_nrep_%d_vstep_%05d.pdf\" % (n_repetition, vtu_step))\n",
    "    # fig.savefig(ofile)\n",
    "    # print(\"saved figure %s\" % ofile)\n",
    "    \n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-d case, basic\n",
    "\n",
    "Note: Here we need to first generate scripts for making plot. Then we run them in terminals. It's only all these figures are generated that the final animation could be assembled. In practice, we need to run this section for a couple of times.\n",
    "\n",
    "List of task list\n",
    "- \"TRENCH_CENTER\": modify with real trench location, so that the triangle will show up at the right location\n",
    "- Finalizing results from paraview: use frames with ticks\n",
    "- Assemble animation: assemble colorbars for plots as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "# animate_2d_case_basic - top-level control\n",
    "# debug_step0_animate_2d_case_basic - only run step 0 to debug\n",
    "# generate_paraview_scripts_for_animate_2d_case_basic - generate paraview scripts stepwise\n",
    "animate_2d_case_basic = False\n",
    "debug_step0_animate_2d_case_basic = False\n",
    "generate_paraview_scripts_for_animate_2d_case_basic = True\n",
    "\n",
    "if animate_2d_case_basic:\n",
    "    \n",
    "    from hamageolib.research.mow_subduction.case_options import CASE_OPTIONS_TWOD\n",
    "    from hamageolib.research.haoyuan_3d_subduction.post_process import ProcessVtuFileTwoDStep\n",
    "\n",
    "    # Assign a time interval for animation\n",
    "    time_interval = 0.5e6\n",
    "    animation_name= \"ani_basic\"\n",
    "    max_depth = \"1500\"\n",
    "\n",
    "    # Apply case options\n",
    "    Case_Options_2d = CASE_OPTIONS_TWOD(local_dir_2d)\n",
    "    Case_Options_2d.Interpret()\n",
    "    Case_Options_2d.SummaryCaseVtuStep(os.path.join(local_dir_2d, \"summary.csv\"))\n",
    "    Case_Options_2d.SummaryCaseVtuStepExport(os.path.join(local_dir_2d, \"summary.csv\"))\n",
    "    resampled_df = Case_Options_2d.resample_visualization_df(time_interval)\n",
    "    graphical_steps = resampled_df[\"Vtu step\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate paraview scripts stepwise\n",
    "\n",
    "This is an optional step to generate stepwise paraview scripts (controlled by generate_paraview_scripts_for_animate_2d_case_basic).\n",
    "After this step: run the py_temp_foo.py in a terminal to generate visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop the time steps to get things done \n",
    "if animate_2d_case_basic and generate_paraview_scripts_for_animate_2d_case_basic: \n",
    "\n",
    "    # Open py_temp_file for output\n",
    "    fout = open(py_temp_file, 'w')\n",
    "    assert(fout)\n",
    "    fout.write(\"#!/bin/bash\\n\")\n",
    "\n",
    "    # Run stepwise\n",
    "    print(\"Start generating paraview scripts\")\n",
    "    for i, _time in enumerate(resampled_df[\"Time\"].values):\n",
    "\n",
    "        # debug run step 0\n",
    "        if debug_step0_animate_2d_case_basic:\n",
    "            if i > 0:\n",
    "                break\n",
    "\n",
    "        # Stepwise configurations \n",
    "        _time = resampled_df[\"Time\"].values[i]\n",
    "        time_rounded = round(_time / float(resampled_df.attrs[\"Time between graphical output\"]))\\\n",
    "              * float(resampled_df.attrs[\"Time between graphical output\"])\n",
    "        step = graphical_steps[i]\n",
    "        print(\"\\tGenerating paraview scripts for step = %d, time = %.4e\" % (step, time_rounded))\n",
    "\n",
    "        # Assign the script to use\n",
    "        py_script = \"slab1.py\"\n",
    "\n",
    "        # Make the directory to hold the scripts\n",
    "        ps_dir = os.path.join(local_dir_2d, 'paraview_scripts')\n",
    "        if not os.path.isdir(ps_dir):\n",
    "            os.mkdir(ps_dir) \n",
    "        odir = os.path.join(ps_dir, \"stepwise\")\n",
    "        if not os.path.isdir(odir):\n",
    "            os.mkdir(odir)\n",
    "\n",
    "        # Apply stepwise configuration\n",
    "        Case_Options_2d.options['GRAPHICAL_STEPS'] = [step]\n",
    "        Case_Options_2d.options['GRAPHICAL_TIMES'] = [time_rounded]\n",
    "        Case_Options_2d.options[\"TRENCH_CENTER\"] = -1.0 # modify with real trench location\n",
    "        Case_Options_2d.options[\"FOO00\"] = 1 # this turns on the contour of eq_trans\n",
    "        Case_Options_2d.options[\"FOO01\"] = 1 # this turns on the contour of 725 C\n",
    "        Case_Options_2d.options[\"FOO02\"] = 1 # this turns on the metastable area\n",
    "        Case_Options_2d.options[\"FOO03\"] = 1 # this turns on the metastable area in the slab\n",
    "        Case_Options_2d.options[\"DA_RANGE\"] = \"[-1e8, 1e8]\"\n",
    "        Case_Options_2d.options[\"PLOT_TYPES\"] = [\"upper_mantle\"]\n",
    "        if max_depth == \"1500\":\n",
    "            Case_Options_2d.options[\"MAX_PLOT_DEPTH_IN_SLICE\"] = 1500e3\n",
    "        ofile = os.path.join(odir, 'slab_%d.py' % (step))\n",
    "        paraview_script = os.path.join(SCRIPT_DIR, 'paraview_scripts', 'ThDSubduction', py_script)\n",
    "        paraview_script_base = os.path.join(SCRIPT_DIR, 'paraview_scripts', 'base.py')\n",
    "        Case_Options_2d.read_contents(paraview_script_base, paraview_script)\n",
    "\n",
    "        # Save script\n",
    "        Case_Options_2d.substitute()\n",
    "        Case_Options_2d.save(ofile)\n",
    "\n",
    "        # Write to py_temp file\n",
    "        fout.write(\"pvpython %s\\n\" % ofile)\n",
    "\n",
    "    # Finish writting to py_temp file\n",
    "    fout.close()\n",
    "    subprocess.run([\"chmod\", \"+x\", py_temp_file])\n",
    "    print(\"saved file: %s\" % py_temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalize plot from paraview\n",
    "\n",
    "Note that the previous step needs to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if animate_2d_case_basic:\n",
    "\n",
    "\n",
    "    from hamageolib.research.haoyuan_2d_subduction.workflow_scripts import finalize_visualization_2d_12172024\n",
    "    from hamageolib.research.haoyuan_3d_subduction.post_process import finalize_visualization_2d_07222025_box\n",
    "\n",
    "    # file types\n",
    "    file_name_list = [\"slice_center_viscosity\", \"slice_center_temperature\", \"slice_center_density\"]\n",
    "    if Case_Options_2d.options[\"MODEL_TYPE\"] == \"mow\":\n",
    "        file_name_list += [\"slice_center_mow\"]\n",
    "        if Case_Options_2d.options[\"HAS_METASTABLE_GRAIN_SIZE\"]:\n",
    "            file_name_list += [\"slice_center_meta_x0\", \"slice_center_meta_grain_size\"]\n",
    "\n",
    "    print(\"Start Finalizing Plots\")\n",
    "    for i, _time in enumerate(resampled_df[\"Time\"].values):\n",
    "\n",
    "        # debug run step 0\n",
    "        if debug_step0_animate_2d_case_basic:\n",
    "            if i > 0:\n",
    "                break\n",
    "\n",
    "        # Stepwise configurations \n",
    "        _time = resampled_df[\"Time\"].values[i]\n",
    "        time_rounded = round(_time / float(resampled_df.attrs[\"Time between graphical output\"]))\\\n",
    "              * float(resampled_df.attrs[\"Time between graphical output\"])\n",
    "        step = graphical_steps[i]\n",
    "        print(\"\\tFinalizing plots for step = %d, time = %.4e\" % (step, time_rounded))\n",
    "\n",
    "        for file_name in file_name_list: \n",
    "            if Case_Options_2d.options[\"GEOMETRY\"] == \"chunk\":\n",
    "                if max_depth == \"1000\":\n",
    "                    frame_png_file_with_ticks = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/upper_mantle_frame_12172024_trans_modified-01.png\"\n",
    "                    output_image_file = finalize_visualization_2d_12172024(local_dir_2d, file_name, time_rounded, frame_png_file_with_ticks, add_time=False)\n",
    "                else:\n",
    "                    raise NotImplementedError()\n",
    "            else:\n",
    "                if max_depth == \"1000\":\n",
    "                    frame_png_file_with_ticks = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/upper_mantle_frame_07222025_trans_modified_box_with_frame.png\"\n",
    "                    output_image_file = finalize_visualization_2d_07222025_box(local_dir_2d, file_name, time_rounded, frame_png_file_with_ticks, add_time=False, canvas_size=(1040, 610))\n",
    "                elif max_depth == \"1300\":\n",
    "                    frame_png_file_with_ticks = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/upper_mantle_frame_07222025_trans_modified_box_1300-01.png\"\n",
    "                    output_image_file = finalize_visualization_2d_07222025_box(local_dir_2d, file_name, time_rounded, frame_png_file_with_ticks, add_time=False, canvas_size=(1040, 610))\n",
    "                elif max_depth == \"1500\":\n",
    "                    # pos_v_diff=90, test whether this is needed, needed in the 3-d slice\n",
    "                    frame_png_file_with_ticks = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/upper_mantle_frame_07222025_trans_modified_box_with_frame_1500.png\"\n",
    "                    output_image_file = finalize_visualization_2d_07222025_box(local_dir_2d, file_name, time_rounded, frame_png_file_with_ticks, add_time=False, canvas_size=(1040, 800),\\\n",
    "                                                                               pos_v_diff=90)\n",
    "                else:\n",
    "                    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assemble and make animation\n",
    "\n",
    "Using the generated figures (e.g., linear plots and finalized figures from **ParaView**):\n",
    "\n",
    "1. Assemble them stepwise and export one combined figure per step.\n",
    "2. Create an `.avi` animation from the combined figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if animate_2d_case_basic:\n",
    "\n",
    "    print(\"Start making animation\")\n",
    "\n",
    "    # Load modules\n",
    "    from hamageolib.research.haoyuan_2d_subduction.workflow_scripts import create_avi_from_images\n",
    "\n",
    "    # Initiation\n",
    "    prep_dir = os.path.join(local_dir_2d, \"img\", \"prep\")\n",
    "    ani_file_paths = [] # path of the figures\n",
    "\n",
    "    # Loop the steps to get job done\n",
    "    for i, _time in enumerate(resampled_df[\"Time\"].values):\n",
    "\n",
    "        # debug run step 0\n",
    "        if debug_step0_animate_2d_case_basic:\n",
    "            if i > 0:\n",
    "                break\n",
    "\n",
    "        # do this if there is error at the last step\n",
    "        if i == resampled_df[\"Time\"].values.size - 1:\n",
    "            break\n",
    "\n",
    "        # Stepwise configurations \n",
    "        _time = resampled_df[\"Time\"].values[i]\n",
    "        time_rounded = round(_time / float(resampled_df.attrs[\"Time between graphical output\"]))\\\n",
    "              * float(resampled_df.attrs[\"Time between graphical output\"])\n",
    "        step = graphical_steps[i]\n",
    "        print(\"\\tAssembling plots for step = %d, time = %.4e\" % (step, time_rounded))\n",
    "\n",
    "        # File paths\n",
    "        image_files = []; image_positions=[]; cropping_regions=[]; image_scale_factors=[]\n",
    "        # 0: viscosity slice\n",
    "        file_path_0 = os.path.join(prep_dir, \"%s_t%.4e.png\" % (file_name_list[0], time_rounded))\n",
    "        assert(os.path.isfile(file_path_0))\n",
    "        image_files.append(file_path_0)\n",
    "        image_positions.append((0, 100)) \n",
    "        cropping_regions.append(None)\n",
    "        image_scale_factors.append(0.9)\n",
    "        # 0: viscosity colorbar\n",
    "        file_path_0_c = \"/home/lochy/Documents/papers/documented_files/MOW/paper_dynamics/color_viscosity_19_24-01.png\"\n",
    "        assert(os.path.isfile(file_path_0_c))\n",
    "        image_files.append(file_path_0_c)\n",
    "        image_positions.append((100, 550)) \n",
    "        cropping_regions.append(None)\n",
    "        image_scale_factors.append(1.5)\n",
    "        # 1: metastable\n",
    "        file_path_1 = None\n",
    "        if Case_Options_2d.options[\"MODEL_TYPE\"] == \"mow\":\n",
    "            # 1a: metastable\n",
    "            file_path_1 = os.path.join(prep_dir, \"slice_center_mow_t%.4e.png\" % (time_rounded))\n",
    "            assert(os.path.isfile(file_path_1))\n",
    "            image_files.append(file_path_1)\n",
    "            image_positions.append((1000, 100)) \n",
    "            cropping_regions.append(None)\n",
    "            image_scale_factors.append(0.9)\n",
    "            # 1a: metastable colorbar\n",
    "            file_path_1c = \"/home/lochy/Documents/papers/documented_files/MOW/paper_dynamics/color_metastable_0_1-01.png\"\n",
    "            assert(os.path.isfile(file_path_1c))\n",
    "            image_files.append(file_path_1c)\n",
    "            image_positions.append((1100, 550)) \n",
    "            cropping_regions.append(None)\n",
    "            image_scale_factors.append(1.5)\n",
    "            # 1b: meta_x0\n",
    "            # 1c: meta_grain_size\n",
    "            if Case_Options_2d.options[\"HAS_METASTABLE_GRAIN_SIZE\"]:\n",
    "                file_path_meta_x0 = os.path.join(prep_dir, \"%s_t%.4e.png\" % (file_name_list[-2], time_rounded))\n",
    "                assert(os.path.isfile(file_path_meta_x0))\n",
    "                image_files.append(file_path_meta_x0)\n",
    "                image_positions.append((2000, 100)) \n",
    "                cropping_regions.append(None)\n",
    "                image_scale_factors.append(0.9)\n",
    "                file_path_meta_x0_c = \"/home/lochy/Documents/papers/documented_files/MOW/paper_dynamics/color_meta_x0_1_1e25-01.png\"\n",
    "                assert(os.path.isfile(file_path_meta_x0_c))\n",
    "                image_files.append(file_path_meta_x0_c)\n",
    "                image_positions.append((2100, 550)) \n",
    "                cropping_regions.append(None)\n",
    "                image_scale_factors.append(1.5)\n",
    "\n",
    "                file_path_meta_grain_size = os.path.join(prep_dir, \"%s_t%.4e.png\" % (file_name_list[-1], time_rounded))\n",
    "                assert(os.path.isfile(file_path_meta_grain_size))\n",
    "                image_files.append(file_path_meta_grain_size)\n",
    "                image_positions.append((2000, 800)) \n",
    "                cropping_regions.append(None)\n",
    "                image_scale_factors.append(0.9)\n",
    "                file_path_meta_grain_size_c = \"/home/lochy/Documents/papers/documented_files/MOW/paper_dynamics/color_meta_grain_size_1e-10_1.png\"\n",
    "                assert(os.path.isfile(file_path_meta_grain_size_c))\n",
    "                image_files.append(file_path_meta_grain_size_c)\n",
    "                image_positions.append((2100, 1250)) \n",
    "                cropping_regions.append(None)\n",
    "                image_scale_factors.append(1.5)\n",
    "\n",
    "        # 2: temperature slice\n",
    "        file_path_2 = os.path.join(prep_dir, \"%s_t%.4e.png\" % (file_name_list[1], time_rounded))\n",
    "        assert(os.path.isfile(file_path_2))\n",
    "        image_files.append(file_path_2)\n",
    "        image_positions.append((0, 800)) \n",
    "        cropping_regions.append(None)\n",
    "        image_scale_factors.append(0.9)\n",
    "        # 2: temperature colorbar\n",
    "        file_path_2_c = \"/home/lochy/Documents/papers/documented_files/MOW/paper_dynamics/color_temperature_0_2000-01.png\"\n",
    "        assert(os.path.isfile(file_path_2_c))\n",
    "        image_files.append(file_path_2_c)\n",
    "        image_positions.append((100, 1250)) \n",
    "        cropping_regions.append(None)\n",
    "        image_scale_factors.append(1.5)\n",
    "        # 3: density slice\n",
    "        file_path_3 = os.path.join(prep_dir, \"%s_t%.4e.png\" % (file_name_list[2], time_rounded))\n",
    "        assert(os.path.isfile(file_path_3))\n",
    "        image_files.append(file_path_3)\n",
    "        image_positions.append((1000, 800)) \n",
    "        cropping_regions.append(None)\n",
    "        image_scale_factors.append(0.9)\n",
    "        # 3: density colorbar\n",
    "        file_path_3_c = \"/home/lochy/Documents/papers/documented_files/MOW/paper_dynamics/color_density_3000_4000-01.png\"\n",
    "        assert(os.path.isfile(file_path_3_c))\n",
    "        image_files.append(file_path_3_c)\n",
    "        image_positions.append((1100, 1250)) \n",
    "        cropping_regions.append(None)\n",
    "        image_scale_factors.append(1.5)\n",
    "\n",
    "        # Combine images\n",
    "        output_image_file = os.path.join(prep_dir, \"%s_t%.4e.png\" % (animation_name, _time))\n",
    "        # Remove existing output image to ensure a clean overlay\n",
    "        if os.path.isfile(output_image_file):\n",
    "            os.remove(output_image_file)\n",
    "        # Call overlay function\n",
    "        plot_helper.overlay_images_on_blank_canvas(\n",
    "            canvas_size=(3000, 1500),  # Size of the blank canvas in pixels (width, height)\n",
    "            image_files=image_files,  # List of image file paths to overlay\n",
    "            image_positions=image_positions,  # Positions of each image on the canvas\n",
    "            cropping_regions=cropping_regions,  # Optional cropping regions for the images\n",
    "            image_scale_factors=image_scale_factors,  # Scaling factors for resizing the images\n",
    "            output_image_file=output_image_file  # Path to save the final combined image\n",
    "        )\n",
    "\n",
    "        # Add time stamp\n",
    "        text = \"t = %.1f Ma\" % (time_rounded / 1e6)  # Replace with the text you want to add\n",
    "        position = (25, 0)  # Replace with the desired text position (x, y)\n",
    "        font_path = \"/usr/share/fonts/truetype/msttcorefonts/times.ttf\"  # Path to Times New Roman font\n",
    "        font_size = 56\n",
    "\n",
    "        plot_helper.add_text_to_image(output_image_file, output_image_file, text, position, font_path, font_size)\n",
    "\n",
    "        ani_file_paths.append(output_image_file)\n",
    "\n",
    "    # Generate animation\n",
    "    if not debug_step0_animate_2d_case_basic:\n",
    "        ani_dir = os.path.join(local_dir_2d, \"img\", \"animation\")\n",
    "        if not os.path.isdir(ani_dir):\n",
    "            os.mkdir(ani_dir)\n",
    "        output_file = os.path.join(local_dir_2d, \"img\", \"animation\", \"%s.avi\" % animation_name)\n",
    "        create_avi_from_images(ani_file_paths, output_file, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-d case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_3d_animation = True\n",
    "is_3d_animation_debug_first_step = False\n",
    "is_3d_animation_skip_missing_files = True\n",
    "\n",
    "if is_3d_animation:\n",
    "    from hamageolib.research.mow_subduction.case_options import CASE_OPTIONS\n",
    "    \n",
    "    assert(local_dir is not None)\n",
    "    # ani_factor = 5 # every th vtu steps\n",
    "    time_interval = 0.5e6\n",
    "\n",
    "    # utility function\n",
    "    round_values = lambda values: [round(x) for x in values]\n",
    "    \n",
    "    # case options \n",
    "    Case_Options = CASE_OPTIONS(local_dir)\n",
    "    Case_Options.Interpret()\n",
    "    Case_Options.SummaryCaseVtuStep(os.path.join(local_dir, \"summary.csv\"))\n",
    "    # all_graphical_steps = Case_Options.summary_df[\"Vtu step\"]\n",
    "    # ani_graphical_steps = all_graphical_steps[::ani_factor]\n",
    "    resampled_df = Case_Options.resample_visualization_df(time_interval)\n",
    "    ani_graphical_steps = round_values(resampled_df[\"Time\"].values / float(resampled_df.attrs[\"Time between graphical output\"]))\n",
    "\n",
    "    # make the animation directory\n",
    "    ani_dir = os.path.join(local_dir, \"img\", \"animation\")\n",
    "    if not os.path.isdir(ani_dir):\n",
    "        os.mkdir(ani_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then prepare the figure scripts in Paraview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_3d_animation_generate_figures = True\n",
    "\n",
    "if is_3d_animation and is_3d_animation_generate_figures:\n",
    "\n",
    "    from hamageolib.research.haoyuan_3d_subduction.post_process import get_trench_position_from_file, get_slab_depth_from_file,\\\n",
    "        PLOT_CASE_RUN_THD, finalize_visualization_2d_07222025_box\n",
    "    \n",
    "    # write header to script file \n",
    "    with open(py_temp_file, 'w') as fout:\n",
    "        fout.write(\"#!/bin/bash\\n\")\n",
    "\n",
    "    # parameters\n",
    "    ofile_list = [\"slab1.py\"]; require_base=True\n",
    "    time_range = None\n",
    "    time_interval = None\n",
    "    # turn on plot_axis if I want to save a complete result\n",
    "    # turn off if I want to prepare for figures in a paper\n",
    "    plot_axis = False\n",
    "    slices=None # specify steps\n",
    "    # step = \"auto\"; slices=3  # auto-figure out the steps, take the numebr of slices\n",
    "    max_velocity = -1.0  # rescale the color for velocity\n",
    "    rotation_plus = 0.47 # rotation of the frame along the lon when making plot\n",
    "    da_range = [-10e6, 10e6] # range of dynamic pressures\n",
    "\n",
    "    # get initial trench position\n",
    "    pyvista_outdir0 = os.path.join(local_dir, \"pyvista_outputs\", \"%05d\" % int(Case_Options.options['INITIAL_ADAPTIVE_REFINEMENT']))\n",
    "    try:\n",
    "        trench_center_ini = get_trench_position_from_file(pyvista_outdir0, int(Case_Options.options['INITIAL_ADAPTIVE_REFINEMENT']), Case_Options.options['GEOMETRY'])\n",
    "    except FileNotFoundError:\n",
    "        trench_center_ini = -1.0\n",
    "\n",
    "    # Generate paraview script\n",
    "    for step in ani_graphical_steps:\n",
    "    \n",
    "        # Initiate plotting class\n",
    "        PlotCaseRunThD = PLOT_CASE_RUN_THD(local_dir, time_range=time_range, run_visual=False,\\\n",
    "                time_interval=time_interval, visualization=\"paraview\", step=step, plot_axis=plot_axis, max_velocity=max_velocity,\\\n",
    "                        rotation_plus=rotation_plus, ofile_list=ofile_list, require_base=require_base)\n",
    "        # Get time \n",
    "        idx = Case_Options.summary_df[\"Vtu step\"] == step\n",
    "        _time = Case_Options.summary_df.loc[idx, \"Time\"].values[0]\n",
    "        time_rounded = round(_time / float(resampled_df.attrs[\"Time between graphical output\"]))\\\n",
    "              * float(resampled_df.attrs[\"Time between graphical output\"])\n",
    "\n",
    "        # get trench center\n",
    "        pvtu_step = step + int(Case_Options.options['INITIAL_ADAPTIVE_REFINEMENT']) \n",
    "        pyvista_outdir = os.path.join(local_dir, \"pyvista_outputs\", \"%05d\" % pvtu_step)\n",
    "        try:\n",
    "            trench_center = get_trench_position_from_file(pyvista_outdir, pvtu_step, Case_Options.options['GEOMETRY'], trench_depth=50e3)\n",
    "            trench_center_deg = trench_center * 180.0  / np.pi\n",
    "            slab_depth = get_slab_depth_from_file(pyvista_outdir, pvtu_step, Case_Options.options['GEOMETRY'], float(Case_Options.options['OUTER_RADIUS']), \"sp_lower\")\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "        # plot symmetry plane mantle\n",
    "        # FOO01 (T contour): 1- 725 C, 2 - 900 C, 3 - 1100 C\n",
    "\n",
    "        Case_Options.Interpret(rotation_angle=0.47) \n",
    "        additional_options = {\"ANIMATION\": \"True\", \"TRENCH_CENTER\": trench_center, \"TRENCH_INI_DERIVED\": trench_center_ini,\\\n",
    "        \"PLOT_TIME\": _time, \"DA_RANGE\": str(da_range), \"FOO05\": \"0\", \"FOO01\": \"3\", 'GRAPHICAL_STEPS': [step], 'GRAPHICAL_TIMES': [time_rounded],\\\n",
    "            \"PLOT_TYPES\": [\"upper_mantle\"]}\n",
    "        Case_Options.options.update(additional_options)\n",
    "        snapshot = Case_Options.options['GRAPHICAL_STEPS'][0] + int(Case_Options.options['INITIAL_ADAPTIVE_REFINEMENT'])\n",
    "        odir = os.path.join(local_dir, 'paraview_scripts', \"%05d\" % snapshot)\n",
    "        if not os.path.isdir(os.path.join(local_dir, 'paraview_scripts')):\n",
    "            os.mkdir(os.path.join(local_dir, 'paraview_scripts'))\n",
    "        if not os.path.isdir(odir):\n",
    "            os.mkdir(odir)\n",
    "        paraview_script = os.path.join(SCRIPT_DIR, 'paraview_scripts',\"ThDSubduction\", \"slab1.py\")\n",
    "        if require_base:\n",
    "            paraview_base_script = os.path.join(SCRIPT_DIR, 'paraview_scripts', 'base.py')  # base.py : base file\n",
    "            Case_Options.read_contents(paraview_base_script, paraview_script)  # this part combines two scripts\n",
    "        else:\n",
    "            Case_Options.read_contents(paraview_script)  # this part combines two scripts\n",
    "\n",
    "        # generate paraview scripts     \n",
    "        Case_Options.substitute()  # substitute keys in these combined file with values determined by Interpret() function\n",
    "        ofile = os.path.join(local_dir, 'paraview_scripts', \"%05d\" % snapshot, \"slab1.py\")\n",
    "        Case_Options.save(ofile)\n",
    "        with open(py_temp_file, 'a') as fout:\n",
    "            fout.write(\"pvpython %s\\n\" % ofile)\n",
    "\n",
    "        # plot the mantle wedge region\n",
    "        # (temporarily commented to omit the wedge plot)\n",
    "        # diff_angle = 0 # deg, to match the frame we use\n",
    "        # additional_options = {\"ANIMATION\": \"True\", \"TRENCH_CENTER\": trench_center, \"TRENCH_INI_DERIVED\": trench_center_ini,\\\n",
    "        # \"PLOT_TIME\": _time, \"DA_RANGE\": str(da_range), \"FOO05\": \"0\", \"FOO01\": \"3\", 'GRAPHICAL_STEPS': [step], 'GRAPHICAL_TIMES': [time_rounded],\\\n",
    "        #     \"PLOT_TYPES\": [\"wedge\"], \"ROTATION_ANGLE\": 90.0 - trench_center_deg - diff_angle}\n",
    "        # Case_Options.options.update(additional_options)\n",
    "        # if require_base:\n",
    "        #     paraview_base_script = os.path.join(SCRIPT_DIR, 'paraview_scripts', 'base.py')  # base.py : base file\n",
    "        #     Case_Options.read_contents(paraview_base_script, paraview_script)  # this part combines two scripts\n",
    "        # else:\n",
    "        #     Case_Options.read_contents(paraview_script)  # this part combines two scripts\n",
    "        # Case_Options.substitute()  # substitute keys in these combined file with values determined by Interpret() function\n",
    "        # ofile = os.path.join(local_dir, 'paraview_scripts', \"%05d\" % snapshot, \"slab2.py\")\n",
    "        # Case_Options.save(ofile)\n",
    "        # with open(py_temp_file, 'a') as fout:\n",
    "        #     fout.write(\"pvpython %s\\n\" % ofile)\n",
    "\n",
    "        # plot the slab 3-d morphology\n",
    "        additional_options = {\"ANIMATION\": \"True\", \"TRENCH_CENTER\": trench_center, \"TRENCH_INI_DERIVED\": trench_center_ini,\\\n",
    "        \"PLOT_TIME\": _time, \"DA_RANGE\": str(da_range), \"FOO05\": \"0\", \"FOO01\": \"3\", 'GRAPHICAL_STEPS': [step], 'GRAPHICAL_TIMES': [time_rounded],\\\n",
    "            \"PLOT_TYPES\": [\"slab_3d\"]}\n",
    "        Case_Options.options.update(additional_options)\n",
    "        snapshot = Case_Options.options['GRAPHICAL_STEPS'][0] + int(Case_Options.options['INITIAL_ADAPTIVE_REFINEMENT'])\n",
    "        odir = os.path.join(local_dir, 'paraview_scripts', \"%05d\" % snapshot)\n",
    "        if not os.path.isdir(odir):\n",
    "            os.mkdir(odir)\n",
    "        paraview_script = os.path.join(SCRIPT_DIR, 'paraview_scripts',\"ThDSubduction\", \"slab1.py\")\n",
    "        if require_base:\n",
    "            paraview_base_script = os.path.join(SCRIPT_DIR, 'paraview_scripts', 'base.py')  # base.py : base file\n",
    "            Case_Options.read_contents(paraview_base_script, paraview_script)  # this part combines two scripts\n",
    "        else:\n",
    "            Case_Options.read_contents(paraview_script)  # this part combines two scripts\n",
    "\n",
    "        # generate paraview scripts     \n",
    "        Case_Options.substitute()  # substitute keys in these combined file with values determined by Interpret() function\n",
    "        ofile = os.path.join(local_dir, 'paraview_scripts', \"%05d\" % snapshot, \"slab3.py\")\n",
    "        Case_Options.save(ofile)\n",
    "        with open(py_temp_file, 'a') as fout:\n",
    "            fout.write(\"pvpython %s\\n\" % ofile)\n",
    "\n",
    "        if is_3d_animation_debug_first_step:\n",
    "            break\n",
    "\n",
    "    fout.close()\n",
    "    subprocess.run([\"chmod\", \"+x\", py_temp_file])\n",
    "\n",
    "    print(\"Saved paraview script %s\" % py_temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate morphology plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_3d_animation_generate_morphology = False\n",
    "\n",
    "if is_3d_animation and is_3d_animation_generate_morphology:\n",
    "    \n",
    "    from matplotlib import rcdefaults\n",
    "    import hamageolib.utils.plot_helper as plot_helper\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "    # Generate slab morphology plot\n",
    "    # todo_ani\n",
    "    # plot options\n",
    "    scaling_factor = 1.0\n",
    "    font_scaling_multiplier = 1.5 # extra scaling multiplier for font\n",
    "    legend_font_scaling_multiplier = 0.5\n",
    "    line_width_scaling_multiplier = 2.0 # extra scaling multiplier for lines\n",
    "    tr_lim = (-1000.0, 1000.0)\n",
    "    tr_tick_interval = 200.0   # tick interval along x\n",
    "    depth_lim = (0.0, 2000)\n",
    "    depth_tick_interval = 200.0  # tick interval along y\n",
    "    v_lim = (-10.0, 10.0)\n",
    "    v_tick_interval = 2.0  # tick interval along v\n",
    "    angle_lim = (0.0, 100.0)\n",
    "    angle_tick_interval = 10.0\n",
    "    n_minor_ticks = 4  # number of minor ticks between two major ones\n",
    "    factor_3d = 10\n",
    "\n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # read case options\n",
    "    geometry = Case_Options.options[\"GEOMETRY\"]\n",
    "    Ro = Case_Options.options[\"OUTER_RADIUS\"]\n",
    "\n",
    "    # scale the matplotlib params\n",
    "    plot_helper.scale_matplotlib_params(scaling_factor, font_scaling_multiplier=font_scaling_multiplier,\\\n",
    "                            legend_font_scaling_multiplier=legend_font_scaling_multiplier,\n",
    "                            line_width_scaling_multiplier=line_width_scaling_multiplier)\n",
    "\n",
    "    # Update font settings for compatibility with publishing tools like Illustrator.\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'Times New Roman',\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42\n",
    "    })\n",
    "\n",
    "    for step in ani_graphical_steps:\n",
    "\n",
    "        # assign output directory\n",
    "        pvtu_step = step + int(Case_Options.options['INITIAL_ADAPTIVE_REFINEMENT']) \n",
    "        odir = os.path.join(local_dir, 'img', \"animation\", \"%05d\" % step)\n",
    "        if not os.path.isdir(odir):\n",
    "            os.mkdir(odir)\n",
    "\n",
    "        # Get time \n",
    "        idx = Case_Options.summary_df[\"Vtu step\"] == step\n",
    "        _time = Case_Options.summary_df.loc[idx, \"Time\"].values[0]\n",
    "\n",
    "        # parse data\n",
    "        time_3d = Case_Options.summary_df[\"Time\"].to_numpy()\n",
    "        slab_depth_3d = Case_Options.summary_df[\"Slab depth\"].to_numpy()\n",
    "        dip_angle_center_3d = Case_Options.summary_df[\"Dip 100 (center)\"].to_numpy()\n",
    "        sp_velocity_raw = Case_Options.summary_df[\"Sp velocity\"].to_numpy()\n",
    "        if geometry == \"chunk\":\n",
    "            trench_center_3d = Ro * Case_Options.summary_df[\"Trench (center 50km)\"].to_numpy()\n",
    "        else:\n",
    "            trench_center_3d = Case_Options.summary_df[\"Trench (center 50km)\"].to_numpy()\n",
    "        mow_volume_raw = Case_Options.summary_df[\"MOW volume\"].to_numpy()\n",
    "        mow_volume_slab_raw = Case_Options.summary_df[\"MOW volume cold\"].to_numpy()\n",
    "        mow_area_raw = Case_Options.summary_df[\"Mow area center\"].to_numpy()\n",
    "        mow_area_slab_raw = Case_Options.summary_df[\"Mow area cold center\"].to_numpy()\n",
    "\n",
    "        # ------------------------------\n",
    "        # first figure: normal kinematics\n",
    "        # Initiate figure\n",
    "        # ------------------------------\n",
    "        fig = plt.figure(figsize=(10*scaling_factor, 3.5*scaling_factor), tight_layout=True)\n",
    "        gs = gridspec.GridSpec(1, 2)\n",
    "\n",
    "        # add axis\n",
    "        ax = fig.add_subplot(gs[0, 0])\n",
    "        ax_twin = ax.twinx()\n",
    "        ax1 = fig.add_subplot(gs[0, 1])\n",
    "        ax1_twinx = ax1.twinx()\n",
    "\n",
    "\n",
    "        # todo_3d\n",
    "        Xs_3d = time_3d/1e6\n",
    "        Ys_3d = (trench_center_3d - trench_center_3d[0])/1e3\n",
    "        Ys_3d_1 = slab_depth_3d/1e3\n",
    "        dx_dy_3d = np.gradient(Ys_3d[::factor_3d], Xs_3d[::factor_3d]) / 1e3 * 1e2\n",
    "        dx_dy_3d_1 = np.gradient(Ys_3d_1[::factor_3d], Xs_3d[::factor_3d]) / 1e3 * 1e2\n",
    "        ax.plot(Xs_3d[::factor_3d],  Ys_3d[::factor_3d], label=\"Trench (center)\", color=default_colors[0])\n",
    "        ax.axvline(x=_time/1e6, linestyle=\"--\", color=\"tab:grey\")\n",
    "        ax_twin.plot(Xs_3d[::factor_3d],  Ys_3d_1[::factor_3d], linestyle=\"-.\", label=\"Slab Depth\", color=default_colors[0])\n",
    "\n",
    "        ax1.plot(Xs_3d[::factor_3d], dx_dy_3d, label=\"Trench Velocity (center)\", color=default_colors[0])\n",
    "        ax1.plot(Xs_3d[::factor_3d], dx_dy_3d_1, linestyle=\"-.\", label=\"Sinking Velocity (center)\", color=default_colors[0])\n",
    "        ax1.axvline(x=_time/1e6, linestyle=\"--\", color=\"tab:grey\")\n",
    "\n",
    "        ax1_twinx.plot(Xs_3d[::factor_3d], dip_angle_center_3d[::factor_3d]*180.0/np.pi, label=\"Dip 100 (center)\", linestyle=\"--\", color=default_colors[0])\n",
    "\n",
    "        ax.set_ylim(tr_lim)\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(tr_tick_interval))\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(tr_tick_interval/(n_minor_ticks+1)))\n",
    "        ax_twin.set_ylim(depth_lim)\n",
    "        ax_twin.yaxis.set_major_locator(MultipleLocator(depth_tick_interval))\n",
    "        ax_twin.yaxis.set_minor_locator(MultipleLocator(depth_tick_interval/(n_minor_ticks+1)))\n",
    "        ax1.set_ylim(v_lim)\n",
    "        ax1.yaxis.set_major_locator(MultipleLocator(v_tick_interval))\n",
    "        ax1.yaxis.set_minor_locator(MultipleLocator(v_tick_interval/(n_minor_ticks+1)))\n",
    "        ax1_twinx.set_ylim(angle_lim)\n",
    "        ax1_twinx.yaxis.set_major_locator(MultipleLocator(angle_tick_interval))\n",
    "        ax1_twinx.yaxis.set_minor_locator(MultipleLocator(angle_tick_interval/(n_minor_ticks+1)))\n",
    "\n",
    "        ax.grid()\n",
    "        ax1.grid()\n",
    "\n",
    "        # save figure\n",
    "        filepath = os.path.join(odir, \"slab_morphology.pdf\")\n",
    "        fig.savefig(filepath)\n",
    "        print(\"Saved figure: \", filepath)\n",
    "        filepath_png = os.path.join(odir, \"slab_morphology.png\")\n",
    "        fig.savefig(filepath_png)\n",
    "        print(\"Saved figure: \", filepath_png)\n",
    "        plt.close()\n",
    "        \n",
    "        # ------------------------------\n",
    "        # second figure: metastable kinematics\n",
    "        # Initiate figure\n",
    "        # ------------------------------\n",
    "\n",
    "        fig = plt.figure(figsize=(10*scaling_factor, 3.5*scaling_factor), tight_layout=True)\n",
    "        gs = gridspec.GridSpec(1, 2)\n",
    "\n",
    "        # add axis\n",
    "        ax = fig.add_subplot(gs[0, 0])\n",
    "        ax_twin = ax.twinx()\n",
    "        ax1 = fig.add_subplot(gs[0, 1])\n",
    "        ax1_twinx = ax1.twinx()\n",
    "        \n",
    "        # todo_3d\n",
    "        # plot 3-D symmetric plane area\n",
    "        ax.plot(Xs_3d[::factor_3d],  sp_velocity_raw[::factor_3d], color=default_colors[0])\n",
    "        ax.axvline(x=_time/1e6, linestyle=\"--\", color=\"tab:grey\")\n",
    "        ax_twin.plot(Xs_3d[::factor_3d],  mow_area_slab_raw[::factor_3d]/1e6, linestyle=\"-\", color=default_colors[0])\n",
    "\n",
    "        ax.set_ylim([0, 20.0]) # cm/yr\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(5.0))\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(5.0/(n_minor_ticks+1)))\n",
    "\n",
    "        ax_twin.set_ylabel(\"MOW Area (km^2)\")\n",
    "        ax_twin.set_ylim([0, 10000.0]) # km^2\n",
    "        ax_twin.yaxis.set_major_locator(MultipleLocator(2500.0))\n",
    "        ax_twin.yaxis.set_minor_locator(MultipleLocator(2500.0/(n_minor_ticks+1)))\n",
    "\n",
    "        ax.grid()\n",
    "\n",
    "        # plot 3-D volume \n",
    "        ax1.plot(Xs_3d[::factor_3d],  sp_velocity_raw[::factor_3d], color=default_colors[0])\n",
    "        ax1.axvline(x=_time/1e6, linestyle=\"--\", color=\"tab:grey\")\n",
    "        ax1_twinx.plot(Xs_3d[::factor_3d],  mow_volume_slab_raw[::factor_3d]/1e9, linestyle=\"-\", color=default_colors[0])\n",
    "        \n",
    "        ax1.set_ylim([0, 20.0]) # cm/yr\n",
    "        ax1.yaxis.set_major_locator(MultipleLocator(5.0))\n",
    "        ax1.yaxis.set_minor_locator(MultipleLocator(5.0/(n_minor_ticks+1)))\n",
    "        \n",
    "        ax1_twinx.set_ylabel(\"MOW Volume (km^3)\")\n",
    "        ax1_twinx.set_ylim([0, 10e6]) # km^2\n",
    "        ax1_twinx.yaxis.set_major_locator(MultipleLocator(2.5e6))\n",
    "        ax1_twinx.yaxis.set_minor_locator(MultipleLocator(2.5e6/(n_minor_ticks+1)))\n",
    "\n",
    "        ax1.grid()\n",
    "\n",
    "        # save figure\n",
    "        filepath = os.path.join(odir, \"slab_morphology1.pdf\")\n",
    "        fig.savefig(filepath)\n",
    "        print(\"Saved figure: \", filepath)\n",
    "        filepath_png = os.path.join(odir, \"slab_morphology1.png\")\n",
    "        fig.savefig(filepath_png)\n",
    "        print(\"Saved figure: \", filepath_png)\n",
    "        plt.close()\n",
    "        \n",
    "        if is_3d_animation_debug_first_step:\n",
    "            break\n",
    "\n",
    "    # Reset rcParams to defaults\n",
    "    rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalize plot from paraview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_3d_animation:\n",
    "    import warnings\n",
    "    from hamageolib.utils.plot_helper import convert_eps_to_pdf, extract_image_by_size, overlay_images_on_blank_canvas,\\\n",
    "    add_text_to_image, scale_matplotlib_params\n",
    "    from hamageolib.research.haoyuan_2d_subduction.workflow_scripts import finalize_visualization_2d_12172024, finalize_visualization_2d_wedge_12202024, finalize_visualization_2d_wedge_02122025, create_avi_from_images\n",
    "    from hamageolib.research.haoyuan_3d_subduction.post_process import finalize_visualization_2d_07222025_box\n",
    "    found_steps = []\n",
    "    skip_steps = []\n",
    "    ani_file_paths  = []\n",
    "\n",
    "    prep_file_dir = os.path.join(local_dir, \"img\", \"animation\", 'prep')\n",
    "    if not os.path.isdir(prep_file_dir):\n",
    "            os.mkdir(prep_file_dir)\n",
    "\n",
    "    for step in ani_graphical_steps:\n",
    "        # Get time \n",
    "        idx = Case_Options.summary_df[\"Vtu step\"] == step\n",
    "        _time = Case_Options.summary_df.loc[idx, \"Time\"].values[0]\n",
    "        _time_rounded = round(_time / float(resampled_df.attrs[\"Time between graphical output\"]))\\\n",
    "            * float(resampled_df.attrs[\"Time between graphical output\"])\n",
    "\n",
    "        # find files\n",
    "        thd_3d_slice_file = os.path.join(local_dir, \"img\", \"pv_outputs\", \"slice_center_viscosity_t%.4e.png\" % _time_rounded)\n",
    "        \n",
    "        slab_morphology_file = os.path.join(local_dir, \"img\", \"animation\", \"%05d\" % step, \"slab_morphology.png\")\n",
    "        slab_morphology1_file = os.path.join(local_dir, \"img\", \"animation\", \"%05d\" % step, \"slab_morphology1.png\")\n",
    "        slab_morphology_legend = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/kinematic_legend-01.png\"\n",
    "\n",
    "        try:\n",
    "            my_assert(os.path.isfile(thd_3d_slice_file), FileExistsError, \"File %s doesn't exist\" % thd_3d_slice_file)\n",
    "        except FileExistsError as e:\n",
    "            if is_3d_animation_skip_missing_files:\n",
    "                warnings.warn(\"File %s doesn't exist, skip step %05d\" % (thd_3d_slice_file, step))\n",
    "                skip_steps.append(step)\n",
    "                continue\n",
    "            else:\n",
    "                raise e\n",
    "        try:\n",
    "            my_assert(os.path.isfile(slab_morphology_file), FileExistsError, \"File %s doesn't exist\" % slab_morphology_file)\n",
    "        except FileExistsError as e:\n",
    "            if is_3d_animation_skip_missing_files:\n",
    "                warnings.warn(\"File %s doesn't exist, skip step %05d\" % (thd_3d_slice_file, step))\n",
    "                skip_steps.append(step)\n",
    "                continue\n",
    "            else:\n",
    "                raise e\n",
    "        \n",
    "        # todo_ani\n",
    "        # finalize slices\n",
    "        thd_slab_file = os.path.join(local_dir, \"img/pv_outputs\", \"3d_velocity_%.4e.png\" % (_time_rounded))\n",
    "        if Case_Options.options[\"GEOMETRY\"] == \"chunk\":\n",
    "            raise NotImplementedError() \n",
    "    \n",
    "        else:\n",
    "            frame_png_file_with_ticks = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/upper_mantle_frame_07222025_trans_modified_box_with_frame.png\"\n",
    "            # viscosity slice\n",
    "            thd_3d_slice_viscosity_finalized_file = finalize_visualization_2d_07222025_box(local_dir, \"slice_center_viscosity\", _time_rounded, frame_png_file_with_ticks, add_time=False)\n",
    "            # density slice \n",
    "            thd_3d_slice_density_finalized_file = finalize_visualization_2d_07222025_box(local_dir, \"slice_center_density\", _time_rounded, frame_png_file_with_ticks, add_time=False)\n",
    "            # mow slice \n",
    "            if Case_Options.options[\"MODEL_TYPE\"] == \"mow\":\n",
    "                thd_3d_slice_mow_finalized_file = finalize_visualization_2d_07222025_box(local_dir, \"slice_center_mow\", _time_rounded, frame_png_file_with_ticks, add_time=False)\n",
    "            # grain size slice\n",
    "            if Case_Options.options[\"HAS_METASTABLE_GRAIN_SIZE\"]:\n",
    "                thd_3d_slice_gz_finalized_file = finalize_visualization_2d_07222025_box(local_dir, \"slice_center_meta_grain_size\", _time_rounded, frame_png_file_with_ticks, add_time=False)\n",
    "\n",
    "            viscosity_colorbar_file = \"/home/lochy/Documents/papers/documented_files/MOW/paper_dynamics/color_viscosity_19_24-01.png\"\n",
    "        assert(os.path.isfile(viscosity_colorbar_file))\n",
    "        \n",
    "        density_colorbar_file = \"/home/lochy/Documents/papers/documented_files/MOW/paper_dynamics/color_density_3000_4000-01.png\"\n",
    "        assert(os.path.isfile(density_colorbar_file))\n",
    "        \n",
    "        mow_colorbar_file = \"/home/lochy/Documents/papers/documented_files/MOW/paper_dynamics/color_metastable_0_1-01.png\"\n",
    "        assert(os.path.isfile(mow_colorbar_file))\n",
    "        \n",
    "        gz_colorbar_file = \"/home/lochy/Documents/papers/documented_files/MOW/paper_dynamics/color_meta_grain_size_1e-10_1.png\"\n",
    "        assert(os.path.isfile(gz_colorbar_file))\n",
    "        \n",
    "        dp_colorbar_file = \"/home/lochy/Documents/papers/documented_files/ThDSubduction/Frame/color_da_pressure_10.png\"\n",
    "        assert(os.path.isfile(dp_colorbar_file))\n",
    "            \n",
    "        prep_file_dir = os.path.join(local_dir, \"img\", \"animation\", 'prep')\n",
    "        if not os.path.isdir(prep_file_dir):\n",
    "            os.mkdir(prep_file_dir)\n",
    "\n",
    "        # combine figures\n",
    "        # Overlays multiple images on a blank canvas with specified sizes, positions, cropping, and scaling.\n",
    "        output_image_file = os.path.join(prep_file_dir, \"animation_upper_mantle_t%.4e.png\" % (_time))\n",
    "        if os.path.isfile(output_image_file):\n",
    "            # Remove existing output image to ensure a clean overlay\n",
    "            os.remove(output_image_file)\n",
    "\n",
    "        height_3d = 1000\n",
    "        # List of image file paths to overlay\n",
    "        image_file_list = [thd_slab_file,\\\n",
    "                         thd_3d_slice_viscosity_finalized_file, viscosity_colorbar_file,\\\n",
    "                         thd_3d_slice_density_finalized_file, density_colorbar_file]\n",
    "        if Case_Options.options[\"MODEL_TYPE\"] == \"mow\":\n",
    "            image_file_list += [thd_3d_slice_mow_finalized_file, mow_colorbar_file]\n",
    "        if Case_Options.options[\"HAS_METASTABLE_GRAIN_SIZE\"]:\n",
    "            image_file_list += [thd_3d_slice_gz_finalized_file, gz_colorbar_file]\n",
    "        image_file_list += [slab_morphology_file, slab_morphology_legend,\\\n",
    "                                  slab_morphology1_file]  \n",
    "        # Positions of each image on the canvas\n",
    "        image_position_list = [(100, 100),\\\n",
    "                             (0, 100+height_3d), (150, 700+height_3d),\\\n",
    "                                (1200, 100+height_3d), (1350, 700+height_3d)]\n",
    "        if Case_Options.options[\"MODEL_TYPE\"] == \"mow\":\n",
    "            image_position_list += [(0, 900+height_3d), (150, 1500+height_3d)]\n",
    "        if Case_Options.options[\"HAS_METASTABLE_GRAIN_SIZE\"]:\n",
    "            image_position_list += [(1200, 900+height_3d), (1350, 1500+height_3d)]\n",
    "        image_position_list += [(100, 1800+height_3d), (400, 2400+height_3d),\\\n",
    "                                        (100, 2700+height_3d)]\n",
    "        # Optional cropping regions for the images\n",
    "        cropping_region_list = [(100, 0, 1200, 700),\\\n",
    "                              None, None,\\\n",
    "                                None, None]\n",
    "        if Case_Options.options[\"MODEL_TYPE\"] == \"mow\":\n",
    "            cropping_region_list +=  [None,None]             \n",
    "        if Case_Options.options[\"HAS_METASTABLE_GRAIN_SIZE\"]:\n",
    "            cropping_region_list += [None,None]\n",
    "        cropping_region_list += [None, None, None]\n",
    "        # Scaling factors for resizing the images\n",
    "        image_scale_factor_list = [1.5,\\\n",
    "                                 1.0, 1.5,\\\n",
    "                                    1.0, 1.5]\n",
    "        if Case_Options.options[\"MODEL_TYPE\"] == \"mow\":\n",
    "            image_scale_factor_list += [1.0, 1.5]\n",
    "        if Case_Options.options[\"HAS_METASTABLE_GRAIN_SIZE\"]:\n",
    "            image_scale_factor_list += [1.0, 1.5]\n",
    "        image_scale_factor_list+= [1.8, 1.0,\\\n",
    "                                        1.8]  \n",
    "\n",
    "        overlay_images_on_blank_canvas(\n",
    "            canvas_size=(2200, 4700),  # Size of the blank canvas in pixels (width, height)\n",
    "            image_files=image_file_list,\n",
    "            image_positions=image_position_list,\n",
    "            cropping_regions=cropping_region_list,  \n",
    "            image_scale_factors=image_scale_factor_list,  \n",
    "            output_image_file=output_image_file  # Path to save the final combined image\n",
    "        )\n",
    "\n",
    "        # Add time stamp\n",
    "        text = \"t = %.1f Ma\" % (_time_rounded / 1e6)  # Replace with the text you want to add\n",
    "        position = (25, 0)  # Replace with the desired text position (x, y)\n",
    "        font_path = \"/usr/share/fonts/truetype/msttcorefonts/times.ttf\"  # Path to Times New Roman font\n",
    "        font_size = 56\n",
    "        add_text_to_image(output_image_file, output_image_file, text, position, font_path, font_size)\n",
    "\n",
    "        # Add notation for trench position & 3-d figure\n",
    "        text = \"Note: Trench is derived at 50 km depth on the interface\\n The 3-d figure is plotted in a croped region of 1000-km depth.\"\n",
    "        position = (50, 50)  # Replace with the desired text position (x, y)\n",
    "        font_path = \"/usr/share/fonts/truetype/msttcorefonts/times.ttf\"  # Path to Times New Roman font\n",
    "        font_size = 40\n",
    "        add_text_to_image(output_image_file, output_image_file, text, position, font_path, font_size)\n",
    "\n",
    "        # Add notation for trench position & slice\n",
    "        text = \"Note: Slice at the symmetric plane\"\n",
    "        position = (50, 1000)  # Replace with the desired text position (x, y)\n",
    "        font_path = \"/usr/share/fonts/truetype/msttcorefonts/times.ttf\"  # Path to Times New Roman font\n",
    "        font_size = 40\n",
    "        add_text_to_image(output_image_file, output_image_file, text, position, font_path, font_size)\n",
    "\n",
    "        # Add notation for trench position & slice at the mantle wedge\n",
    "        text = \"Note: Kinematic results\"\n",
    "        position = (50, 2800)  # Replace with the desired text position (x, y)\n",
    "        font_path = \"/usr/share/fonts/truetype/msttcorefonts/times.ttf\"  # Path to Times New Roman font\n",
    "        font_size = 40\n",
    "        add_text_to_image(output_image_file, output_image_file, text, position, font_path, font_size)\n",
    "\n",
    "        # Add notation for mow area\n",
    "        text = \"Note: MOW area in 2d symmetry plane and volume in 3d\"\n",
    "        position = (50, 3700)  # Replace with the desired text position (x, y)\n",
    "        font_path = \"/usr/share/fonts/truetype/msttcorefonts/times.ttf\"  # Path to Times New Roman font\n",
    "        font_size = 40\n",
    "        add_text_to_image(output_image_file, output_image_file, text, position, font_path, font_size)\n",
    "            \n",
    "        found_steps.append(step)\n",
    "\n",
    "        ani_file_paths.append(output_image_file)\n",
    "\n",
    "        if is_3d_animation_debug_first_step:\n",
    "            break\n",
    "\n",
    "    # Generate animation\n",
    "    if not is_3d_animation_debug_first_step:\n",
    "        ani_dir = os.path.join(local_dir, \"img\", \"animation\")\n",
    "        if not os.path.isdir(ani_dir):\n",
    "            os.mkdir(ani_dir)\n",
    "        output_file = os.path.join(ani_dir, \"slab.avi\")\n",
    "        create_avi_from_images(ani_file_paths, output_file, 1)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmgeolib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
