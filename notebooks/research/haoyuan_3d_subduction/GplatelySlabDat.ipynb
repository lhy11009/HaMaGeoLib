{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gplate for slab dataset\n",
    "\n",
    "In this notebook, I use gplately to extract slab dataset, resample and plot the results\n",
    "\n",
    "## Prerequisite\n",
    "\n",
    "- Install the gplately package in a conda environment. Refer to their home page and there installation link [https://github.com/GPlates/gplately](https://github.com/GPlates/gplately)\n",
    "- Download this package and set path to the installation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the environment of py-gplate\n",
    "import sys\n",
    "import gplately\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import cartopy.crs as ccrs\n",
    "from plate_model_manager import PlateModelManager\n",
    "from shutil import rmtree\n",
    "\n",
    "# Include this pakage\n",
    "# change to your download path\n",
    "HaMaGeoLib_DIR = \"/home/lochy/ASPECT_PROJECT/HaMaGeoLib\"\n",
    "if os.path.abspath(HaMaGeoLib_DIR) not in sys.path:\n",
    "    sys.path.append(os.path.abspath(HaMaGeoLib_DIR))\n",
    "\n",
    "from hamageolib.research.haoyuan_3d_subduction.gplately_utilities import GPLOTTER, GPLATE_PROCESS\n",
    "from hamageolib.utils.exception_handler import my_assert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the directory of the plate reconstruction files\n",
    "case_dir = \"/mnt/lochy/ASPECT_DATA/ThDSubduction/gplate_dataset_09202025\"\n",
    "if not os.path.isdir(case_dir):\n",
    "  os.mkdir(case_dir)\n",
    "if not os.path.isdir(os.path.join(case_dir, \"img\")):\n",
    "  os.mkdir(os.path.join(case_dir, \"img\"))\n",
    "csv_dir = os.path.join(case_dir, \"csv\")\n",
    "if not os.path.isdir(csv_dir):\n",
    "  os.mkdir(csv_dir)\n",
    "\n",
    "# assign a reconstruction time\n",
    "model_name = \"Muller2019\"\n",
    "reconstruction_time=0 # time of reconstruction, must be integar\n",
    "assert(type(reconstruction_time) == int)\n",
    "anchor_plate_id = 0 # anchor plate id: 0 - Africa\n",
    "\n",
    "# set up a directory to output for every step\n",
    "img_dir = os.path.join(os.path.join(case_dir, \"img\", \"%05dMa\" % reconstruction_time))\n",
    "if not os.path.isdir(img_dir):\n",
    "  os.mkdir(img_dir)\n",
    "\n",
    "GplateP = GPLATE_PROCESS(case_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import a lookup file for slab names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the name lookup file\n",
    "# These files are exported from gplate (GUI)\n",
    "parse_name_lookup = False\n",
    "if parse_name_lookup:\n",
    "    from hamageolib.research.haoyuan_3d_subduction.gplately_utilities import read_subduction_reconstruction_data\n",
    "\n",
    "    subduction_name_lookup_file = os.path.join(case_dir, \"Muller_etal_2019_PlateBoundaries_no_topologies\",\\\n",
    "                                              \"reconstructed_%.2fMa.xy\" % float(reconstruction_time))\n",
    "    name_lookups = read_subduction_reconstruction_data(subduction_name_lookup_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup for a key word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_key_word = False\n",
    "\n",
    "if parse_name_lookup and lookup_key_word:\n",
    "\n",
    "    # print(name_lookups[\"trench_names\"]) # debug\n",
    "\n",
    "    keyword = \"ryu\"\n",
    "\n",
    "    matching_indices = [i for i, name in enumerate(name_lookups[\"trench_names\"]) if keyword.lower() in name.lower()]\n",
    "    for index in matching_indices:\n",
    "        print(index)\n",
    "        print(\"name: \", name_lookups[\"trench_names\"][index])\n",
    "        print(\"id: \", name_lookups[\"trench_pids\"][index])\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lookup by trench pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_by_trench_pid = False\n",
    "\n",
    "if parse_name_lookup and lookup_by_trench_pid:\n",
    "\n",
    "    pid_lookup_list = [12001, 686, 736, 651, 669, 612, 678, 648, 659, 699, 111, 406, 413, 2000, 201, 2031, 2011, 815, 821]\n",
    "\n",
    "    for index, pid in enumerate(name_lookups[\"trench_pids\"]):\n",
    "        if pid in pid_lookup_list:\n",
    "            print(\"pid = %d, name = %s\" % (pid, name_lookups[\"trench_names\"][index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run in series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_in_series = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import reconstruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_series:\n",
    "    GplateP.reconstruct(model_name, reconstruction_time, anchor_plate_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_series:\n",
    "    GplateP.add_age_raster()\n",
    "    GplateP.export_csv(\"subduction_data\", \"ori.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and save results of every subduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_all_slabs = False\n",
    "inspect_all_slabs_in_separate_plots = False\n",
    "\n",
    "if run_in_series and inspect_all_slabs:\n",
    "    GplateP.save_results_ori(inspect_all_slabs_in_separate_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make A Global / Regional Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo_plot\n",
    "\n",
    "plot_original_results_paper = True\n",
    "\n",
    "if plot_original_results_paper:\n",
    "\n",
    "    GplateP.save_results_global_paper(projection_type=\"robinson\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_dataset = True\n",
    "\n",
    "if run_in_series and resample_dataset:\n",
    "\n",
    "    # parameters for resampling \n",
    "    arc_length_edge = 2.0; arc_length_resample_section = 2.0\n",
    "\n",
    "    GplateP.resample_subduction(arc_length_edge, arc_length_resample_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and save results of resampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_all_slabs_resampled = True\n",
    "inspect_all_slabs_resampled_plot_individual = True\n",
    "\n",
    "if run_in_series and resample_dataset and inspect_all_slabs_resampled:\n",
    "\n",
    "    GplateP.save_results_resampled(inspect_all_slabs_resampled_plot_individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_analysis = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define additional markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_series and do_analysis:\n",
    "\n",
    "    from matplotlib.path import Path\n",
    "\n",
    "    verts = [\n",
    "        (0., 0.),   # Center\n",
    "        (0.2, 0.6), # Upper arm\n",
    "        (0., 0.),   # Center\n",
    "        (0.4, 0.4), # Right diagonal\n",
    "        (0., 0.),   # Center\n",
    "        (0.6, 0.2), # Right arm\n",
    "        (0., 0.),   # Center\n",
    "        (0.4, -0.4),# Right down diagonal\n",
    "        (0., 0.),   # Center\n",
    "        (0.2, -0.6),# Bottom arm\n",
    "        (0., 0.),   # Center\n",
    "        (-0.4, -0.4),# Left down diagonal\n",
    "        (0., 0.),   # Center\n",
    "        (-0.6, -0.2),# Left arm\n",
    "        (0., 0.),   # Center\n",
    "        (-0.4, 0.4),# Left diagonal\n",
    "        (0., 0.),   # Center\n",
    "        (-0.2, 0.6),# Upper left arm\n",
    "    ]\n",
    "    codes = [Path.MOVETO] + [Path.LINETO, Path.MOVETO] * 8 + [Path.MOVETO]\n",
    "    snowflake = Path(verts, codes)\n",
    "\n",
    "    # Define vertices for two equilateral triangles\n",
    "    vertices = [\n",
    "        [0, 1], [-np.sqrt(3)/2, -0.5], [np.sqrt(3)/2, -0.5], [0, 1],  # First triangle\n",
    "        [0, -1], [-np.sqrt(3)/2, 0.5], [np.sqrt(3)/2, 0.5], [0, -1]   # Second triangle\n",
    "    ]\n",
    "    # Flatten the vertices list for creating the Path\n",
    "    vertices = np.array(vertices)\n",
    "    # Define path codes (all 'LINETO' except the start 'MOVETO')\n",
    "    codes = [Path.MOVETO] + [Path.LINETO] * (len(vertices) - 1)\n",
    "    star_path = Path(vertices, codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot options for cases\n",
    "\n",
    "Notes:\n",
    "\n",
    "- The plot_by_name option plots the data points with their assigned names. These names have to be specified. Be default, set to False and the subducting_pid will be used to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_series and do_analysis:\n",
    "\n",
    "    # Plot options\n",
    "    plot_by_name = False  # True - by name; False - by pid\n",
    "    \n",
    "    # Retrieve the default color cycle\n",
    "    default_colors = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "    # assign plot options\n",
    "    if plot_by_name:\n",
    "        if reconstruction_time == 0:\n",
    "            plot_options = \\\n",
    "            (\n",
    "                (903, {\"marker\": 'o',  \"markerfacecolor\": \"yellow\", \"name\": \"CAS\"}),\n",
    "                (511, {\"marker\": 's',  \"markerfacecolor\": \"yellow\", \"name\": \"ANDA-SUM\"}),\n",
    "                (801, {\"marker\": 'd',  \"markerfacecolor\": \"yellow\", \"name\": \"JAVA\"}),\n",
    "                (645, {\"marker\": snowflake,  \"markerfacecolor\": \"black\", \"name\": \"SULA\"}),\n",
    "                (602, {\"marker\": 'x',  \"markerfacecolor\": \"blue\", \"name\": \"LUZ\"}),\n",
    "                (608, {\"marker\": 's',  \"markerfacecolor\": 'c', \"name\": \"PHIL\"}),\n",
    "                ({901: 699}, {\"marker\": '>',  \"markerfacecolor\": 'red', \"name\": \"MAR\"}),\n",
    "                ({901: 659}, {\"marker\": 's',  \"markerfacecolor\": 'red', \"name\": \"IZU\"}),\n",
    "                ({901: (601115.0, 601118.0)}, {\"marker\": '^',  \"markerfacecolor\": 'green', \"name\": \"JAP\"}),\n",
    "                ({901: 406}, {\"marker\": 'v',  \"markerfacecolor\": 'green', \"name\": \"KUKAM\"}),\n",
    "                ({901: 111}, {\"marker\": 'o',  \"markerfacecolor\": 'pink', \"name\": \"ALE-ALA\"}),\n",
    "                ({901: (806, 821)}, {\"marker\": 'd',  \"markerfacecolor\": 'blue', \"name\": \"TON-KERM\"}),\n",
    "                (909, {\"marker\": star_path,  \"markerfacecolor\": 'c', \"name\": \"MEX\"}),\n",
    "                (911, {\"marker\": 'o',  \"markerfacecolor\": 'k', \"name\": \"PER-NCHI-JUAN-SCHI\"}),\n",
    "                (802, {\"marker\": 'd',  \"markerfacecolor\": 'k', \"name\": \"SSCHI-TBD\"}),\n",
    "                ({201: 2011}, {\"marker\": '+',  \"markerfacecolor\": 'pink', \"name\": \"ANT\"}),\n",
    "                ({201: 815}, {\"marker\": '*',  \"markerfacecolor\": 'r', \"name\": \"SAND\"}),\n",
    "                (1, {\"marker\": 'd',  \"markerfacecolor\": \"r\", \"name\": \"RYU\"})\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    else:\n",
    "        plot_options = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate vs age plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_age_combined = True\n",
    "\n",
    "if run_in_series and do_analysis and analyze_age_combined:\n",
    "\n",
    "    GplateP.plot_age_combined(resample_dataset, plot_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run_in_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_animation = True\n",
    "\n",
    "if make_animation:\n",
    "    start_time = 0.0\n",
    "    end_time = 61.0\n",
    "    interval = 1.0\n",
    "    \n",
    "    only_one_pid = None  # None - process all subductions; a number - only process with this subducting plid\n",
    "\n",
    "    # resample parameters     \n",
    "    arc_length_edge = 2.0; arc_length_resample_section = 2.0\n",
    "\n",
    "    reconstruction_times = np.arange(start_time, end_time, interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the python script\n",
    "\n",
    "Run with the same option as above\n",
    "\n",
    "    hamageolib/research/haoyuan_3d_subduction/scripts/Gplately_Slab_Dat_Batch.py\n",
    "\n",
    "This loops the time of reconstructions, plot for the desinated regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if make_animation:\n",
    "    import json\n",
    "    from hamageolib.research.haoyuan_2d_subduction.workflow_scripts import create_avi_from_images\n",
    "    \n",
    "    ani_dir = os.path.join(case_dir, \"animation\")\n",
    "    if not os.path.isdir(ani_dir):\n",
    "        os.mkdir(ani_dir)\n",
    "\n",
    "    # loop first to get pid and region dict\n",
    "    pid_dict = {} # record existing pid in timestep\n",
    "    region_dict = {} # record plot region for each subduction\n",
    "    \n",
    "    # todo_data\n",
    "    # load pid dict from script output\n",
    "    pid_filepath = os.path.join(case_dir, \"pid_dict.json\")\n",
    "    assert(os.path.isfile(pid_filepath))\n",
    "\n",
    "    with open(pid_filepath, 'r') as fin:\n",
    "        pid_dict = json.load(fin)\n",
    "\n",
    "    for subducting_pid, _times in pid_dict.items():\n",
    "\n",
    "        # skip other pids if only one pid is requried\n",
    "        if only_one_pid is not None:\n",
    "            if int(subducting_pid) != only_one_pid:\n",
    "                continue\n",
    "\n",
    "        # create animation for each subduction zone\n",
    "        ani_file_list = []\n",
    "\n",
    "        for i, reconstruction_time in enumerate(_times):\n",
    "\n",
    "            image_file = os.path.join(\"%05dMa\" % int(reconstruction_time),\\\n",
    "                                   \"resampled_edge%.1f_section%.1f\" % (arc_length_edge, arc_length_resample_section),\\\n",
    "                                    \"global_subduction_resampled_t%.2fMa_pid%06d.png\" % (reconstruction_time, only_one_pid))\n",
    "\n",
    "            my_assert(os.path.isfile(image_file), FileExistsError, \"%s doesn't exist.\")\n",
    "        \n",
    "            ani_file_list.append(image_file)\n",
    "\n",
    "        ani_file_name = \"pid%06d_%05dMa_%05dMa\" % (int(subducting_pid), _times[0], _times[-1])\n",
    "        output_file = os.path.join(ani_dir, \"%s.avi\" % ani_file_name)\n",
    "        create_avi_from_images(ani_file_list, output_file, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-gplate-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
